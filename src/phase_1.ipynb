{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHASE 1: PROFILE + GEN Q'S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.csv_utils as csv_utils \n",
    "import utils.dir_utils as dir_utils\n",
    "import utils.dict_utils as dict_utils \n",
    "import utils.ptr_utils as ptr_utils\n",
    "import utils.constants as constants \n",
    "import helpers.official as official\n",
    "import helpers.search as search\n",
    "import helpers.congress as congress\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of officials in House and Senate in total (from 112-117th congress): 0\n",
      "\n",
      "Number of transactions: 22,195 \n",
      "\n",
      "Number of transactions by House Representatives: 13,154, 59.27%\n",
      "Number of transactions by House Representatives controlled: 83.78 transactions per representative \n",
      "\n",
      "Number of transactions by Senators: 9,041, 40.73%\n",
      "Number of transactions by Senators controlled: 143.51 transactions per senator \n",
      "\n",
      "Number of officials in House and Senate in total (from 112-117th congress): 27\n",
      "\n",
      "Number of officials in input: 220\n",
      "Number of officials in input controlled: 22.70%\n",
      "\n",
      "Number of representatives in input: 157, 71.36%\n",
      "Number of representatives in input controlled: 18.87% \n",
      "\n",
      "Number of senators in input: 63, 28.64%\n",
      "Number of senators in input controlled: 38.41% \n",
      "\n",
      "Number of officials in total (from 112-117th congress): 969\n",
      "Number of representatives in total (from 112-117th congress): 832\n",
      "Number of senators in total (from 112-117th congress): 164\n",
      "\n",
      "Number of officials from 112-117th congress who DID NOT engage in the market: 749, 77.30%\n",
      "\n",
      "Number of representatives from 112-117th congress who DID NOT engage in the market: 648\n",
      "Number of senators from 112-117th congress who DID NOT engage in the market: 101\n",
      "\n",
      "Number of officials from 112-117th congress who DID engage in the market: 220, 22.70% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, input_df = dir_utils.get_data(combined=True)\n",
    "_, house_input_df = dir_utils.get_data(house=True)\n",
    "_, senate_input_df = dir_utils.get_data(senate=True)\n",
    "\n",
    "num_of_transactions = input_df.shape[0]\n",
    "num_of_house_transactions = house_input_df.shape[0]\n",
    "num_of_senate_transactions = senate_input_df.shape[0]\n",
    "\n",
    "sector_df = dir_utils.get_mapping(sector=True)\n",
    "industry_df = dir_utils.get_mapping(industry=True)\n",
    "\n",
    "# {canonical_name_input_based : link, ...}\n",
    "input_all_officials_name = {}\n",
    "\n",
    "# {link : canonical_name_input_based, ....}\n",
    "input_all_officials_link = {}\n",
    "input_house_officials_link = {}\n",
    "input_senate_officials_link = {}\n",
    "\n",
    "# (canonical_name_input_based, ...)\n",
    "names = set()\n",
    "\n",
    "for _,t in input_df.iterrows():        \n",
    "    name = official.get_name(t)\n",
    "        \n",
    "    if name not in names:    \n",
    "        link = search.get_wiki_link(name)\n",
    "                \n",
    "        if ptr_utils.isvalid(t[constants.REPRESENTATIVE]) and link not in input_house_officials_link:\n",
    "            input_house_officials_link =  dict_utils.increment_dictionary(input_house_officials_link, link, name, not_math=True)\n",
    "        if ptr_utils.isvalid(t[constants.SENATOR]) and link not in input_senate_officials_link:\n",
    "            input_senate_officials_link =  dict_utils.increment_dictionary(input_senate_officials_link, link, name, not_math=True)\n",
    "        \n",
    "        input_all_officials_link =  dict_utils.increment_dictionary(input_all_officials_link, link, name, not_math=True)\n",
    "        input_all_officials_name =  dict_utils.increment_dictionary(input_all_officials_name, name, link, not_math=True)\n",
    "\n",
    "        names.add(name)\n",
    "\n",
    "input_officials_in_house_and_senate = 0 \n",
    "for link in input_all_officials_link:\n",
    "    if link in input_house_officials_link and link in input_senate_officials_link:\n",
    "        del input_house_officials_link[link]\n",
    "        input_officials_in_house_and_senate += 1\n",
    "print(\"Number of officials in House and Senate in total (from 112-117th congress): {}\\n\".format(input_officials_in_house_and_senate))\n",
    "\n",
    "\n",
    "print(\"Number of transactions: {} \\n\".format(ptr_utils.commify_str(len(input_df.index))))\n",
    "\n",
    "print(\"Number of transactions by House Representatives: {}, {}\".format(ptr_utils.commify_str(num_of_house_transactions), ptr_utils.make_percent(num_of_house_transactions, len(input_df.index))))\n",
    "print(\"Number of transactions by House Representatives controlled: {0:.2f} transactions per representative \\n\".format((num_of_house_transactions / len(input_house_officials_link))))\n",
    "\n",
    "print(\"Number of transactions by Senators: {}, {}\".format(ptr_utils.commify_str(num_of_senate_transactions), ptr_utils.make_percent(num_of_senate_transactions, len(input_df.index))))\n",
    "print(\"Number of transactions by Senators controlled: {0:.2f} transactions per senator \\n\".format( (num_of_senate_transactions /  len(input_senate_officials_link))))\n",
    "\n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "input_house_officials_objects = {}\n",
    "for link, person in input_house_officials_link.items(): \n",
    "    off = search.wiki_search(person)        \n",
    "    input_house_officials_objects[link] = (person, off)\n",
    "        \n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "input_senate_officials_objects = {}\n",
    "for link, person in input_senate_officials_link.items():\n",
    "    off = search.wiki_search(person)        \n",
    "    input_senate_officials_objects[link] = (person, off)\n",
    "\n",
    "# {link : (canonical_name_input_based, official_object) ... }\n",
    "input_officials_objects = {**input_house_officials_objects, **input_senate_officials_objects}\n",
    "\n",
    "# {link : canonical_name_wiki_based, ... }\n",
    "all_officials = congress.get_all_officials()\n",
    "house_officials = congress.get_house_officials()\n",
    "senate_officials = congress.get_senate_officials()\n",
    "\n",
    "# {link : gender, ...}\n",
    "all_officials_gender = {}\n",
    "input_house_officials_gender = {}\n",
    "input_senate_officials_gender = {}\n",
    "\n",
    "all_officials_party_and_gender = {}\n",
    "house_officials_party_and_gender = {}\n",
    "senate_officials_party_and_gender = {}\n",
    "\n",
    "for link, name in all_officials.items():\n",
    "    gender = official.get_gender(name, link)\n",
    "    \n",
    "    x = search.congress_gov_get(name, party_only=True)\n",
    "    grouped = x + \", \" + gender\n",
    "        \n",
    "    all_officials_party_and_gender = dict_utils.increment_dictionary(all_officials_party_and_gender, grouped)\n",
    "\n",
    "    if link in senate_officials:\n",
    "        senate_officials_party_and_gender = dict_utils.increment_dictionary(senate_officials_party_and_gender, grouped)\n",
    "    if link in house_officials:\n",
    "        house_officials_party_and_gender = dict_utils.increment_dictionary(house_officials_party_and_gender, grouped)\n",
    "  \n",
    "    if link in input_house_officials_objects:\n",
    "       input_house_officials_gender[link] = gender\n",
    "    if link in input_senate_officials_objects:\n",
    "        input_senate_officials_gender[link] =  gender\n",
    "    all_officials_gender[link] = gender\n",
    "\n",
    "# {'California' :  #_of_representatives_from_112_to_117, ...}\n",
    "all_officials_state_count = congress.get_officials_state(everyone=list(all_officials.values()))\n",
    "house_officials_state_count = congress.get_officials_state(house=list(house_officials.values()))\n",
    "senate_officials_state_count = congress.get_officials_state(everyone=list(senate_officials.values()))\n",
    "\n",
    "congress_objects = []\n",
    "house_officials_party = {}\n",
    "senate_officials_party = {}\n",
    "for i in range(112, 118):\n",
    "    c = search.get_congress(i)\n",
    "    congress_objects.append(c)\n",
    "    house_officials_party.update(c.get_house_party())\n",
    "    senate_officials_party.update(c.get_senate_party())\n",
    "all_officials_party = {**house_officials_party, **senate_officials_party}\n",
    "    \n",
    "# {link : canonical_name_wiki_based, ... }\n",
    "all_officials_not_in_input = dict(all_officials)\n",
    "house_officials_not_in_input = dict(house_officials)\n",
    "senate_officials_not_in_input = dict(senate_officials)\n",
    "\n",
    "all_officials_in_house_and_senate = 0 \n",
    "for link in all_officials_not_in_input:\n",
    "    if link in house_officials_not_in_input and link in senate_officials_not_in_input:\n",
    "        del house_officials_not_in_input[link]\n",
    "        all_officials_in_house_and_senate += 1\n",
    "print(\"Number of officials in House and Senate in total (from 112-117th congress): {}\\n\".format(all_officials_in_house_and_senate))\n",
    "\n",
    "\n",
    "for link_input in input_all_officials_link.keys():\n",
    "    del all_officials_not_in_input[link_input]\n",
    "    \n",
    "    if link_input in house_officials_not_in_input:\n",
    "        del house_officials_not_in_input[link_input]\n",
    "    else:\n",
    "        del senate_officials_not_in_input[link_input]\n",
    "    \n",
    "\n",
    "print(\"Number of officials in input: {}\".format(len(input_all_officials_link)))\n",
    "print(\"Number of officials in input controlled: {}\\n\".format(ptr_utils.make_percent(len(input_all_officials_link), len(all_officials))))\n",
    "\n",
    "print(\"Number of representatives in input: {}, {}\".format(len(input_house_officials_link), ptr_utils.make_percent(len(input_house_officials_link), len(input_all_officials_link))))\n",
    "print(\"Number of representatives in input controlled: {} \\n\".format(ptr_utils.make_percent(len(input_house_officials_link), len(house_officials))))\n",
    "\n",
    "print(\"Number of senators in input: {}, {}\".format(len(input_senate_officials_link), ptr_utils.make_percent(len(input_senate_officials_link), len(input_all_officials_link))))\n",
    "print(\"Number of senators in input controlled: {} \\n\".format(ptr_utils.make_percent(len(input_senate_officials_link), len(senate_officials))))\n",
    "\n",
    "print(\"Number of officials in total (from 112-117th congress): {}\".format(ptr_utils.commify_str(len(all_officials))))\n",
    "print(\"Number of representatives in total (from 112-117th congress): {}\".format(ptr_utils.commify_str(len(house_officials))))\n",
    "print(\"Number of senators in total (from 112-117th congress): {}\\n\".format(ptr_utils.commify_str(len(senate_officials))))\n",
    "\n",
    "print(\"Number of officials from 112-117th congress who DID NOT engage in the market: {}, {}\\n\".format(len(all_officials_not_in_input), ptr_utils.make_percent(len(all_officials_not_in_input), len(all_officials) ) ))\n",
    "print(\"Number of representatives from 112-117th congress who DID NOT engage in the market: {}\".format(len(house_officials_not_in_input)))\n",
    "print(\"Number of senators from 112-117th congress who DID NOT engage in the market: {}\\n\".format(len(senate_officials_not_in_input)))\n",
    "\n",
    "print(\"Number of officials from 112-117th congress who DID engage in the market: {}, {} \\n\".format(len(input_all_officials_link), ptr_utils.make_percent(len(input_all_officials_link), len(all_officials) ) ))\n",
    "\n",
    "def t_to_obj(t):\n",
    "    name = official.get_name(t)\n",
    "    link = input_all_officials_name[name]\n",
    "    _, obj = input_officials_objects[link]\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Party and Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_party_and_gender(group, normalized=None):\n",
    "    # {party_and_gender : 45_ppl}\n",
    "    d = {}\n",
    "        \n",
    "    # {link : (canonical_name_input_based, official_object), ... \n",
    "    for link, (_,obj) in group.items():\n",
    "        x = obj.party\n",
    "        gender = all_officials_gender[link]\n",
    "        grouped = x + \", \" + gender\n",
    "        d = dict_utils.increment_dictionary(d, grouped)\n",
    "\n",
    "    # Normalize\n",
    "    if normalized: \n",
    "        d = dict_utils.normalize(d, normalized, percent=True)\n",
    "\n",
    "    return d\n",
    "\n",
    "d1 = profile_party_and_gender(input_house_officials_objects, house_officials_party_and_gender)\n",
    "d2 = profile_party_and_gender(input_senate_officials_objects, senate_officials_party_and_gender)\n",
    "d3 = profile_party_and_gender(input_officials_objects, all_officials_party_and_gender)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"profile/partyandgender\")\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_party_and_gender_normalized\", (d1,d2,d3), [constants.PARTY + \", \" + constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "\n",
    "d1 = profile_party_and_gender(input_house_officials_objects)\n",
    "d2 = profile_party_and_gender(input_senate_officials_objects)\n",
    "d3 = profile_party_and_gender(input_officials_objects)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"profile/partyandgender\")\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_party_and_gender\", (d1,d2,d3), [constants.PARTY + \", \" + constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_active_party_and_gender(group, normalized=None):\n",
    "    # {party_and_gender : 45_transactions}\n",
    "    d_number = {}\n",
    "    # {party_and_gender : [gmean, gmean, ...]}\n",
    "    d_size = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "            name = official.get_name(t)\n",
    "            link = input_all_officials_name[name]\n",
    "\n",
    "            gender = all_officials_gender[link]\n",
    "            obj = t_to_obj(t)\n",
    "            x = obj.party\n",
    "            grouped = x + \", \" + gender\n",
    "\n",
    "            \n",
    "            d_number =  dict_utils.increment_dictionary(d_number, grouped)\n",
    "            \n",
    "            mean =  ptr_utils.get_gmean(t[constants.AMOUNT])             \n",
    "            d_size = dict_utils.increment_list_in_dictionary(d_size, grouped, mean)\n",
    "\n",
    "    d_size = dict_utils.flatten_gmean(d_size)\n",
    "\n",
    "    # Normalize\n",
    "    if normalized: \n",
    "        d_number = dict_utils.normalize(d_number, normalized, percent=True)\n",
    "        d_number = dict_utils.sort_dictionary_by_tuple(d_number)\n",
    "        \n",
    "        d_size = dict_utils.normalize(d_size, normalized)\n",
    "        d_size = dict_utils.sort_dictionary_by_tuple(d_size)\n",
    "\n",
    "    return d_number, d_size\n",
    "    \n",
    "d1,d4 = profile_active_party_and_gender(house_input_df, house_officials_party_and_gender)\n",
    "d2,d5 = profile_active_party_and_gender(senate_input_df, senate_officials_party_and_gender)\n",
    "d3,d6 = profile_active_party_and_gender(input_df, all_officials_party_and_gender)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"profile/partyandgender\")\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_party_and_gender_number_normalized\", (d1,d2,d3), [constants.PARTY + \", \" + constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_party_and_gender_size_normalized\", (d4,d5,d6), [constants.PARTY + \", \" + constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "\n",
    "d1,d4 = profile_active_party_and_gender(house_input_df)\n",
    "d2,d5 = profile_active_party_and_gender(senate_input_df)\n",
    "d3,d6 = profile_active_party_and_gender(input_df)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_party_and_gender_number\", (d1,d2,d3), [constants.PARTY + \", \" + constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_party_and_gender_size\", (d4,d5,d6), [constants.PARTY + \", \" + constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age (Lowest, Highest, Average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_age(group):\n",
    "    # {age, age, ...}\n",
    "    l = []\n",
    "    \n",
    "    # group = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for _, (_, off_obj) in group.items(): \n",
    "        l.append(off_obj.get_age())\n",
    "    \n",
    "    l.sort()\n",
    "    \n",
    "    d = {}\n",
    "    d[\"0. Youngest\"] = l[0]\n",
    "    d[\"1. Average\"] = round((sum(l) / len(l)))\n",
    "    d[\"2. Oldest\"] = l[len(l)-1]\n",
    "    \n",
    "    return d \n",
    "    \n",
    "d1 = profile_age(input_house_officials_objects)\n",
    "d2 = profile_age(input_senate_officials_objects)\n",
    "d3 = profile_age(input_officials_objects)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"profile/age\")\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_age\", (d1,d2,d3), [\"Age\", constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "def profile_age_2(group):\n",
    "    # {age : #_of_people, ...}\n",
    "    d = dict(constants.age_groups)\n",
    "    \n",
    "    for (_, off_obj) in group.values(): \n",
    "        age = off_obj.get_age()\n",
    "        d = dict_utils.increment_dictionary(d, ptr_utils.which_age_group(age)) \n",
    "    \n",
    "    return d \n",
    "    \n",
    "d1 = profile_age_2(input_house_officials_objects)\n",
    "d2 = profile_age_2(input_senate_officials_objects)\n",
    "d3 = profile_age_2(input_officials_objects)\n",
    "\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_age_2\", (d1,d2,d3), [\"Age\", constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age (Which age is most active?) Active = No. of Trades &  Size of Transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'house_input_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/y3/llvqw9gd7nz5vkbmv014r2kc0000gn/T/ipykernel_57952/173836290.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0md_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0md1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprofile_active_age\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhouse_input_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile_age_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_house_officials_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0md2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprofile_active_age\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msenate_input_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile_age_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_senate_officials_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0md3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprofile_active_age\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile_age_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_officials_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'house_input_df' is not defined"
     ]
    }
   ],
   "source": [
    "def profile_active_age(group, normalized=None):\n",
    "    # {age : 45_transactions}\n",
    "    d_number = dict(constants.age_groups)\n",
    "    \n",
    "    # {age : [gmean, gmean, ...]}\n",
    "    d_size = dict(constants.age_groups)\n",
    "    for k,_ in d_size.items():\n",
    "        d_size[k] = []\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "            obj = t_to_obj(t)\n",
    "            age = obj.get_age()\n",
    "            \n",
    "            age_group = ptr_utils.which_age_group(age)\n",
    "            d_number =  dict_utils.increment_dictionary(d_number, age_group)\n",
    "            \n",
    "            mean =  ptr_utils.get_gmean(t[constants.AMOUNT])             \n",
    "            d_size = dict_utils.increment_list_in_dictionary(d_size, age_group, mean)\n",
    "\n",
    "    d_size = dict_utils.flatten_gmean(d_size)\n",
    "\n",
    "    # Normalize\n",
    "    if normalized: \n",
    "        d_number = dict_utils.normalize(d_number, normalized, percent=True)\n",
    "        d_number = dict_utils.sort_dictionary_by_tuple(d_number)\n",
    "        \n",
    "        d_size = dict_utils.normalize(d_size, normalized, percent=True)\n",
    "        d_size = dict_utils.sort_dictionary_by_tuple(d_size)\n",
    "\n",
    "    return d_number, d_size\n",
    "    \n",
    "d1,d4 = profile_active_age(house_input_df, profile_age_2(input_house_officials_objects))\n",
    "d2,d5 = profile_active_age(senate_input_df, profile_age_2(input_senate_officials_objects))\n",
    "d3,d6 = profile_active_age(input_df, profile_age_2(input_officials_objects))\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"profile/age\")\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_age_active_number_normalized\", (d1,d2,d3), [constants.AGE, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_age_active_size_normalized\", (d4,d5,d6), [constants.AGE, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "    \n",
    "d1,d4 = profile_active_age(house_input_df)\n",
    "d2,d5 = profile_active_age(senate_input_df)\n",
    "d3,d6 = profile_active_age(input_df)\n",
    "\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_age_active_number\", (d1,d2,d3), [constants.AGE, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_age_active_size\", (d4,d5,d6), [constants.AGE, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oldest and Most Recent Dates (transaction and disclosure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oldest transaction_date for house: 2018/09/08 \n",
      " https://disclosures-clerk.house.gov/public_disc/ptr-pdfs/2021/8218371.pdf\n",
      "Most recent transaction_date for house: 2021/12/31 \n",
      " https://disclosures-clerk.house.gov/public_disc/ptr-pdfs/2022/20020182.pdf \n",
      "Oldest disclosure_date for house: 2020/01/02 \n",
      " https://disclosures-clerk.house.gov/public_disc/ptr-pdfs/2020/20013832.pdf\n",
      "Most recent disclosure_date for house: 2022/02/11 \n",
      " https://disclosures-clerk.house.gov/public_disc/ptr-pdfs/2022/20020423.pdf\n",
      "\n",
      "Oldest transaction_date for senate: 2012/06/14 \n",
      " https://efdsearch.senate.gov/search/view/ptr/86e969b3-64e7-4a51-84d7-da82847b501e/\n",
      "Most recent transaction_date for senate: 2021/12/31 \n",
      " https://efdsearch.senate.gov/search/view/ptr/41868f55-ad42-4855-9aca-1764a05fb956/ \n",
      "Oldest disclosure_date for senate: 2012/07/25 \n",
      " https://efdsearch.senate.gov/search/view/paper/CDFDAF62-18EA-4298-B0C5-62085A6EC3CD/\n",
      "Most recent disclosure_date for senate: 2022/01/21 \n",
      " https://efdsearch.senate.gov/search/view/ptr/bfd4faf3-88b4-445a-8559-11ee5269ba7b/\n",
      "\n",
      "Oldest transaction_date for input: 2012/06/14 \n",
      " https://efdsearch.senate.gov/search/view/ptr/86e969b3-64e7-4a51-84d7-da82847b501e/\n",
      "Most recent transaction_date for input: 2021/12/31 \n",
      " https://efdsearch.senate.gov/search/view/ptr/41868f55-ad42-4855-9aca-1764a05fb956/ \n",
      "Oldest disclosure_date for input: 2012/07/25 \n",
      " https://efdsearch.senate.gov/search/view/paper/CDFDAF62-18EA-4298-B0C5-62085A6EC3CD/\n",
      "Most recent disclosure_date for input: 2022/02/11 \n",
      " https://disclosures-clerk.house.gov/public_disc/ptr-pdfs/2022/20020423.pdf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def profile_dates(group, type):\n",
    "    lowest_tdate = lowest_ddate = highest_tdate = highest_ddate = None\n",
    "    lowest_tdate_obj = lowest_ddate_obj = highest_tdate_obj = highest_ddate_obj = None\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        curr = t[constants.TDATE]            \n",
    "        if not lowest_tdate or curr < lowest_tdate:\n",
    "            lowest_tdate = curr \n",
    "            lowest_tdate_obj = t\n",
    "        if not highest_tdate or curr > highest_tdate:\n",
    "            highest_tdate = curr  \n",
    "            highest_tdate_obj = t\n",
    "\n",
    "        curr = t[constants.DDATE]\n",
    "        if not lowest_ddate or curr < lowest_ddate:\n",
    "            lowest_ddate = curr \n",
    "            lowest_ddate_obj = t\n",
    "        if not highest_ddate or curr > highest_ddate:\n",
    "            highest_ddate = curr \n",
    "            highest_ddate_obj = t\n",
    "\n",
    "    print(\"Oldest transaction_date for {}: {} \\n {}\".format(type, lowest_tdate, lowest_tdate_obj[constants.PTR_LINK]))\n",
    "    print(\"Most recent transaction_date for {}: {} \\n {} \".format(type, highest_tdate, highest_tdate_obj[constants.PTR_LINK]))\n",
    "    \n",
    "    print(\"Oldest disclosure_date for {}: {} \\n {}\".format(type, lowest_ddate, lowest_ddate_obj[constants.PTR_LINK]))\n",
    "    print(\"Most recent disclosure_date for {}: {} \\n {}\\n\".format(type, highest_ddate, highest_ddate_obj[constants.PTR_LINK]))\n",
    "    \n",
    "\n",
    "profile_dates(house_input_df, constants.HOUSE)\n",
    "profile_dates(senate_input_df, constants.SENATE)\n",
    "profile_dates(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_gender(group, normalized=None):\n",
    "    # d_prime = {'Female' : set(Officials), 'Male' : set(Officials), ...}\n",
    "    d_prime = {}\n",
    "\n",
    "    for link, name in group.items(): \n",
    "        gender = all_officials_gender[link]\n",
    "        d_prime = dict_utils.increment_set_in_dictionary(d_prime, gender, name)\n",
    "\n",
    "    # d = {'Female' : #_of_officials, 'Male' : #_of_officials, ...}\n",
    "    d = dict_utils.flatten_len(d_prime, inner_set=True)\n",
    "    \n",
    "    if normalized:\n",
    "        d = dict_utils.normalize(d, normalized, percent=True)\n",
    "        d = dict_utils.sort_dictionary_by_tuple(d)\n",
    "                 \n",
    "    return d\n",
    "\n",
    "d1 = profile_gender(input_house_officials_link, profile_gender(house_officials))\n",
    "d2 = profile_gender(input_senate_officials_link, profile_gender(senate_officials))\n",
    "d3 = profile_gender(input_all_officials_link, profile_gender(all_officials))\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"profile/gender\")\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_gender_normalized\", (d1,d2,d3), [constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "\n",
    "d1 = profile_gender(input_house_officials_link)\n",
    "d2 = profile_gender(input_senate_officials_link)\n",
    "d3 = profile_gender(input_all_officials_link)\n",
    "\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_gender\", (d1,d2,d3), [constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender (Which gender is the most active?) Active = No. of Trades &  Size of Transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_active_gender(group, normalized=None):\n",
    "    # {'gender' : 5_trades, ...}\n",
    "    d_number = {}\n",
    "    \n",
    "    # {gender : [gmean of amount, gmean of amount....] }\n",
    "    d_size = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "            name = official.get_name(t)\n",
    "            link = input_all_officials_name[name]\n",
    "            g = all_officials_gender[link]\n",
    "            \n",
    "            d_number =  dict_utils.increment_dictionary(d_number, g)\n",
    "            \n",
    "            mean =  ptr_utils.get_gmean(t[constants.AMOUNT])             \n",
    "            d_size = dict_utils.increment_list_in_dictionary(d_size, g, mean)\n",
    "\n",
    "    d_size = dict_utils.flatten_gmean(d_size)\n",
    "        \n",
    "    # Normalize\n",
    "    if normalized:\n",
    "        d_number = dict_utils.normalize(d_number, normalized, percent=True)\n",
    "        d_number = dict_utils.sort_dictionary_by_tuple(d_number)\n",
    "        \n",
    "        d_size = dict_utils.normalize(d_size, normalized, percent=True)\n",
    "        d_size = dict_utils.sort_dictionary_by_tuple(d_size)\n",
    "\n",
    "    return d_number, d_size\n",
    "\n",
    "\n",
    "d1,d4 = profile_active_gender(house_input_df, profile_gender(house_officials))\n",
    "d2,d5 = profile_active_gender(senate_input_df, profile_gender(senate_officials))\n",
    "d3,d6 = profile_active_gender(input_df, profile_gender(all_officials))\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"profile/gender\")\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_gender_number_normalized\", (d1,d2,d3), [constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_gender_size_normalized\", (d4,d5,d6), [constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "\n",
    "d1,d4 = profile_active_gender(house_input_df)\n",
    "d2,d5 = profile_active_gender(senate_input_df)\n",
    "d3,d6 = profile_active_gender(input_df)\n",
    "\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_gender_number\", (d1,d2,d3), [constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_gender_size\", (d4,d5,d6), [constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_party(group, normalized=None):\n",
    "    # d_prime = {'Republican' : set(Officials), 'Democrat' : set(Officials), ...}\n",
    "    d_prime = {}\n",
    "    \n",
    "    for (_, off_obj) in group.values(): \n",
    "        d_prime = dict_utils.increment_set_in_dictionary(d_prime, off_obj.party, off_obj.name)\n",
    "        \n",
    "    # d = {'Republican' : #_of_officials, 'Democrat' : #_of_officials, ...}\n",
    "    d = dict_utils.flatten_len(d_prime, inner_set=True)\n",
    "    \n",
    "    if normalized: \n",
    "        d = dict_utils.normalize(d, normalized, percent=True)\n",
    "        d = dict_utils.sort_dictionary_by_tuple(d)\n",
    "\n",
    "    return d\n",
    "\n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "d1 = profile_party(input_house_officials_objects, house_officials_party)\n",
    "d2 = profile_party(input_senate_officials_objects, senate_officials_party)\n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "d3 = profile_party(input_officials_objects, all_officials_party)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"profile/party\")\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_party_normalized\", (d1,d2,d3), [constants.PARTY, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "d1 = profile_party(input_house_officials_objects)\n",
    "d2 = profile_party(input_senate_officials_objects)\n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "d3 = profile_party(input_officials_objects)\n",
    "\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_party\", (d1,d2,d3), [constants.PARTY, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Party (Which party is the most active?) Active = No. of Trades &  Size of Transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_active_party(group, normalized=None):\n",
    "    # {'party' : 5_trades, ...}\n",
    "    d_number = {}\n",
    "    \n",
    "    # {party : [gmean of amount, gmean of amount....] }\n",
    "    d_size = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "            obj = t_to_obj(t)\n",
    "            party = obj.party        \n",
    "            \n",
    "            d_number =  dict_utils.increment_dictionary(d_number, party)\n",
    "            \n",
    "            mean =  ptr_utils.get_gmean(t[constants.AMOUNT])             \n",
    "            d_size = dict_utils.increment_list_in_dictionary(d_size, party, mean)\n",
    "\n",
    "    d_size = dict_utils.flatten_gmean(d_size)\n",
    "        \n",
    "    # Normalize\n",
    "    if normalized:\n",
    "        d_number = dict_utils.normalize(d_number, normalized, percent=True)\n",
    "        d_number = dict_utils.sort_dictionary_by_tuple(d_number)\n",
    "        \n",
    "        d_size = dict_utils.normalize(d_size, normalized, percent=True)\n",
    "        d_size = dict_utils.sort_dictionary_by_tuple(d_size)\n",
    "    \n",
    "    return d_number, d_size\n",
    "\n",
    "d1,d4 = profile_active_party(house_input_df, house_officials_party)\n",
    "d2,d5 = profile_active_party(senate_input_df, senate_officials_party)\n",
    "d3,d6 = profile_active_party(input_df, all_officials_party)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"profile/party\")\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_party_number_normalized\", (d1,d2,d3), [constants.PARTY, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_party_size_normalized\", (d4,d5,d6), [constants.PARTY, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "\n",
    "d1,d4 = profile_active_party(house_input_df)\n",
    "d2,d5 = profile_active_party(senate_input_df)\n",
    "d3,d6 = profile_active_party(input_df)\n",
    "\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_party_number\", (d1,d2,d3), [constants.PARTY, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_party_size\", (d4,d5,d6), [constants.PARTY, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_state(group, normalized=None):\n",
    "    # d_prime = {'Maryland' : set(Officials), 'California' : set(Officials), ...}\n",
    "    d_prime = {}\n",
    "    \n",
    "    # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for _, off_obj in group.values(): \n",
    "        d_prime = dict_utils.increment_set_in_dictionary(d_prime, off_obj.state, off_obj.name)\n",
    "\n",
    "    # d = {'Maryland' : #_of_officials, 'California' : #_of_officials, ...}\n",
    "    d = dict_utils.flatten_len(d_prime, inner_set=True)\n",
    "    \n",
    "    if normalized:\n",
    "        d = dict_utils.normalize(d, normalized, percent=True)\n",
    "        d = dict_utils.sort_dictionary_by_tuple(d)\n",
    "            \n",
    "    return d \n",
    "\n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "d1 = profile_state(input_house_officials_objects, house_officials_state_count)\n",
    "d2 = profile_state(input_senate_officials_objects, senate_officials_state_count)\n",
    "\n",
    "# {link : (canonical_name_input_based, official_object) ... }\n",
    "d3 = profile_state(input_officials_objects, all_officials_state_count)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"profile/state\")\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_state_normalized\", (d1,d2,d3), [constants.STATE, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "d1 = profile_state(input_house_officials_objects)\n",
    "d2 = profile_state(input_senate_officials_objects)\n",
    "\n",
    "# {link : (canonical_name_input_based, official_object) ... }\n",
    "d3 = profile_state(input_officials_objects)\n",
    "\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_state\", (d1,d2,d3), [constants.STATE, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State (Which state is the most active?) Active = No. of Trades &  Size of Transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_active_state(group, normalized=None):\n",
    "    # {'state' : 5_trades, ...}\n",
    "    d_number = {}\n",
    "    \n",
    "    # {state : [gmean of amount, gmean of amount....] }\n",
    "    d_size = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "            obj =  t_to_obj(t)\n",
    "            \n",
    "            d_number =  dict_utils.increment_dictionary(d_number, obj.state)\n",
    "            \n",
    "            mean =  ptr_utils.get_gmean(t[constants.AMOUNT])             \n",
    "            d_size = dict_utils.increment_list_in_dictionary(d_size, obj.state, mean)\n",
    "\n",
    "    d_size = dict_utils.flatten_gmean(d_size)\n",
    "    \n",
    "    if normalized:\n",
    "        d_number = dict_utils.normalize(d_number, normalized, percent=True)\n",
    "        d_number = dict_utils.sort_dictionary_by_tuple(d_number)\n",
    "        \n",
    "        d_size = dict_utils.normalize(d_size, normalized, percent=True)\n",
    "        d_size = dict_utils.sort_dictionary_by_tuple(d_size)\n",
    "\n",
    "    return d_number, d_size\n",
    "\n",
    "d1,d4 = profile_active_state(house_input_df, house_officials_state_count)\n",
    "d2,d5 = profile_active_state(senate_input_df, senate_officials_state_count)\n",
    "d3,d6 = profile_active_state(input_df, all_officials_state_count)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"profile/state\")\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_state_number_normalized\", (d1,d2,d3), [constants.STATE, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_state_size_normalized\", (d4,d5,d6), [constants.STATE, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "\n",
    "d1,d4 = profile_active_state(house_input_df)\n",
    "d2,d5 = profile_active_state(senate_input_df)\n",
    "d3,d6 = profile_active_state(input_df)\n",
    "\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_state_number\", (d1,d2,d3), [constants.STATE, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_state_size\", (d4,d5,d6), [constants.STATE, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seniority (Lowest, Highest, Average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_seniority(group):\n",
    "    # d = {x_years_in_congress, y_years_in_congres, ...}\n",
    "    l = []\n",
    "    \n",
    "    # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for _, (_, off_obj) in group.items(): \n",
    "        l.append(off_obj.get_seniority())\n",
    "    \n",
    "    l.sort()\n",
    "    \n",
    "    d = {}\n",
    "    d[\"0. Lowest\"] = l[0]\n",
    "    d[\"1. Average\"] = round((sum(l) / len(l)))\n",
    "    d[\"2. Highest\"] = l[len(l)-1]\n",
    "\n",
    "    return d \n",
    "\n",
    "d1 = profile_seniority(input_house_officials_objects)\n",
    "d2 = profile_seniority(input_senate_officials_objects)\n",
    "d3 = profile_seniority(input_officials_objects)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"profile/seniority\")\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_seniority\", (d1,d2,d3), [constants.SENIORITY, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "def profile_seniority_2(group):\n",
    "    # d = {x_years_in_congress : #_of_people, }\n",
    "    d = {}\n",
    "    \n",
    "    # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for (_, off_obj) in group.values(): \n",
    "        d =  dict_utils.increment_dictionary(d, off_obj.get_seniority())\n",
    "    \n",
    "    return d \n",
    "\n",
    "d1 = profile_seniority_2(input_house_officials_objects)\n",
    "d2 = profile_seniority_2(input_senate_officials_objects)\n",
    "d3 = profile_seniority_2(input_officials_objects)\n",
    "\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_seniority_2\", (d1,d2,d3), [constants.SENIORITY, constants.HOUSE, constants.SENATE, constants.INPUT])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seniority (Which seniority is most active?) Active = No. of Trades & Size of Transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_active_seniority(group, normalized=None):\n",
    "    # {'seniority' : 5_peeps_with_it, ...}\n",
    "    d_number = {}\n",
    "    \n",
    "    # {'seniority' :  [gmean of amount, gmean of amount....] }\n",
    "    d_size = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "            obj = t_to_obj(t)\n",
    "            seniority = obj.get_seniority()\n",
    "            \n",
    "            d_number =  dict_utils.increment_dictionary(d_number, seniority)\n",
    "            \n",
    "            mean =  ptr_utils.get_gmean(t[constants.AMOUNT])             \n",
    "            d_size = dict_utils.increment_list_in_dictionary(d_size, seniority, mean)\n",
    "    \n",
    "    d_size = dict_utils.flatten_gmean(d_size)\n",
    "\n",
    "    # Normalize\n",
    "    if normalized: \n",
    "        d_number = dict_utils.normalize(d_number, normalized, percent=True)\n",
    "        d_size = dict_utils.normalize(d_size, normalized, percent=True)\n",
    "\n",
    "    return d_number, d_size\n",
    "    \n",
    "d1,d4 = profile_active_seniority(house_input_df, profile_seniority_2(input_house_officials_objects))\n",
    "d2,d5 = profile_active_seniority(senate_input_df, profile_seniority_2(input_senate_officials_objects))\n",
    "d3,d6 = profile_active_seniority(input_df, profile_seniority_2(input_officials_objects))\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"profile/seniority\")\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_seniority_number_normalized\", (d1,d2,d3), [constants.AGE, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_seniority_size_normalized\", (d4,d5,d6), [constants.AGE, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "\n",
    "d1,d4 = profile_active_seniority(house_input_df)\n",
    "d2,d5 = profile_active_seniority(senate_input_df)\n",
    "d3,d6 = profile_active_seniority(input_df)\n",
    "\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_seniority_number\", (d1,d2,d3), [constants.AGE, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_seniority_size\", (d4,d5,d6), [constants.AGE, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get_Congress (Lowest, Highest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Degrees (Lowest, Highest, Average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_congress(group):\n",
    "    lowest = highest = None \n",
    "    \n",
    "    # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for (_, off_obj) in group.values():\n",
    "        res = off_obj.get_congress()\n",
    "        \n",
    "        if not lowest or res[0] < lowest:\n",
    "            lowest = res[0]\n",
    "    \n",
    "        if not highest or res[len(res) - 1] > highest:\n",
    "            highest = res[len(res) - 1]\n",
    "                    \n",
    "    d = {}\n",
    "    d[\"Lowest Congress\"] = lowest\n",
    "    d[\"Highest Congress\"] = highest\n",
    "\n",
    "    return d \n",
    "                        \n",
    "d1 = profile_congress(input_house_officials_objects)\n",
    "d2 = profile_congress(input_senate_officials_objects)\n",
    "d3 = profile_congress(input_officials_objects)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"profile/congress\")\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_congress\", (d1,d2,d3), [\"\", constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_degrees(group):    \n",
    "    # d = {x_degrees, y_degrees, ...}\n",
    "    l = []\n",
    "    \n",
    "    # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for (_, off_obj) in group.values(): \n",
    "        l.append(off_obj.get_num_of_degrees())\n",
    "    \n",
    "    l.sort()\n",
    "    \n",
    "    d = {}\n",
    "    d[\"0. Lowest\"] = l[0]\n",
    "    d[\"1. Average\"] = round((sum(l) / len(l)))\n",
    "    d[\"2. Highest\"] = l[len(l)-1]\n",
    "\n",
    "    return d \n",
    "    \n",
    "d1 = profile_degrees(input_house_officials_objects)\n",
    "d2 = profile_degrees(input_senate_officials_objects)\n",
    "d3 = profile_degrees(input_officials_objects)       \n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"profile/degrees\")\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_degrees\", (d1,d2,d3), [\"No. of Degrees\", constants.HOUSE, constants.SENATE, constants.INPUT]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_JD(group):\n",
    "    # d = {x_degrees, y_degrees, ...}\n",
    "    yes = total = 0 \n",
    "    \n",
    "    # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for (_, off_obj) in group.values(): \n",
    "        if off_obj.has_JD():\n",
    "            yes += 1 \n",
    "        total += 1 \n",
    "        \n",
    "    d = {}\n",
    "    \n",
    "    d[\"(Raw, Percent)\"] = (yes, ptr_utils.make_percent(yes, total))\n",
    "    \n",
    "    return d \n",
    "    \n",
    "d1 = profile_JD(input_house_officials_objects)\n",
    "d2 = profile_JD(input_senate_officials_objects)\n",
    "d3 = profile_JD(input_officials_objects)        \n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"profile/education\")\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_JDs\", (d1,d2,d3), [\"\", constants.HOUSE, constants.SENATE, constants.INPUT]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transaction Date (transaction_date) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency of Differences between Transaction and Disclosure Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_differences(group):\n",
    "    d = {}\n",
    "    # match = {}\n",
    "    total = num = 0 \n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        # Negative, X days BEFORE\n",
    "        # Positive, Y dayas AFTER\n",
    "        diff = ptr_utils.difference_between_dates(t)      \n",
    "        total += 1 \n",
    "        num += diff   \n",
    "        \n",
    "        # match = {5 days: {'Tom' : 1313, 'X': 3 , ...}. ..}\n",
    "        # match =  dict_utils.increment_dictionary_in_dictionary(match, diff, official.get_name(t))\n",
    "            \n",
    "        d =  dict_utils.increment_dictionary(d, int(diff))\n",
    "    \n",
    "    d[\"Average\"] = ptr_utils.make_percent(num, total)\n",
    "    \n",
    "    return d \n",
    "    # return dict_utils.sort_dictionary_by_keys(d)\n",
    "\n",
    "d1 = frequency_of_differences(house_input_df)\n",
    "d2 = frequency_of_differences(senate_input_df)\n",
    "d3 = frequency_of_differences(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"frequency_of_differences\", (d1,d2,d3), [\"Difference\", constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each sector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               sector transaction_date  number_of_transactions\n",
      "0  Financial Services       2020/03/18                      63\n",
      "1   Consumer Cyclical       2020/03/18                      45\n",
      "2         Industrials       2020/03/18                      37\n",
      "3          Technology       2019/06/24                      37\n",
      "4          Healthcare       2019/06/24                      32\n",
      "               sector transaction_date  number_of_transactions\n",
      "0  Financial Services       2020/04/14                      30\n",
      "1                Fund       2020/04/02                      27\n",
      "2   Consumer Cyclical       2020/04/14                      23\n",
      "3          Technology       2020/04/14                      20\n",
      "4         Industrials       2020/04/07                      20\n",
      "               sector transaction_date  number_of_transactions\n",
      "0  Financial Services       2020/03/18                      65\n",
      "1   Consumer Cyclical       2020/03/18                      48\n",
      "2         Industrials       2020/03/18                      39\n",
      "3          Technology       2019/06/24                      37\n",
      "4          Healthcare       2019/06/24                      32\n"
     ]
    }
   ],
   "source": [
    "def transaction_date_wrt_sector(group, diff):\n",
    "    # d_prime = {'sector' : {'date' : #_of_transactions, ....} , 'sector2' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            sector = dir_utils.search_mapping(sector_df, t[constants.TICKER], sector=True)            \n",
    "            d_prime =  dict_utils.increment_dictionary_in_dictionary(d_prime, sector, (t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    filename = \"transaction_date_wrt_sector\"  \n",
    "    if diff:\n",
    "        filename += \"_\" + diff \n",
    "    key_header = constants.SECTOR\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_sector(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_sector(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_sector(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each sector controlling for each official. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sector transaction_date  number_of_transactions\n",
      "0   MSFT       2021/04/30                       3\n",
      "1   TSLA       2021/03/22                       3\n",
      "2   AAPL       2020/03/23                       3\n",
      "3    UNH       2020/03/23                       3\n",
      "4    DIS       2020/03/18                       3\n",
      "  sector transaction_date  number_of_transactions\n",
      "0   AAPL       2020/08/27                       3\n",
      "1   DWDP       2017/09/01                       3\n",
      "2   AMZN       2020/06/26                       2\n",
      "3    XOM       2020/04/14                       2\n",
      "4    CVS       2020/04/14                       2\n",
      "  sector transaction_date  number_of_transactions\n",
      "0   AAPL       2021/10/29                       3\n",
      "1   TSLA       2021/03/22                       3\n",
      "2   GOOG       2020/04/17                       3\n",
      "3    RTX       2020/04/07                       3\n",
      "4   SBUX       2020/03/27                       3\n"
     ]
    }
   ],
   "source": [
    "def transaction_date_wrt_sector_controlled(group, diff):    \n",
    "    # d_prime = { ('ticker' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime = dict_utils.increment_set_in_inner_dictionary(d_prime, t[constants.TICKER], t[constants.TDATE], official.get_name(t))\n",
    "       \n",
    "    \n",
    "    d_prime = dict_utils.flatten_len(d_prime)\n",
    "\n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    \n",
    "    filename = \"transaction_date_wrt_sector_controlled\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff \n",
    "     \n",
    "    key_header = constants.SECTOR\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_sector_controlled(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_sector_controlled(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_sector_controlled(input_df, constants.INPUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                industry transaction_date  number_of_transactions\n",
      "0                   Fund       2020/10/09                      28\n",
      "1         Semiconductors       2020/07/13                      24\n",
      "2  Oil & Gas - Midstream       2020/06/10                      22\n",
      "3                  Banks       2020/03/18                      19\n",
      "4   Application Software       2020/02/13                      18\n",
      "                  industry transaction_date  number_of_transactions\n",
      "0                     Fund       2020/04/02                      27\n",
      "1    Oil & Gas - Midstream       2020/04/15                      16\n",
      "2            Entertainment       2020/04/14                      14\n",
      "3       Drug Manufacturers       2020/04/14                      11\n",
      "4  Consumer Packaged Goods       2020/04/07                      10\n",
      "                industry transaction_date  number_of_transactions\n",
      "0                   Fund       2020/04/02                      28\n",
      "1         Semiconductors       2020/07/13                      24\n",
      "2  Oil & Gas - Midstream       2020/06/10                      22\n",
      "3                  Banks       2020/03/18                      20\n",
      "4   Application Software       2020/02/13                      18\n"
     ]
    }
   ],
   "source": [
    "def transaction_date_wrt_industry(group, diff):    \n",
    "    # d_prime = {'industry' : {'date' : #_of_transactions, ....} , 'industry2' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            industry = dir_utils.search_mapping(industry_df, t[constants.TICKER], industry=True)\n",
    "\n",
    "            d_prime =  dict_utils.increment_dictionary_in_dictionary(d_prime, industry, (t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    filename = \"transaction_date_wrt_industry\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff  \n",
    "    key_header = constants.INDUSTRY\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_industry(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_industry(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_industry(input_df, constants.INPUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each industry controlling for official. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               industry transaction_date  number_of_transactions\n",
      "0  Application Software       2020/03/26                       6\n",
      "1   Brokers & Exchanges       2021/03/01                       4\n",
      "2   Aerospace & Defense       2020/04/03                       4\n",
      "3                  Fund       2020/03/10                       4\n",
      "4        Semiconductors       2021/11/18                       3\n",
      "            industry transaction_date  number_of_transactions\n",
      "0  Computer Hardware       2020/08/27                       3\n",
      "1  Health Care Plans       2020/04/14                       3\n",
      "2   Asset Management       2020/04/14                       3\n",
      "3    Credit Services       2020/04/14                       3\n",
      "4      Entertainment       2020/04/06                       3\n",
      "               industry transaction_date  number_of_transactions\n",
      "0  Application Software       2020/03/26                       7\n",
      "1         Entertainment       2020/04/06                       5\n",
      "2   Aerospace & Defense       2020/04/03                       5\n",
      "3                  Fund       2020/03/10                       5\n",
      "4   Brokers & Exchanges       2021/03/01                       4\n"
     ]
    }
   ],
   "source": [
    "def transaction_date_wrt_industry_controlled(group, diff):\n",
    "    \n",
    "    # d_prime = { ('ticker' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            industry = dir_utils.search_mapping(industry_df, t[constants.TICKER], industry=True)\n",
    "            \n",
    "            d_prime = dict_utils.increment_set_in_inner_dictionary(d_prime, industry, t[constants.TDATE],  official.get_name(t))\n",
    "\n",
    "    d_prime = dict_utils.flatten_len(d_prime)\n",
    "    \n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "    \n",
    "    filename = \"transaction_date_wrt_industry_controlled\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff  \n",
    "    key_header = constants.INDUSTRY\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_industry_controlled(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_industry_controlled(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_industry_controlled(input_df, constants.INPUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each ticker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ticker transaction_date  number_of_transactions\n",
      "0    RUN       2020/07/13                      24\n",
      "1   MSFT       2020/02/13                      18\n",
      "2     SO       2020/03/16                      16\n",
      "3    AMN       2020/09/02                       9\n",
      "4   CRWD       2021/10/01                       8\n",
      "  ticker transaction_date  number_of_transactions\n",
      "0   ECOM       2021/02/10                       8\n",
      "1      X       2021/05/06                       6\n",
      "2    OXY       2021/02/16                       6\n",
      "3    CLF       2021/07/21                       5\n",
      "4     AA       2021/01/06                       5\n",
      "  ticker transaction_date  number_of_transactions\n",
      "0    RUN       2020/07/13                      24\n",
      "1   MSFT       2020/02/13                      18\n",
      "2     SO       2020/03/16                      16\n",
      "3    AMN       2020/09/02                       9\n",
      "4   CRWD       2021/10/01                       8\n"
     ]
    }
   ],
   "source": [
    "def transaction_date_wrt_ticker(group, diff):    \n",
    "    # d_prime = {'ticker' : {'date' : #_of_transactions, ....} , 'ticker2' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime =  dict_utils.increment_dictionary_in_dictionary(d_prime, t[constants.TICKER], (t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    filename = \"transaction_date_wrt_ticker\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "    key_header = constants.TICKER\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_ticker(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_ticker(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_ticker(input_df, constants.INPUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each ticker controlling for official."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_ticker_controlled(group, diff):    \n",
    "    # d_prime = { ('ticker' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():    \n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):    \n",
    "            name = official.get_name(t)\n",
    "            d_prime = dict_utils.increment_set_in_inner_dictionary(d_prime, t[constants.TICKER], t[constants.TDATE], name)\n",
    "       \n",
    "    d_prime = dict_utils.flatten_len_inner_set(d_prime)\n",
    "\n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    \n",
    "    filename = \"transaction_date_wrt_ticker_controlled\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff  \n",
    "        \n",
    "    key_header = constants.TICKER\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_ticker_controlled(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_ticker_controlled(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_ticker_controlled(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             type transaction_date  number_of_transactions\n",
      "0        Purchase       2020/03/18                     204\n",
      "1     Sale (Full)       2019/06/24                     204\n",
      "2  Sale (Partial)       2020/11/13                      60\n",
      "3        Exchange       2020/02/24                      18\n",
      "             type transaction_date  number_of_transactions\n",
      "0     Sale (Full)       2020/04/14                     116\n",
      "1        Purchase       2017/03/16                      78\n",
      "2  Sale (Partial)       2020/04/14                      26\n",
      "3        Exchange       2017/09/01                       5\n",
      "             type transaction_date  number_of_transactions\n",
      "0        Purchase       2020/03/18                     212\n",
      "1     Sale (Full)       2019/06/24                     204\n",
      "2  Sale (Partial)       2020/11/13                      60\n",
      "3        Exchange       2020/02/24                      18\n"
     ]
    }
   ],
   "source": [
    "def transaction_date_wrt_type(group, diff):        \n",
    "    # d_prime = {'type' : {'date' : #_of_transactions, ....} , 'type2' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime =  dict_utils.increment_dictionary_in_dictionary(d_prime, ptr_utils.format_type(t[constants.TYPE]), (t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'type' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    filename = \"transaction_date_wrt_type\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff  \n",
    "    key_header = constants.TYPE\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df)\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_type(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_type(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_type(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for type controlling for official. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             type transaction_date  number_of_transactions\n",
      "0        Purchase       2020/11/13                      12\n",
      "1     Sale (Full)       2020/03/23                       9\n",
      "2  Sale (Partial)       2020/03/18                       6\n",
      "3        Exchange       2020/04/03                       5\n",
      "             type transaction_date  number_of_transactions\n",
      "0     Sale (Full)       2020/07/07                       4\n",
      "1        Purchase       2019/02/27                       4\n",
      "2  Sale (Partial)       2020/03/17                       3\n",
      "3        Exchange       2017/09/01                       3\n",
      "             type transaction_date  number_of_transactions\n",
      "0        Purchase       2021/01/15                      12\n",
      "1     Sale (Full)       2020/03/23                       9\n",
      "2  Sale (Partial)       2020/03/18                       7\n",
      "3        Exchange       2020/04/03                       6\n"
     ]
    }
   ],
   "source": [
    "def transaction_date_wrt_type_controlled(group, diff):    \n",
    "    # d_prime = { ('type' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime = dict_utils.increment_set_in_inner_dictionary(d_prime, t[constants.TYPE], (t[constants.TDATE]), official.get_name(t))\n",
    "       \n",
    "\n",
    "    d_prime = dict_utils.flatten_len(d_prime)\n",
    "            \n",
    "    # d = {'type' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "    \n",
    "    \n",
    "    filename = \"transaction_date_wrt_type_controlled\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff  \n",
    "    key_header = constants.TYPE\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_type_controlled(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_type_controlled(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_type_controlled(input_df, constants.INPUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                type  2020/03/18  2020/07/13  2020/11/17  2020/11/19  \\\n",
      "0           $1,001 -           0          12           0           0   \n",
      "1   $1,001 - $15,000         257           0           0           0   \n",
      "2   $1,000 - $15,000           0           0           0           0   \n",
      "3  $15,001 - $50,000           0           0           0          68   \n",
      "4  $15,000 - $50,000           0           0           0           0   \n",
      "\n",
      "   2021/01/19  2021/02/12  2021/04/09  2021/04/27  2021/05/20  2021/08/16  \\\n",
      "0           0           0           0           0           0           0   \n",
      "1           0           0           0           0           0           0   \n",
      "2           0           0           0           0           4           0   \n",
      "3           0           0           0           0           0           0   \n",
      "4           0           0           0           0           3           0   \n",
      "\n",
      "   2021/11/15  sort_key  \n",
      "0           0      1001  \n",
      "1           0     15000  \n",
      "2           0     15000  \n",
      "3           0     50000  \n",
      "4           0     50000  \n",
      "                  type  2015/02/13  2015/02/20  2020/03/11  2020/04/07  \\\n",
      "0     $1,001 - $15,000          96           0           0           0   \n",
      "1    $15,001 - $50,000           0           0           0           0   \n",
      "2   $50,001 - $100,000           0           0           0           0   \n",
      "3  $100,001 - $250,000           0           0           0          43   \n",
      "4  $250,001 - $500,000           0           0           0           8   \n",
      "\n",
      "   2020/04/14  2020/05/20  2021/11/01  sort_key  \n",
      "0           0           0           0     15000  \n",
      "1          69           0           0     50000  \n",
      "2          23           0           0    100000  \n",
      "3           0           0           0    250000  \n",
      "4           0           0           0    500000  \n",
      "                type  2015/02/20  2020/03/11  2020/03/18  2020/04/07  \\\n",
      "0           $1,001 -           0           0           0           0   \n",
      "1   $1,001 - $15,000           0           0         265           0   \n",
      "2   $1,000 - $15,000           0           0           0           0   \n",
      "3  $15,001 - $50,000           0           0           0           0   \n",
      "4  $15,000 - $50,000           0           0           0           0   \n",
      "\n",
      "   2020/04/14  2020/07/13  2021/02/12  2021/04/27  2021/05/20  2021/08/16  \\\n",
      "0           0          12           0           0           0           0   \n",
      "1           0           0           0           0           0           0   \n",
      "2           0           0           0           0           4           0   \n",
      "3          70           0           0           0           0           0   \n",
      "4           0           0           0           0           3           0   \n",
      "\n",
      "   sort_key  \n",
      "0      1001  \n",
      "1     15000  \n",
      "2     15000  \n",
      "3     50000  \n",
      "4     50000  \n"
     ]
    }
   ],
   "source": [
    "def transaction_date_wrt_amount(group, diff):\n",
    "    # d_prime = {'amount' : {'date' : #_of_transactions, ....} , 'amount1' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime =  dict_utils.increment_dictionary_in_dictionary(d_prime, t[constants.AMOUNT], (t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'type' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "    d = dict_utils.add_sort_key_for_amount(d)\n",
    "    d = dict_utils.sort_dictionary_by_sort_key(d)\n",
    "\n",
    "    filename = \"transaction_date_wrt_amount\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff  \n",
    "    key_header = constants.TYPE\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, key_header)\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_amount(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_amount(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_amount(input_df, constants.INPUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for amount controlling for official."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              amount  2020/01/09  2020/03/13  2020/03/18  2020/08/07  \\\n",
      "0           $1,001 -           0           0           0           0   \n",
      "1   $1,001 - $15,000           0           0          13           0   \n",
      "2   $1,000 - $15,000           0           0           0           0   \n",
      "3  $15,001 - $50,000           0           0           0           0   \n",
      "4  $15,000 - $50,000           0           0           0           0   \n",
      "\n",
      "   2020/09/02  2020/11/17  2021/01/04  2021/01/15  2021/01/22  2021/02/16  \\\n",
      "0           0           0           0           0           0           0   \n",
      "1           0           0           0           0           0           0   \n",
      "2           0           0           0           0           0           0   \n",
      "3           0           0           0           0           0           8   \n",
      "4           0           0           0           0           0           0   \n",
      "\n",
      "   2021/02/22  2021/05/20  sort_key  \n",
      "0           2           0      1001  \n",
      "1           0           0     15000  \n",
      "2           0           1     15000  \n",
      "3           0           0     50000  \n",
      "4           0           1     50000  \n",
      "                amount  2015/02/20  2015/10/05  2016/02/11  2016/08/12  \\\n",
      "0              Unknown           0           0           0           3   \n",
      "1     $1,001 - $15,000           0           0           5           0   \n",
      "2    $15,001 - $50,000           0           0           0           0   \n",
      "3   $50,001 - $100,000           0           0           0           0   \n",
      "4  $100,001 - $250,000           0           0           0           0   \n",
      "\n",
      "   2017/02/01  2018/12/27  2019/10/11  2020/07/31  2021/03/01  2021/07/23  \\\n",
      "0           0           0           0           0           0           0   \n",
      "1           0           0           0           0           0           0   \n",
      "2           5           0           0           0           0           0   \n",
      "3           0           0           0           3           0           0   \n",
      "4           0           3           0           0           0           0   \n",
      "\n",
      "   2021/11/08  sort_key  \n",
      "0           0        -1  \n",
      "1           0     15000  \n",
      "2           0     50000  \n",
      "3           0    100000  \n",
      "4           0    250000  \n",
      "              amount  2015/02/20  2015/10/05  2016/08/12  2020/01/09  \\\n",
      "0            Unknown           0           0           3           0   \n",
      "1           $1,001 -           0           0           0           0   \n",
      "2   $1,001 - $15,000           0           0           0           0   \n",
      "3   $1,000 - $15,000           0           0           0           0   \n",
      "4  $15,001 - $50,000           0           0           0           0   \n",
      "\n",
      "   2020/03/13  2020/11/16  2021/01/04  2021/01/15  2021/01/22  2021/02/16  \\\n",
      "0           0           0           0           0           0           0   \n",
      "1           0           0           0           0           0           0   \n",
      "2           0          15           0           0           0           0   \n",
      "3           0           0           0           0           0           0   \n",
      "4           0           0           0           0           0          10   \n",
      "\n",
      "   2021/02/22  2021/03/01  2021/05/20  2021/07/23  2021/11/08  sort_key  \n",
      "0           0           0           0           0           0        -1  \n",
      "1           2           0           0           0           0      1001  \n",
      "2           0           0           0           0           0     15000  \n",
      "3           0           0           1           0           0     15000  \n",
      "4           0           0           0           0           0     50000  \n"
     ]
    }
   ],
   "source": [
    "def transaction_date_wrt_amount_controlled(group, diff):\n",
    "    # d_prime = { ('amount' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "       d_prime = dict_utils.increment_set_in_inner_dictionary(d_prime, t[constants.AMOUNT], (t[constants.TDATE]), official.get_name(t))\n",
    "       \n",
    "\n",
    "    d_prime = dict_utils.flatten_len(d_prime)\n",
    "        \n",
    "    # d = {'amount' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "    d = dict_utils.add_sort_key_for_amount(d)\n",
    "    d = dict_utils.sort_dictionary_by_sort_key(d)\n",
    "    \n",
    "    \n",
    "    filename = \"transaction_date_wrt_amount_controlled\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff  \n",
    "    key_header = constants.AMOUNT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, key_header)\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_amount_controlled(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_amount_controlled(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_amount_controlled(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each official."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            official transaction_date  number_of_transactions\n",
      "0     Shalala, Donna       2019/06/24                     204\n",
      "1  Cisneros, Gilbert       2020/03/18                     160\n",
      "2      Meijer, Peter       2021/02/16                     150\n",
      "3     Phillips, Dean       2020/04/02                     114\n",
      "4    Sherrill, Mikie       2020/02/20                     113\n",
      "               official transaction_date  number_of_transactions\n",
      "0       Loeffler, Kelly       2020/04/07                     111\n",
      "1  Perdue Jr., David A.       2020/04/14                     110\n",
      "2     Tillis, Thomas R.       2015/02/13                      93\n",
      "3         Murray, Patty       2017/06/15                      83\n",
      "4     Collins, Susan M.       2014/05/07                      64\n",
      "            official transaction_date  number_of_transactions\n",
      "0     Shalala, Donna       2019/06/24                     204\n",
      "1  Cisneros, Gilbert       2020/03/18                     160\n",
      "2      Meijer, Peter       2021/02/16                     150\n",
      "3     Phillips, Dean       2020/04/02                     114\n",
      "4    Sherrill, Mikie       2020/02/20                     113\n"
     ]
    }
   ],
   "source": [
    "def transaction_date_wrt_official(group, diff):\n",
    "    # d_prime = {'person1' : {'date' : #_of_transactions, ....} , 'person2' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime =  dict_utils.increment_dictionary_in_dictionary(d_prime, official.get_name(t), (t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'person' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    filename = \"transaction_date_wrt_official\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff \n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [constants.OFFICIAL, constants.TDATE, constants.NUMT])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "transaction_date_wrt_official_res = transaction_date_wrt_official(house_input_df, constants.HOUSE)\n",
    "transaction_date_wrt_official_res = transaction_date_wrt_official(senate_input_df, constants.SENATE)\n",
    "transaction_date_wrt_official_res = transaction_date_wrt_official(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_per_date(group):\n",
    "    d={}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        d =  dict_utils.increment_dictionary(d, (t[constants.TDATE]))\n",
    "\n",
    "    return d \n",
    "\n",
    "d1 = num_of_trans_per_date(house_input_df)\n",
    "d2 = num_of_trans_per_date(senate_input_df)\n",
    "d3 = num_of_trans_per_date(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_per_date\", (d1,d2,d3), [constants.TDATE, constants.HOUSE, constants.SENATE, constants.INPUT])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Transactions per Date Controlled\n",
    "_Number of transactions per date controlled by official. E.g. if Ted Baker made 40 transactions on 1/1/02 and Sam Wall made 2 transactions on 1/1/02, we conclude that there were two transactions on 1/1/02._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_per_date_controlled(group):    \n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        d =  dict_utils.increment_dictionary_in_dictionary(d, (t[constants.TDATE]), official.get_name(t))\n",
    "\n",
    "    return dict_utils.flatten_len(d, inner_set=True)\n",
    "    \n",
    "d1 = num_of_trans_per_date_controlled(house_input_df)\n",
    "d2 = num_of_trans_per_date_controlled(senate_input_df)\n",
    "d3 = num_of_trans_per_date_controlled(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_per_date_controlled\", (d1,d2,d3), [constants.TDATE, constants.HOUSE, constants.SENATE, constants.INPUT])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Transactions Within 2 Weeks Prior to Quarterly Tax Date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_within_tax_date(group):        \n",
    "        total = within = 0 \n",
    "        d = {}\n",
    "\n",
    "        for _,t in group.iterrows():  \n",
    "                total += 1 \n",
    "                if ptr_utils.within_tax_date(t[constants.TDATE]):\n",
    "                        within += 1 \n",
    "\n",
    "        d[\"(No. of transactions within 2 weeks of tax deadline, %)\"] = (within,  ptr_utils.make_percent(within, total))\n",
    "\n",
    "        return d \n",
    "\n",
    "d1 = num_of_trans_within_tax_date(house_input_df)\n",
    "d2 = num_of_trans_within_tax_date(senate_input_df)\n",
    "d3 = num_of_trans_within_tax_date(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_within_tax_date\", (d1,d2,d3), [\"\", constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Transactions Within 2 Weeks Prior to Quarterly Tax Date Semi-Controlled \n",
    "\n",
    "_Given dict='09/03/2021': {'Thomas H Tuberville': 1, 'Cynthia M Lummis': 1, 'A. Mitchell Mcconnell, Jr.': 1}...I only incremement the number of within (tax date) once per date per official. So, if an official does 100 transactions on a date within two weeks of a quarterly deadline, then I only count it as one transaction._\n",
    "\n",
    "_A Note: total === number of transactions per person per date (so not really all transactions) because someone could have potentially made 60 transactions on one date which we don't include in neither total or within, if applicable._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_within_tax_date_controlled(group):\n",
    "        total = within = 0 \n",
    "        people = set()\n",
    "        d = {}\n",
    "\n",
    "        for _, t in group.iterrows():\n",
    "                name = official.get_name(t)\n",
    "                if ptr_utils.within_tax_date(t[constants.TDATE]) and name not in people:\n",
    "                        people.add(name)\n",
    "                        within += 1 \n",
    "                total += 1         \n",
    "                \n",
    "        d[\"(No. of transactions within 2 weeks of tax deadline, %)\"] = (within,  ptr_utils.make_percent(within, total))\n",
    "\n",
    "        return d\n",
    "\n",
    "d1 = num_of_trans_within_tax_date_controlled(house_input_df)\n",
    "d2 = num_of_trans_within_tax_date_controlled(senate_input_df)\n",
    "d3 = num_of_trans_within_tax_date_controlled(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_within_tax_date_controlled\", (d1,d2,d3), [\"\", constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def people_and_within_tax_date(people):        \n",
    "#         # todo get number of senators. \n",
    "#         # todo is the monetary value of that equal!!!! \n",
    "#         d = {}\n",
    "#         for i in people:\n",
    "#                 d[i] = \"\"\n",
    "                \n",
    "#         d = dict_utils.sort_dictionary_by_keys(d)\n",
    "        \n",
    "#         dir = dir_utils.makesubdir(constants.path_csv, \"transaction_date/tax\")\n",
    "#         wd = csv_utils.make_csv(dir, \"people_and_within_tax_date_list\", d, [\"Officials\"])\n",
    "#         df = pd.read_csv(wd)\n",
    "#         print(\"People who posted transactions within two weeks of quarterly tax deadline:\\n {}\\n\".format(df.head(5)))\n",
    "\n",
    "#         print(\"Number of people who posted transactions within two weeks of quarterly tax deadline: {}\\n\".format(len(people)))\n",
    "        \n",
    "#         party = {}\n",
    "#         for p in people:\n",
    "#                 link = search.get_wiki_link(p)\n",
    "#                 _, obj = input_officials_objects[link]\n",
    "#                 party =  dict_utils.increment_dictionary(party, obj.party)\n",
    "                \n",
    "#         party = dict_utils.sort_dictionary_by_values(party)\n",
    "        \n",
    "#         wd = csv_utils.make_csv(dir, \"people_and_within_tax_date_list_w_aff\", party, [\"party\", \"number_of_filing_within_tax_date\"])\n",
    "#         df = pd.read_csv(wd)\n",
    "#         print(\"Party breakdown of people who posted transactions within two weeks of quarterly tax deadline:\\n {}\\n\".format(df.head(5)))\n",
    "\n",
    "# people_and_within_tax_date(num_of_trans_within_tax_date_controlled_res_house)\n",
    "# people_and_within_tax_date(num_of_trans_within_tax_date_controlled_res_senate)\n",
    "# people_and_within_tax_date(num_of_trans_within_tax_date_controlled_res_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def people_and_within_tax_date_how_often(people):\n",
    "\n",
    "#         d = {}\n",
    "#         d_controlled_by_dates = {}\n",
    "        \n",
    "#         for _,t in input_df.iterrows():\n",
    "#                 if official.get_canonical_name(t[title]) in people and ptr_utils.within_tax_date(t[constants.TDATE]):\n",
    "#                         d =  dict_utils.increment_dictionary(d, t[title])\n",
    "#                         d_controlled_by_dates =  dict_utils.increment_dictionary_in_dictionary(d_controlled_by_dates, t[constants.TDATE], t[title])\n",
    "\n",
    "#         d_controlled_by_dates_res  = {}\n",
    "#         for date in d_controlled_by_dates:\n",
    "#                 for person in d_controlled_by_dates[date]:\n",
    "#                         d_controlled_by_dates_res =  dict_utils.increment_dictionary(d_controlled_by_dates_res, person)\n",
    "\n",
    "#         d = dict_utils.sort_dictionary_by_values(d)\n",
    "#         d_controlled_by_dates_res = dict_utils.sort_dictionary_by_values(d_controlled_by_dates_res)\n",
    "\n",
    "#         dir = dir_utils.makesubdir(constants.path_csv, \"transaction_date/tax\")\n",
    "#         wd = csv_utils.make_csv(dir, \"people_and_within_tax_date_how_often\", d, [title, \"number_of_filing_within_tax_date\"])\n",
    "#         df = pd.read_csv(wd)\n",
    "#         print(\"People who posted transactions within two weeks of quarterly tax deadline and the number of transactions posted:\\n {}\\n\".format(df.head(5)))\n",
    "\n",
    "#         wd = csv_utils.make_csv(dir, \"people_and_within_tax_date_how_often_date_controlled\", d_controlled_by_dates_res, [title, \"number_of_filing_within_tax_date_date_controlled\"])\n",
    "#         df = pd.read_csv(wd)\n",
    "#         print(\"People who posted transactions within two weeks of quarterly tax deadline and the number of transactions posted controlled by date:\\n {}\\n\".format(df.head(5)))\n",
    "\n",
    "          \n",
    "# people_and_within_tax_date_how_often(num_of_trans_within_tax_date_controlled_res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Owner (owner) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Count of Owner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_count_of_owner(group):\n",
    "    # d = {'Joint' : 5}\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if constants.OWNER in t and ptr_utils.isvalid(t[constants.OWNER]) :\n",
    "            d =  dict_utils.increment_dictionary(d, t[constants.OWNER].capitalize())\n",
    "        \n",
    "    return dict_utils.sort_dictionary_by_values(d)\n",
    "    \n",
    "    \n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "d1 = freq_count_of_owner(house_input_df)\n",
    "d2 = freq_count_of_owner(senate_input_df)\n",
    "\n",
    "# {link : (canonical_name_input_based, official_object) ... }\n",
    "d3 = freq_count_of_owner(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.OWNER)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"freq_count_of_owner\", (d1,d2,d3), [\"Owner\", constants.HOUSE, constants.SENATE, constants.INPUT]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_count_by_spouse(group):\n",
    "    # d = {'x_spouse' : 5}\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if constants.OWNER in t and ptr_utils.isvalid(t[constants.OWNER]) and t[constants.OWNER].capitalize() == 'Spouse':\n",
    "            d =  dict_utils.increment_dictionary(d, official.get_name(t))\n",
    "        \n",
    "    return d\n",
    "    \n",
    "    \n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "d1 = freq_count_by_spouse(house_input_df)\n",
    "d2 = freq_count_by_spouse(senate_input_df)\n",
    "\n",
    "# {link : (canonical_name_input_based, official_object) ... }\n",
    "d3 = freq_count_by_spouse(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.OWNER)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"freq_count_by_spouse\", (d1,d2,d3), [\"Owner\", constants.HOUSE, constants.SENATE, constants.INPUT]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ticker (ticker) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_tickers(group):\n",
    "    # d = {'ticker' : #_of_times }\n",
    "    d = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d =  dict_utils.increment_dictionary(d, t[constants.TICKER])\n",
    "       \n",
    "\n",
    "    return dict_utils.sort_dictionary_by_values(d, reverse=True)\n",
    "\n",
    "d1 = num_of_tickers(house_input_df)\n",
    "d2 = num_of_tickers(senate_input_df)\n",
    "d3 = num_of_tickers(input_df)\n",
    "    \n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.TICKER)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_tickers\", (d1,d2,d3), [constants.TICKER, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Ticker per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ticker  2018  2019  2020  2021  9999\n",
      "0  35G.SG     0     0     0     2     2\n",
      "1     7XY     0     0     0     1     1\n",
      "    ticker  2012  2013  2014  2015  2016  2017  2018  2019  2020  2021  9999\n",
      "0  0QZI.IL     0     0     0     0     0     0     0     2     0     0     2\n",
      "1  3V64.TI     0     0     0     0     0     0     0     2     0     0     2\n",
      "    ticker  2012  2013  2014  2015  2016  2017  2018  2019  2020  2021  9999\n",
      "0  0QZI.IL     0     0     0     0     0     0     0     2     0     0     2\n",
      "1   35G.SG     0     0     0     0     0     0     0     0     0     2     2\n"
     ]
    }
   ],
   "source": [
    "def frequency_of_ticker_breakdown_year(group, diff):\n",
    "    d = {}\n",
    "\n",
    "    # {\"ticker\" : {\"year\" : number, \"year\" : number, ...}}\n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d = dict_utils.increment_dictionary_in_dictionary(d, t[constants.TICKER], ptr_utils.get_year(t[constants.TDATE]))\n",
    "            d = dict_utils.increment_dictionary_in_dictionary(d, t[constants.TICKER], 9999)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_keys(d)\n",
    "    filename = \"frequency_of_ticker_breakdown_year\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "    key_header = constants.TICKER\n",
    "    \n",
    "    \n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TICKER)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "\n",
    "frequency_of_ticker_breakdown_year(house_input_df, constants.HOUSE)\n",
    "frequency_of_ticker_breakdown_year(senate_input_df, constants.SENATE)\n",
    "frequency_of_ticker_breakdown_year(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Ticker per Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ticker  2018/12/27  2019/01/09  2019/01/10  2019/01/15  2019/01/23  \\\n",
      "0     BP           0           0           0           0           0   \n",
      "1    XOM           0           0           0           0           0   \n",
      "\n",
      "   2019/01/30  2019/02/01  2019/02/05  2019/02/06  ...  2021/12/15  \\\n",
      "0           0           0           0           0  ...           0   \n",
      "1           0           0           0           0  ...           0   \n",
      "\n",
      "   2021/12/16  2021/12/17  2021/12/20  2021/12/21  2021/12/22  2021/12/23  \\\n",
      "0           0           0           0           0           0           0   \n",
      "1           0           0           0           0           0           0   \n",
      "\n",
      "   2021/12/28  2021/12/30  2021/12/31  \n",
      "0           0           0           0  \n",
      "1           0           0           0  \n",
      "\n",
      "[2 rows x 479 columns]\n",
      "  ticker  2013/04/29  2013/05/01  2014/01/29  2014/02/06  2014/02/19  \\\n",
      "0    NVS           0           0           0           0           0   \n",
      "1     VZ           0           0           0           0           0   \n",
      "\n",
      "   2014/02/21  2014/02/27  2014/03/13  2014/03/28  ...  2021/11/17  \\\n",
      "0           0           0           0           0  ...           0   \n",
      "1           0           0           0           0  ...           0   \n",
      "\n",
      "   2021/11/29  2021/12/01  2021/12/15  2021/12/16  2021/12/21  2021/12/23  \\\n",
      "0           0           0           1           0           0           0   \n",
      "1           0           0           0           0           0           0   \n",
      "\n",
      "   2021/12/28  2021/12/29  2021/12/31  \n",
      "0           0           0           0  \n",
      "1           0           0           0  \n",
      "\n",
      "[2 rows x 492 columns]\n",
      "  ticker  2013/04/29  2013/05/01  2014/01/29  2014/02/06  2014/02/21  \\\n",
      "0    NVS           0           0           0           0           0   \n",
      "1     VZ           0           0           0           0           0   \n",
      "\n",
      "   2014/02/27  2014/03/13  2014/03/28  2014/04/03  ...  2021/12/15  \\\n",
      "0           0           0           0           0  ...           0   \n",
      "1           0           0           0           0  ...           0   \n",
      "\n",
      "   2021/12/16  2021/12/17  2021/12/20  2021/12/21  2021/12/22  2021/12/23  \\\n",
      "0           0           0           0           0           0           0   \n",
      "1           0           0           0           0           0           0   \n",
      "\n",
      "   2021/12/28  2021/12/29  2021/12/31  \n",
      "0           0           0           0  \n",
      "1           0           0           0  \n",
      "\n",
      "[2 rows x 761 columns]\n"
     ]
    }
   ],
   "source": [
    "def frequency_of_ticker_by_date(group, diff):\n",
    "    # {ticker : {date : ___}}\n",
    "    d = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d = dict_utils.increment_dictionary_in_dictionary(d, t[constants.TICKER], t[constants.TDATE])\n",
    "\n",
    "    \n",
    "    d = dict_utils.flatten_best(d)\n",
    "    \n",
    "\n",
    "    filename = \"frequency_of_ticker_by_date\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "    \n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TICKER)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, constants.TICKER)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "\n",
    "d1 = frequency_of_ticker_by_date(house_input_df, constants.HOUSE)\n",
    "d2 = frequency_of_ticker_by_date(senate_input_df, constants.SENATE)\n",
    "d3 = frequency_of_ticker_by_date(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Industry & Sector "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Transactions per Industry\n",
    "_Not controlled in any way._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_transactions_per_indusry(group):        \n",
    "    d = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            industry = dir_utils.search_mapping(industry_df, t[constants.TICKER], industry=True)\n",
    "            d = dict_utils.increment_dictionary(d, industry)\n",
    "\n",
    "    return dict_utils.sort_dictionary_by_values(d)\n",
    "    \n",
    "\n",
    "d1 = number_of_transactions_per_indusry(house_input_df)\n",
    "d2 = number_of_transactions_per_indusry(senate_input_df)\n",
    "d3 = number_of_transactions_per_indusry(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.INDUSTRY)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"number_of_transactions_per_indusry\", (d1,d2,d3), [constants.INDUSTRY, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "\n",
    "\n",
    "def number_of_transactions_per_sector(group):        \n",
    "    d = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            sector = dir_utils.search_mapping(sector_df, t[constants.TICKER], sector=True)\n",
    "            d = dict_utils.increment_dictionary(d, sector)\n",
    "\n",
    "    return dict_utils.sort_dictionary_by_values(d)\n",
    "    \n",
    "\n",
    "d1 = number_of_transactions_per_sector(house_input_df)\n",
    "d2 = number_of_transactions_per_sector(senate_input_df)\n",
    "d3 = number_of_transactions_per_sector(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.SECTOR)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"number_of_transactions_per_sector\", (d1,d2,d3), [constants.SECTOR, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Industry Breakdown per Official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            official  Advertising & Marketing Services  Advertising Agencies  \\\n",
      "0  Allen, Richard W.                                 0                     0   \n",
      "1      Amash, Justin                                 0                     0   \n",
      "\n",
      "   Aerospace & Defense  Agricultural Inputs  Agriculture  Airlines  \\\n",
      "0                    1                    0            0         0   \n",
      "1                    0                    0            0         0   \n",
      "\n",
      "   Apparel Manufacturing  Apparel Retail  Application Software  ...  Trust  \\\n",
      "0                      0               0                     1  ...      0   \n",
      "1                      0               0                     0  ...      0   \n",
      "\n",
      "   Utilities - Independent Power Producers  Utilities - Regulated  \\\n",
      "0                                        0                      3   \n",
      "1                                        0                      0   \n",
      "\n",
      "   Utilities - Regulated Water  UtilitiesDiversified  \\\n",
      "0                            0                      0   \n",
      "1                            0                      0   \n",
      "\n",
      "   UtilitiesRegulated Electric  UtilitiesRegulated Gas  \\\n",
      "0                             0                        0   \n",
      "1                             0                        0   \n",
      "\n",
      "   UtilitiesRegulated Water  UtilitiesRenewable  Waste Management  \n",
      "0                          0                    0                 0  \n",
      "1                          0                    0                 0  \n",
      "\n",
      "[2 rows x 181 columns]\n",
      "             official  Advertising & Marketing Services  Aerospace & Defense  \\\n",
      "0  Bennet, Michael F.                                 0                    0   \n",
      "1       Blunt, Roy D.                                 0                    0   \n",
      "\n",
      "   Aerospace/Defense  Agricultural Inputs  Agriculture  Airlines  \\\n",
      "0                  0                    0            0         0   \n",
      "1                  0                    0            0         0   \n",
      "\n",
      "   Apparel Manufacturing  Application Software  Asset Management  ...  \\\n",
      "0                      0                     0                 0  ...   \n",
      "1                      0                     0                 0  ...   \n",
      "\n",
      "   Travel & Leisure  Travel Services  Truck Manufacturing  Trust  Utilities  \\\n",
      "0                 0                0                    0      0          0   \n",
      "1                 0                0                    0      0          0   \n",
      "\n",
      "   Utilities - Independent Power Producers  Utilities - Regulated  \\\n",
      "0                                        0                      0   \n",
      "1                                        0                      0   \n",
      "\n",
      "   Utilities--Regulated Electric  UtilitiesRenewable  Waste Management  \n",
      "0                              0                    0                 0  \n",
      "1                              0                    0                 0  \n",
      "\n",
      "[2 rows x 147 columns]\n",
      "            official  Advertising & Marketing Services  Advertising Agencies  \\\n",
      "0  Allen, Richard W.                                 0                     0   \n",
      "1      Amash, Justin                                 0                     0   \n",
      "\n",
      "   Aerospace & Defense  Aerospace/Defense  Agricultural Inputs  Agriculture  \\\n",
      "0                    1                  0                    0            0   \n",
      "1                    0                  0                    0            0   \n",
      "\n",
      "   Airlines  Apparel Manufacturing  Apparel Retail  ...  \\\n",
      "0         0                      0               0  ...   \n",
      "1         0                      0               0  ...   \n",
      "\n",
      "   Utilities - Independent Power Producers  Utilities - Regulated  \\\n",
      "0                                        0                      3   \n",
      "1                                        0                      0   \n",
      "\n",
      "   Utilities - Regulated Water  Utilities--Regulated Electric  \\\n",
      "0                            0                              0   \n",
      "1                            0                              0   \n",
      "\n",
      "   UtilitiesDiversified  UtilitiesRegulated Electric  \\\n",
      "0                      0                             0   \n",
      "1                      0                             0   \n",
      "\n",
      "   UtilitiesRegulated Gas  UtilitiesRegulated Water  UtilitiesRenewable  \\\n",
      "0                        0                          0                    0   \n",
      "1                        0                          0                    0   \n",
      "\n",
      "   Waste Management  \n",
      "0                 0  \n",
      "1                 0  \n",
      "\n",
      "[2 rows x 208 columns]\n",
      "            official  Banks - Regional  Basic Materials  \\\n",
      "0  Allen, Richard W.                 0                5   \n",
      "1      Amash, Justin                 0                0   \n",
      "\n",
      "   Communication Services  Communications  Consumer Cyclical  \\\n",
      "0                       1               0                  4   \n",
      "1                       0               0                  3   \n",
      "\n",
      "   Consumer Defensive  Consumer Staples  Cryptocurrency  Energy  ...  \\\n",
      "0                   2                 0               0       0  ...   \n",
      "1                   0                 0               0       0  ...   \n",
      "\n",
      "   Induistrial  Industrials  Information Technology  Medical  Real Estate  \\\n",
      "0            0            6                       0        0            0   \n",
      "1            0            0                       0        0            0   \n",
      "\n",
      "   Retail/Wholesale  Services  Technology  Trust  Utilities  \n",
      "0                 0         0           2      0          3  \n",
      "1                 0         0           0      0          0  \n",
      "\n",
      "[2 rows x 23 columns]\n",
      "             official  Basic Materials  Communication Services  \\\n",
      "0  Bennet, Michael F.                0                       0   \n",
      "1       Blunt, Roy D.                0                       0   \n",
      "\n",
      "   Communications  Consumer Cyclical  Consumer Defensive  \\\n",
      "0               0                  2                   0   \n",
      "1               0                  0                   3   \n",
      "\n",
      "   Consumer Discretionary  Consumer Goods  Cryptocurrency  Energy  ...  Fund  \\\n",
      "0                       0               0               0       0  ...     0   \n",
      "1                       0               0               0       0  ...     0   \n",
      "\n",
      "   Healthcare  Industrial Goods  Industrials  Oil & Gas Storage & Trpor  \\\n",
      "0           0                 0            0                          0   \n",
      "1           0                 0            0                          0   \n",
      "\n",
      "   Real Estate  Services  Technology  Trust  Utilities  \n",
      "0            0         0           1      0          0  \n",
      "1            0         0           1      0          0  \n",
      "\n",
      "[2 rows x 22 columns]\n",
      "            official  Banks - Regional  Basic Materials  \\\n",
      "0  Allen, Richard W.                 0                5   \n",
      "1      Amash, Justin                 0                0   \n",
      "\n",
      "   Communication Services  Communications  Consumer Cyclical  \\\n",
      "0                       1               0                  4   \n",
      "1                       0               0                  3   \n",
      "\n",
      "   Consumer Defensive  Consumer Discretionary  Consumer Goods  \\\n",
      "0                   2                       0               0   \n",
      "1                   0                       0               0   \n",
      "\n",
      "   Consumer Staples  ...  Industrials  Information Technology  Medical  \\\n",
      "0                 0  ...            6                       0        0   \n",
      "1                 0  ...            0                       0        0   \n",
      "\n",
      "   Oil & Gas Storage & Trpor  Real Estate  Retail/Wholesale  Services  \\\n",
      "0                          0            0                 0         0   \n",
      "1                          0            0                 0         0   \n",
      "\n",
      "   Technology  Trust  Utilities  \n",
      "0           2      0          3  \n",
      "1           0      0          0  \n",
      "\n",
      "[2 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "def frequency_of_industry_breakdown_official(group, diff):\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            industry = dir_utils.search_mapping(industry_df, t[constants.TICKER], industry=True)\n",
    "            d = dict_utils.increment_dictionary_in_dictionary(d, official.get_name(t), industry)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_keys(d)\n",
    "    \n",
    "    filename = \"frequency_of_industry_breakdown_official\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.INDUSTRY)\n",
    "\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, constants.OFFICIAL)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "    \n",
    "    return d \n",
    "\n",
    "d1 = frequency_of_industry_breakdown_official(house_input_df, constants.HOUSE)\n",
    "d2 = frequency_of_industry_breakdown_official(senate_input_df, constants.SENATE)\n",
    "d3 = frequency_of_industry_breakdown_official(input_df, constants.INPUT)\n",
    "\n",
    "\n",
    "\n",
    "def frequency_of_sector_breakdown_official(group, diff):\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            sector = dir_utils.search_mapping(sector_df, t[constants.TICKER], sector=True)\n",
    "            d = dict_utils.increment_dictionary_in_dictionary(d, official.get_name(t), sector)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_keys(d)\n",
    "    \n",
    "    filename = \"frequency_of_sector_breakdown_official\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.SECTOR)\n",
    "\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, constants.OFFICIAL)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "    \n",
    "    return d \n",
    "\n",
    "d1 = frequency_of_sector_breakdown_official(house_input_df, constants.HOUSE)\n",
    "d2 = frequency_of_sector_breakdown_official(senate_input_df, constants.SENATE)\n",
    "d3 = frequency_of_sector_breakdown_official(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency of Industry per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           industry  2018  2019  2020  2021\n",
      "0  Advertising & Marketing Services     0     3     6     1\n",
      "1              Advertising Agencies     0     5     5     0\n",
      "                           industry  2012  2013  2014  2015  2016  2017  2018  \\\n",
      "0  Advertising & Marketing Services     0     0     0     1     0     0     0   \n",
      "1               Aerospace & Defense     0     0    15    12     8    19    33   \n",
      "\n",
      "   2019  2020  2021  \n",
      "0     0     0     0  \n",
      "1    37    28     4  \n",
      "                           industry  2012  2013  2014  2015  2016  2017  2018  \\\n",
      "0  Advertising & Marketing Services     0     0     0     1     0     0     0   \n",
      "1              Advertising Agencies     0     0     0     0     0     0     0   \n",
      "\n",
      "   2019  2020  2021  \n",
      "0     3     6     1  \n",
      "1     5     5     0  \n",
      "             sector  2018  2019  2020  2021\n",
      "0  Banks - Regional     0     0     1     0\n",
      "1   Basic Materials     0    52   177   143\n",
      "                   sector  2012  2013  2014  2015  2016  2017  2018  2019  \\\n",
      "0         Basic Materials     2     4    20    16    48    73    64    36   \n",
      "1  Communication Services     0     0    23     9    11    38    52    50   \n",
      "\n",
      "   2020  2021  \n",
      "0    57    63  \n",
      "1    58     9  \n",
      "             sector  2012  2013  2014  2015  2016  2017  2018  2019  2020  \\\n",
      "0  Banks - Regional     0     0     0     0     0     0     0     0     1   \n",
      "1   Basic Materials     2     4    20    16    48    73    64    88   234   \n",
      "\n",
      "   2021  \n",
      "0     0  \n",
      "1   206  \n"
     ]
    }
   ],
   "source": [
    "def frequency_of_industry_breakdown(group, diff):\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():     \n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            industry = dir_utils.search_mapping(industry_df, t[constants.TICKER], industry=True)  \n",
    "            d = dict_utils.increment_dictionary_in_dictionary(d, industry, ptr_utils.get_year(t[constants.TDATE]))\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_keys(d)\n",
    "    \n",
    "    filename = \"frequency_of_industry_breakdown\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff \n",
    "    key_header = \"industry\"\n",
    "    \n",
    "    \n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.INDUSTRY)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "    return d \n",
    "\n",
    "d1 = frequency_of_industry_breakdown(house_input_df, constants.HOUSE)\n",
    "d2 = frequency_of_industry_breakdown(senate_input_df, constants.SENATE)\n",
    "d3 = frequency_of_industry_breakdown(input_df, constants.INPUT)\n",
    "\n",
    "\n",
    "def frequency_of_sector_breakdown(group, diff):\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():     \n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            sector = dir_utils.search_mapping(sector_df, t[constants.TICKER], sector=True)  \n",
    "            d = dict_utils.increment_dictionary_in_dictionary(d, sector, ptr_utils.get_year(t[constants.TDATE]))\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_keys(d)\n",
    "    \n",
    "    filename = \"frequency_of_sector_breakdown\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff \n",
    "    key_header = \"sector\"\n",
    "    \n",
    "    \n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.SECTOR)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "    return d \n",
    "\n",
    "d1 = frequency_of_sector_breakdown(house_input_df, constants.HOUSE)\n",
    "d2 = frequency_of_sector_breakdown(senate_input_df, constants.SENATE)\n",
    "d3 = frequency_of_sector_breakdown(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asset Description (asset_description) and Comment (comment) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_options(group):\n",
    "    count = total = 0 \n",
    "    d = {}\n",
    "    # [this_person_placed_an_option, ...]\n",
    "    people = set()\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if constants.ASSET_DESCRIPTION in t and ptr_utils.isvalid(t[constants.ASSET_DESCRIPTION]) and (\"Option\" in t[constants.ASSET_DESCRIPTION] or \"option\" in t[constants.ASSET_DESCRIPTION]): \n",
    "            count += 1 \n",
    "            people.add(official.get_name(t))\n",
    "        total += 1 \n",
    "\n",
    "    d[\"(No. of Options, %)\"] = (count, ptr_utils.make_percent(count, total))\n",
    "\n",
    "    return d \n",
    "            \n",
    "d1 = number_of_options(house_input_df)\n",
    "d2 = number_of_options(senate_input_df)\n",
    "d3 = number_of_options(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.COMMENT)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"number_of_options\", (d1,d2,d3), [\"\", constants.HOUSE, constants.SENATE, constants.INPUT])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Scanned PDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_scanned_pdfs(group):\n",
    "    count = total = 0 \n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if t[constants.ASSET_DESCRIPTION] == constants.DISCLOSED:\n",
    "            count += 1 \n",
    "        total += 1 \n",
    "            \n",
    "    d[\"(No. of Scanned PDFS, %)\"] = (count, ptr_utils.make_percent(count, total))\n",
    "\n",
    "    return d \n",
    "            \n",
    "d1 = number_of_scanned_pdfs(house_input_df)\n",
    "d2 = number_of_scanned_pdfs(senate_input_df)\n",
    "d3 = number_of_scanned_pdfs(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.COMMENT)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"number_of_scanned_pdfs\", (d1,d2,d3), [\"\", constants.HOUSE, constants.SENATE, constants.INPUT])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asset Type (asset_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Asset Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_asset_type(group):\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if constants.ATYPE in t and ptr_utils.isvalid(t[constants.ATYPE]):\n",
    "            d = dict_utils.increment_dictionary(d, t[constants.ATYPE])\n",
    "      \n",
    "    return dict_utils.sort_dictionary_by_values(d)\n",
    "\n",
    "d1 = frequency_of_asset_type(house_input_df)\n",
    "d2 = frequency_of_asset_type(senate_input_df)\n",
    "d3 = frequency_of_asset_type(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.ATYPE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"frequency_of_asset_type\", (d1,d2,d3), [constants.ATYPE, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amount "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Amount by Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              amount  $1,000 - $15,000  $1,000,000 +  $1,000,001 - $5,000,000  \\\n",
      "0  Allen, Richard W.                 0             0                        0   \n",
      "1      Amash, Justin                 0             0                        0   \n",
      "\n",
      "   $1,001 -  $1,001 - $15,000  $100,001 - $250,000  $15,000 - $50,000  \\\n",
      "0         0                15                    0                  0   \n",
      "1         0                 2                    0                  0   \n",
      "\n",
      "   $15,001 - $50,000  $250,001 - $500,000  $5,000,001 - $25,000,000  \\\n",
      "0                 21                    0                         0   \n",
      "1                  1                    0                         0   \n",
      "\n",
      "   $50,000,000 +  $50,001 - $100,000  $500,001 - $1,000,000  \n",
      "0              0                   2                      0  \n",
      "1              0                   0                      0  \n",
      "              amount  $1,000,001 - $5,000,000  $1,001 - $15,000  \\\n",
      "0   Alexander, Lamar                        1                 0   \n",
      "1  Barrasso, John A.                        0                 0   \n",
      "\n",
      "   $100,001 - $250,000  $15,001 - $50,000  $25,000,001 - $50,000,000  \\\n",
      "0                    1                 31                          0   \n",
      "1                    0                  0                          0   \n",
      "\n",
      "   $250,001 - $500,000  $5,000,001 - $25,000,000  $50,001 - $100,000  \\\n",
      "0                    2                         0                  22   \n",
      "1                    0                         0                   1   \n",
      "\n",
      "   $500,001 - $1,000,000  Over $50,000,000  \n",
      "0                      2                 0  \n",
      "1                      0                 0  \n"
     ]
    }
   ],
   "source": [
    "def frequency_of_amount_by_persom(group, diff):\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        d = dict_utils.increment_dictionary_in_dictionary(d, official.get_name(t), t[constants.AMOUNT])\n",
    "    \n",
    "    d = dict_utils.sort_dictionary_by_keys(d)\n",
    "    \n",
    "    filename = \"frequency_of_amount_by_person\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff \n",
    "        \n",
    "    key_header = constants.AMOUNT\n",
    "    \n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.AMOUNT)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "    \n",
    "    return d \n",
    "   \n",
    "    \n",
    "d1 = frequency_of_amount_by_persom(house_input_df, constants.HOUSE)\n",
    "d2 = frequency_of_amount_by_persom(senate_input_df, constants.SENATE)\n",
    "# d3 = frequency_of_amount_by_persom(input_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Transactions by Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_amount_total(group):\n",
    "    d = {}        \n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        amount = t[constants.AMOUNT]\n",
    "        if amount in constants.AMOUNT_CONSISTENCY:\n",
    "            amount = constants.AMOUNT_CONSISTENCY[amount]\n",
    "                    \n",
    "        d = dict_utils.increment_dictionary(d, amount)\n",
    "\n",
    "    return d\n",
    "    \n",
    "d1 = frequency_of_amount_total(house_input_df)\n",
    "d2 = frequency_of_amount_total(senate_input_df)\n",
    "d3 = frequency_of_amount_total(input_df)\n",
    "\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.AMOUNT)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"frequency_of_amount_total\", (d1,d2,d3), [constants.AMOUNT, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Amount by Gender "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             amount  female  male  sort_key\n",
      "0          $1,001 -       7   235      1001\n",
      "1  $1,001 - $15,000    2807  6479     15000\n",
      "             amount  female  male  sort_key\n",
      "0           Unknown      87   378        -1\n",
      "1  $1,001 - $15,000     893  4942     15000\n",
      "     amount  female  male  sort_key\n",
      "0   Unknown      87   378        -1\n",
      "1  $1,001 -       7   235      1001\n"
     ]
    }
   ],
   "source": [
    "def frequency_of_amount_by_gender(group, diff, normalized=None):\n",
    "    d = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        name = official.get_name(t)\n",
    "        link = input_all_officials_name[name]\n",
    "        d = dict_utils.increment_dictionary_in_dictionary(d, t[constants.AMOUNT], all_officials_gender[link])\n",
    "\n",
    "    d = dict_utils.add_sort_key_for_amount(d)\n",
    "    d = dict_utils.sort_dictionary_by_sort_key(d)\n",
    "\n",
    "        \n",
    "    filename = \"frequency_of_amount_by_gender\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "    \n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.AMOUNT)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, constants.AMOUNT)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "    return d \n",
    "   \n",
    "    \n",
    "d1 = frequency_of_amount_by_gender(house_input_df, constants.HOUSE, len(input_house_officials_link))\n",
    "d2 = frequency_of_amount_by_gender(senate_input_df, constants.SENATE, len(input_senate_officials_link))\n",
    "d3 = frequency_of_amount_by_gender(input_df, constants.INPUT, len(input_all_officials_link))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Transactions by Political Affiliation and Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             amount  Democratic  Libertarian  Republican  sort_key\n",
      "0          $1,001 -         236            0           6      1001\n",
      "1  $1,001 - $15,000        6833            2        2455     15000\n",
      "             amount  Democratic  Independent  Republican  sort_key\n",
      "0           Unknown         189            8         268        -1\n",
      "1  $1,001 - $15,000        1993           51        3791     15000\n",
      "     amount  Democratic  Independent  Libertarian  Republican  sort_key\n",
      "0   Unknown         189            8            0         268        -1\n",
      "1  $1,001 -         236            0            0           6      1001\n"
     ]
    }
   ],
   "source": [
    "def frequency_of_amount_by_aff(group, diff):\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        obj = t_to_obj(t)\n",
    "        amount = t[constants.AMOUNT]\n",
    "        if amount in constants.AMOUNT_CONSISTENCY:\n",
    "            amount = constants.AMOUNT_CONSISTENCY[t[constants.AMOUNT]]\n",
    "            \n",
    "        d = dict_utils.increment_dictionary_in_dictionary(d, amount, obj.party)\n",
    "\n",
    "\n",
    "    d = dict_utils.add_sort_key_for_amount(d)\n",
    "    d = dict_utils.sort_dictionary_by_sort_key(d)\n",
    "    \n",
    "        \n",
    "    filename = \"frequency_of_amount_by_aff\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "    \n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.AMOUNT)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, constants.AMOUNT)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "    \n",
    "    return d \n",
    "   \n",
    "    \n",
    "d1 = frequency_of_amount_by_aff(house_input_df, constants.HOUSE)\n",
    "d2 = frequency_of_amount_by_aff(senate_input_df, constants.SENATE)\n",
    "d3 = frequency_of_amount_by_aff(input_df, constants.INPUT) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average For Buys and Sells per Official "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           official average_size_of_transactions\n",
      "0  Matsui, Doris O.                    6,529,007\n",
      "1     Pelosi, Nancy                      498,092\n",
      "2  Peters, Scott H.                      475,089\n",
      "3       Wagner, Ann                      179,838\n",
      "4     Moulton, Seth                      169,410\n",
      "             official average_size_of_transactions\n",
      "0         Scott, Rick                      488,349\n",
      "1     Warner, Mark R.                      232,220\n",
      "2  Bennet, Michael F.                      139,067\n",
      "3        Hoeven, John                       85,128\n",
      "4   Crapo, Michael D.                       73,576\n",
      "           official average_size_of_transactions\n",
      "0  Matsui, Doris O.                   19,526,288\n",
      "1     Pelosi, Nancy                      498,092\n",
      "2       Scott, Rick                      488,349\n",
      "3  Peters, Scott H.                      435,463\n",
      "4   Warner, Mark R.                      232,220\n"
     ]
    }
   ],
   "source": [
    "def average_per_person(group, diff):\n",
    "    d={}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.AMOUNT]) and (t[constants.TYPE] == constants.PURCHASE or t[constants.TYPE] == constants.SALE):\n",
    "                        \n",
    "            mean = ptr_utils.get_gmean(t[constants.AMOUNT])\n",
    "\n",
    "            # if t[constants.TYPE] == constants.PURCHASE: \n",
    "            #     mean = -mean \n",
    "\n",
    "            d = dict_utils.increment_list_in_dictionary(d, official.get_name(t), mean)\n",
    "\n",
    "\n",
    "    d = dict_utils.flatten_gmean(d)        \n",
    "            \n",
    "    filename = \"average_per_person\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "\n",
    "    key_header = constants.OFFICIAL \n",
    "    value_header = \"average_size_of_transactions\"\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_values(d)\n",
    "    d = dict_utils.commify(d)\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.AMOUNT)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "\n",
    "    return d \n",
    "\n",
    "d1 = average_per_person(house_input_df, constants.HOUSE)\n",
    "d2 = average_per_person(senate_input_df, constants.SENATE)\n",
    "d3 = average_per_person(input_df, constants.INPUT) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                official average_size_of_transactions\n",
      "0          Raskin, Jamie                    2,750,540\n",
      "1       Matsui, Doris O.                    1,431,627\n",
      "2          Pelosi, Nancy                      558,256\n",
      "3  Schneider, Bradley S.                      359,331\n",
      "4       Peters, Scott H.                      342,258\n",
      "             official average_size_of_transactions\n",
      "0        Johnson, Ron                    1,526,383\n",
      "1         Scott, Rick                      487,942\n",
      "2  Marshall, Roger W.                      367,879\n",
      "3  Bennet, Michael F.                      194,779\n",
      "4     Warner, Mark R.                      134,027\n",
      "           official average_size_of_transactions\n",
      "0     Raskin, Jamie                   73,575,888\n",
      "1  Matsui, Doris O.                    2,369,337\n",
      "2      Johnson, Ron                    1,526,383\n",
      "3     Pelosi, Nancy                      558,256\n",
      "4       Scott, Rick                      487,942\n"
     ]
    }
   ],
   "source": [
    "def average_activity(group, diff):\n",
    "    d={}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "                        \n",
    "            mean = ptr_utils.get_gmean(t[constants.AMOUNT])\n",
    "\n",
    "            d = dict_utils.increment_list_in_dictionary(d, official.get_name(t), mean)\n",
    "\n",
    "\n",
    "    d = dict_utils.flatten_gmean(d)        \n",
    "            \n",
    "    filename = \"average_activity\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "\n",
    "    key_header = constants.OFFICIAL \n",
    "    value_header = \"average_size_of_transactions\"\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_values(d)\n",
    "    d = dict_utils.commify(d)\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.AMOUNT)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "\n",
    "    return d \n",
    "\n",
    "d1 = average_activity(house_input_df, constants.HOUSE)\n",
    "d2 = average_activity(senate_input_df, constants.SENATE)\n",
    "d3 = average_activity(input_df, constants.INPUT) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types (type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Actions Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_act(group):\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TYPE]): \n",
    "            d = dict_utils.increment_dictionary(d, t[constants.TYPE])\n",
    "    \n",
    "    return dict_utils.sort_dictionary_by_values(d)\n",
    "    \n",
    "     \n",
    "d1 = frequency_of_act(house_input_df)\n",
    "d2 = frequency_of_act(senate_input_df)\n",
    "d3 = frequency_of_act(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.TYPE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"frequency_of_act\", (d1,d2,d3), [constants.TYPE, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Transactions per Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              official  Exchange  Purchase  Sale (Full)  Sale (Partial)  total\n",
      "0    Allen, Richard W.         0        23           14               1     38\n",
      "1        Amash, Justin         0         3            0               0      3\n",
      "2  Arenholz, Ashley H.         0         4           10               0     14\n",
      "3        Axne, Cynthia         5       113           43              13    174\n",
      "4      Banks, James E.         0        28           16               8     52\n",
      "              official  Exchange  Purchase  Sale (Full)  Sale (Partial)  total\n",
      "0     Alexander, Lamar         0        36           21               2     59\n",
      "1    Barrasso, John A.         0         0            1               0      1\n",
      "2   Bennet, Michael F.         1         5            1               1      8\n",
      "3  Blumenthal, Richard         0         0            0               0     50\n",
      "4        Blunt, Roy D.         0         1            7               0     10\n",
      "              official  Exchange  Purchase  Sale (Full)  Sale (Partial)  total\n",
      "0     Alexander, Lamar         0        36           21               2     59\n",
      "1    Allen, Richard W.         0        23           14               1     38\n",
      "2        Amash, Justin         0         3            0               0      3\n",
      "3  Arenholz, Ashley H.         0         4           10               0     14\n",
      "4        Axne, Cynthia         5       113           43              13    174\n",
      "              official  Exchange  Purchase  Sale (Full)  Sale (Partial)  total\n",
      "0    Allen, Richard W.      0.00      3.29         2.00            0.14   5.43\n",
      "1        Amash, Justin      0.00      0.30         0.00            0.00   0.30\n",
      "2  Arenholz, Ashley H.      0.00      4.00        10.00            0.00  14.00\n",
      "3        Axne, Cynthia      1.67     37.67        14.33            4.33  58.00\n",
      "4      Banks, James E.      0.00      5.60         3.20            1.60  10.40\n",
      "              official  Exchange  Purchase  Sale (Full)  Sale (Partial)  total\n",
      "0     Alexander, Lamar      0.00      2.00         1.17            0.11   3.28\n",
      "1    Barrasso, John A.      0.00      0.00         0.07            0.00   0.07\n",
      "2   Bennet, Michael F.      0.08      0.38         0.08            0.08   0.62\n",
      "3  Blumenthal, Richard      0.00      0.00         0.00            0.00   4.55\n",
      "4        Blunt, Roy D.      0.00      0.04         0.28            0.00   0.40\n",
      "              official  Exchange  Purchase  Sale (Full)  Sale (Partial)  total\n",
      "0     Alexander, Lamar      0.00      2.00         1.17            0.11   3.28\n",
      "1    Allen, Richard W.      0.00      3.29         2.00            0.14   5.43\n",
      "2        Amash, Justin      0.00      0.30         0.00            0.00   0.30\n",
      "3  Arenholz, Ashley H.      0.00      4.00        10.00            0.00  14.00\n",
      "4        Axne, Cynthia      1.67     37.67        14.33            4.33  58.00\n"
     ]
    }
   ],
   "source": [
    "def types_of_transactions_per_person(group, diff, normalized=None):\n",
    "    d={}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        d = dict_utils.increment_dictionary_in_dictionary(d, official.get_name(t), t[constants.TYPE])\n",
    "        d = dict_utils.increment_dictionary_in_dictionary(d, official.get_name(t), constants.TOTAL)\n",
    "\n",
    "\n",
    "    if normalized: \n",
    "        for k,v in d.items():\n",
    "            newinner = {}\n",
    "            for ik, iv in v.items():\n",
    "                link = input_all_officials_name[k]\n",
    "                _, obj = input_officials_objects[link]\n",
    "                newinner[ik] = round(iv/obj.get_seniority(), 2)\n",
    "                \n",
    "            d[k] = newinner\n",
    "    \n",
    "    filename = \"types_of_transactions_per_person\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "    if normalized:\n",
    "        filename += \"_normalized\"\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_keys(d)\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TYPE)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, constants.OFFICIAL)\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "\n",
    "    return d \n",
    "\n",
    "d1 = types_of_transactions_per_person(house_input_df, constants.HOUSE)\n",
    "d2 = types_of_transactions_per_person(senate_input_df, constants.SENATE)\n",
    "d3 = types_of_transactions_per_person(input_df, constants.INPUT)\n",
    "\n",
    "d1 = types_of_transactions_per_person(house_input_df, constants.HOUSE, normalized=True)\n",
    "d2 = types_of_transactions_per_person(senate_input_df, constants.SENATE, normalized=True)\n",
    "d3 = types_of_transactions_per_person(input_df, constants.INPUT, normalized=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_per_year(group, normalized=None):\n",
    "    d={}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        d =  dict_utils.increment_dictionary(d, ptr_utils.get_year(t[constants.TDATE]))\n",
    "\n",
    "    if normalized:\n",
    "        d2 = {}\n",
    "        for k,v in d.items():\n",
    "            d2[k] = v/normalized\n",
    "            \n",
    "        \n",
    "    return dict_utils.sort_dictionary_by_values(d), dict_utils.sort_dictionary_by_values(d2)\n",
    "\n",
    "d1, d4 = num_of_trans_per_year(house_input_df, len(input_house_officials_objects))\n",
    "d2, d5 = num_of_trans_per_year(senate_input_df, len(input_senate_officials_objects))\n",
    "d3, d6 = num_of_trans_per_year(input_df, len(input_officials_objects))\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.FREQ)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_per_year\", (d1,d2,d3), [\"year\", constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_per_year_normalized\", (d4,d5,d6), [\"year\", constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Person \n",
    "_Not controlling for number of years in position or size of transaction._ For each official, we want their total number of transactions.  {'Sam': 5, 'Alex': 2424, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_per_person(group):\n",
    "    d={}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        d = dict_utils.increment_dictionary(d, official.get_name(t))\n",
    "\n",
    "    return dict_utils.sort_dictionary_by_values(d)\n",
    "    \n",
    "d1 = num_of_trans_per_person(house_input_df)\n",
    "d2 = num_of_trans_per_person(senate_input_df)    \n",
    "d3 = num_of_trans_per_person(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_per_person\", (d1,d2,d3), [constants.OFFICIAL, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Person Controlled\n",
    "_Divide number of transactions by number of years in official position.  Not controlling for size of transaction._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_per_person_controlled(group):    \n",
    "    d={}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        d = dict_utils.increment_dictionary(d, official.get_name(t))\n",
    "        \n",
    "    for k,v in d.items():\n",
    "        obj = t_to_obj(t)\n",
    "        d[k] = int(v/obj.get_seniority()) if int(v/obj.get_seniority()) != 0 else 1 \n",
    "\n",
    "    return dict_utils.sort_dictionary_by_values(d)\n",
    "\n",
    "\n",
    "d1 = num_of_trans_per_person_controlled(house_input_df)\n",
    "d2 = num_of_trans_per_person_controlled(senate_input_df)\n",
    "d3 = num_of_trans_per_person_controlled(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.FREQ)\n",
    "\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_per_person_controlled\", (d1, d2, d3), [constants.OFFICIAL, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e534e48711db4d1e1c48977d0d14ff85b1f16d41bcc4fdfd88268a329b3c9d66"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
