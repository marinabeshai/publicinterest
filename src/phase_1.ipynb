{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHASE 1: PROFILE + GEN Q'S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.csv_utils as csv_utils \n",
    "import utils.dir_utils as dir_utils\n",
    "import utils.dict_utils as dict_utils \n",
    "import utils.ptr_utils as ptr_utils\n",
    "import utils.constants as constants \n",
    "import helpers.official as official\n",
    "import helpers.search as search\n",
    "import helpers.congress as congress\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of officials in House && in Senate in total (from 112-117th congress): 0\n",
      "\n",
      "Number of transactions: 22,195 \n",
      "\n",
      "Number of transactions by House Representatives: 13,154, 59.27%\n",
      "Number of transactions by House Representatives controlled: 83.78 transactions per representative \n",
      "\n",
      "Number of transactions by Senators: 9,041, 40.73%\n",
      "Number of transactions by Senators controlled: 143.51 transactions per senator \n",
      "\n",
      "Number of officials in House && in Senate in total (from 112-117th congress): 27\n",
      "\n",
      "Number of officials in input: 220\n",
      "Number of officials in input controlled: 22.70%\n",
      "\n",
      "Number of representatives in input: 157, 71.36%\n",
      "Number of representatives in input controlled: 18.87% \n",
      "\n",
      "Number of senators in input: 63, 28.64%\n",
      "Number of senators in input controlled: 38.41% \n",
      "\n",
      "Number of officials in total (from 112-117th congress): 969\n",
      "Number of representatives in total (from 112-117th congress): 832\n",
      "Number of senators in total (from 112-117th congress): 164\n",
      "\n",
      "Number of officials from 112-117th congress who DID NOT engage in the market: 749, 77.30%\n",
      "\n",
      "Number of representatives from 112-117th congress who DID NOT engage in the market: 648\n",
      "Number of senators from 112-117th congress who DID NOT engage in the market: 101\n",
      "\n",
      "Number of officials from 112-117th congress who DID engage in the market: 220, 22.70% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, input_df = dir_utils.get_data(combined=True)\n",
    "_, house_input_df = dir_utils.get_data(house=True)\n",
    "_, senate_input_df = dir_utils.get_data(senate=True)\n",
    "\n",
    "num_of_transactions = input_df.shape[0]\n",
    "num_of_house_transactions = house_input_df.shape[0]\n",
    "num_of_senate_transactions = senate_input_df.shape[0]\n",
    "\n",
    "sector_df = dir_utils.get_mapping(sector=True)\n",
    "industry_df = dir_utils.get_mapping(industry=True)\n",
    "\n",
    "# {canonical_name_input_based : link, ...}\n",
    "input_all_officials_name = {}\n",
    "\n",
    "# {link : canonical_name_input_based, ....}\n",
    "input_all_officials_link = {}\n",
    "input_house_officials_link = {}\n",
    "input_senate_officials_link = {}\n",
    "\n",
    "# (canonical_name_input_based, ...)\n",
    "names = set()\n",
    "\n",
    "for _,t in input_df.iterrows():        \n",
    "    name = official.get_name(t)\n",
    "        \n",
    "    if name not in names:    \n",
    "        link = search.get_wiki_link(name)\n",
    "\n",
    "        if ptr_utils.isvalid(t[constants.REPRESENTATIVE]) and link not in input_house_officials_link:\n",
    "            input_house_officials_link =  dict_utils.increment_dictionary(input_house_officials_link, link, name, not_math=True)\n",
    "        if ptr_utils.isvalid(t[constants.SENATOR]) and link not in input_senate_officials_link:\n",
    "            input_senate_officials_link =  dict_utils.increment_dictionary(input_senate_officials_link, link, name, not_math=True)\n",
    "        \n",
    "        input_all_officials_link =  dict_utils.increment_dictionary(input_all_officials_link, link, name, not_math=True)\n",
    "        input_all_officials_name =  dict_utils.increment_dictionary(input_all_officials_name, name, link, not_math=True)\n",
    "\n",
    "        names.add(name)\n",
    "\n",
    "input_officials_in_house_and_senate = 0 \n",
    "for link in input_all_officials_link:\n",
    "    if link in input_house_officials_link and link in input_senate_officials_link:\n",
    "        del input_house_officials_link[link]\n",
    "        input_officials_in_house_and_senate += 1\n",
    "print(\"Number of officials in House && in Senate in total (from 112-117th congress): {}\\n\".format(input_officials_in_house_and_senate))\n",
    "\n",
    "\n",
    "print(\"Number of transactions: {} \\n\".format(ptr_utils.commify_str(len(input_df.index))))\n",
    "\n",
    "print(\"Number of transactions by House Representatives: {}, {}\".format(ptr_utils.commify_str(num_of_house_transactions), ptr_utils.make_percent(num_of_house_transactions, len(input_df.index))))\n",
    "print(\"Number of transactions by House Representatives controlled: {0:.2f} transactions per representative \\n\".format((num_of_house_transactions / len(input_house_officials_link))))\n",
    "\n",
    "print(\"Number of transactions by Senators: {}, {}\".format(ptr_utils.commify_str(num_of_senate_transactions), ptr_utils.make_percent(num_of_senate_transactions, len(input_df.index))))\n",
    "print(\"Number of transactions by Senators controlled: {0:.2f} transactions per senator \\n\".format( (num_of_senate_transactions /  len(input_senate_officials_link))))\n",
    "\n",
    "congress_objects = []\n",
    "house_officials_party = {}\n",
    "senate_officials_party = {}\n",
    "for i in range(112, 118):\n",
    "    c = search.get_congress(i)\n",
    "    congress_objects.append(c)\n",
    "    house_officials_party.update(c.get_house_party())\n",
    "    senate_officials_party.update(c.get_senate_party())\n",
    "    \n",
    "# {link : (canonical_name_input_based, official_object) ... }\n",
    "input_officials_objects = {}\n",
    "\n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "input_house_officials_objects = {}\n",
    "for link, person in input_house_officials_link.items(): \n",
    "    off = search.wiki_search(person, link)        \n",
    "    input_house_officials_objects[link] = (person, off)\n",
    "    input_officials_objects[link] = (person, off)\n",
    "        \n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "input_senate_officials_objects = {}\n",
    "for link, person in input_senate_officials_link.items():\n",
    "    off = search.wiki_search(person, link)        \n",
    "    input_senate_officials_objects[link] = (person, off)\n",
    "    input_officials_objects[link] = (person, off)\n",
    "\n",
    "# {link : canonical_name_wiki_based, ... }\n",
    "all_officials = congress.get_all_officials()\n",
    "house_officials = congress.get_house_officials()\n",
    "senate_officials = congress.get_senate_officials()\n",
    "\n",
    "# {link : (canonical_name_input_based, official_object) ... }\n",
    "officials_objects = {}\n",
    "house_officials_objects = {}  \n",
    "senate_officials_objects = {}\n",
    " \n",
    "for link, name in house_officials.items():\n",
    "    off = search.wiki_search(name, link)        \n",
    "    house_officials_objects[link] = (name, off)\n",
    "    officials_objects[link] = (name, off)\n",
    "    \n",
    "for link, name in senate_officials.items():\n",
    "    off = search.wiki_search(name, link)        \n",
    "    senate_officials_objects[link] = (name, off)\n",
    "    officials_objects[link] = (name, off)\n",
    "\n",
    "# {link : canonical_name_wiki_based, ... }\n",
    "all_officials_not_in_input = dict(all_officials)\n",
    "house_officials_not_in_input = dict(house_officials)\n",
    "senate_officials_not_in_input = dict(senate_officials)\n",
    "\n",
    "all_officials_in_house_and_senate = 0 \n",
    "for link in all_officials_not_in_input:\n",
    "    if link in house_officials_not_in_input and link in senate_officials_not_in_input:\n",
    "        del house_officials_not_in_input[link]\n",
    "        all_officials_in_house_and_senate += 1\n",
    "print(\"Number of officials in House && in Senate in total (from 112-117th congress): {}\\n\".format(all_officials_in_house_and_senate))\n",
    "\n",
    "for link_input in input_all_officials_link.keys():\n",
    "    del all_officials_not_in_input[link_input]\n",
    "    \n",
    "    if link_input in house_officials_not_in_input:\n",
    "        del house_officials_not_in_input[link_input]\n",
    "    else:\n",
    "        del senate_officials_not_in_input[link_input]\n",
    "\n",
    "# {link : gender, ...}\n",
    "all_officials_gender = {}\n",
    "input_house_officials_gender = {}\n",
    "input_senate_officials_gender = {}\n",
    "\n",
    "all_officials_party_and_gender = {}\n",
    "house_officials_party_and_gender = {}\n",
    "senate_officials_party_and_gender = {}\n",
    "\n",
    "for link, name in all_officials.items():\n",
    "    gender = str(official.get_gender(name, link))\n",
    "    \n",
    "    x = str(search.congress_gov_get(name, party_only=True))\n",
    "    grouped = x + \", \" + gender\n",
    "        \n",
    "    all_officials_party_and_gender = dict_utils.increment_dictionary(all_officials_party_and_gender, grouped)\n",
    "\n",
    "    if link in senate_officials:\n",
    "        senate_officials_party_and_gender = dict_utils.increment_dictionary(senate_officials_party_and_gender, grouped)\n",
    "    if link in house_officials:\n",
    "        house_officials_party_and_gender = dict_utils.increment_dictionary(house_officials_party_and_gender, grouped)\n",
    "  \n",
    "    if link in input_house_officials_objects:\n",
    "       input_house_officials_gender[link] = gender\n",
    "    if link in input_senate_officials_objects:\n",
    "        input_senate_officials_gender[link] =  gender\n",
    "    all_officials_gender[link] = gender\n",
    "\n",
    "# {'California' :  #_of_representatives_from_112_to_117, ...}\n",
    "all_officials_state_count = congress.get_officials_state(everyone=list(all_officials.values()))\n",
    "house_officials_state_count = congress.get_officials_state(house=list(house_officials.values()))\n",
    "senate_officials_state_count = congress.get_officials_state(everyone=list(senate_officials.values()))\n",
    "\n",
    "all_officials_party = {}\n",
    "for (k,v) in house_officials_party.items():\n",
    "    if k in senate_officials_party:\n",
    "        all_officials_party[k] = v + senate_officials_party[k]\n",
    "    else:\n",
    "        all_officials_party[k] = v \n",
    "        \n",
    "for (k,v) in senate_officials_party.items():\n",
    "    if k not in all_officials_party:\n",
    "        all_officials_party[k] = v\n",
    "            \n",
    "\n",
    "print(\"Number of officials in input: {}\".format(len(input_all_officials_link)))\n",
    "print(\"Number of officials in input controlled: {}\\n\".format(ptr_utils.make_percent(len(input_all_officials_link), len(all_officials))))\n",
    "\n",
    "print(\"Number of representatives in input: {}, {}\".format(len(input_house_officials_link), ptr_utils.make_percent(len(input_house_officials_link), len(input_all_officials_link))))\n",
    "print(\"Number of representatives in input controlled: {} \\n\".format(ptr_utils.make_percent(len(input_house_officials_link), len(house_officials))))\n",
    "\n",
    "print(\"Number of senators in input: {}, {}\".format(len(input_senate_officials_link), ptr_utils.make_percent(len(input_senate_officials_link), len(input_all_officials_link))))\n",
    "print(\"Number of senators in input controlled: {} \\n\".format(ptr_utils.make_percent(len(input_senate_officials_link), len(senate_officials))))\n",
    "\n",
    "print(\"Number of officials in total (from 112-117th congress): {}\".format(ptr_utils.commify_str(len(all_officials))))\n",
    "print(\"Number of representatives in total (from 112-117th congress): {}\".format(ptr_utils.commify_str(len(house_officials))))\n",
    "print(\"Number of senators in total (from 112-117th congress): {}\\n\".format(ptr_utils.commify_str(len(senate_officials))))\n",
    "\n",
    "print(\"Number of officials from 112-117th congress who DID NOT engage in the market: {}, {}\\n\".format(len(all_officials_not_in_input), ptr_utils.make_percent(len(all_officials_not_in_input), len(all_officials) ) ))\n",
    "print(\"Number of representatives from 112-117th congress who DID NOT engage in the market: {}\".format(len(house_officials_not_in_input)))\n",
    "print(\"Number of senators from 112-117th congress who DID NOT engage in the market: {}\\n\".format(len(senate_officials_not_in_input)))\n",
    "\n",
    "print(\"Number of officials from 112-117th congress who DID engage in the market: {}, {} \\n\".format(len(input_all_officials_link), ptr_utils.make_percent(len(input_all_officials_link), len(all_officials) ) ))\n",
    "\n",
    "def t_to_obj(t):\n",
    "    name = official.get_name(t)\n",
    "    link = input_all_officials_name[name]\n",
    "    _, obj = input_officials_objects[link]\n",
    "    return obj\n",
    "\n",
    "# 201 Minutes!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 66\n",
      "{'Financial Services': 14, 'Energy': 11, 'Technology': 9, 'Industrials': 8, 'Healthcare': 6, 'Consumer Cyclical': 5, 'Consumer Defensive': 4, 'Basic Materials': 3, 'Communication Services': 3, 'Real Estate': 2, 'Utilities': 1}\n"
     ]
    }
   ],
   "source": [
    "def test(group):\n",
    "    total = s = 0\n",
    "    d = {}\n",
    "    for _,t in group.iterrows():\n",
    "        if  t[constants.TDATE] == '2020/11/13' and t[constants.TYPE] == 'Purchase': \n",
    "            \n",
    "            sector = dir_utils.search_mapping(sector_df, t[constants.TICKER], sector=True)      \n",
    "            obj = t_to_obj(t)\n",
    "\n",
    "            total += 1\n",
    "            d = dict_utils.increment_dictionary(d, sector)\n",
    "\n",
    "    print(len(d), total)\n",
    "    print(dict_utils.sort_dictionary_by_values(d))\n",
    "\n",
    "    return d\n",
    "\n",
    "# {'Financial Services': 14, 'Energy': 11, 'Technology': 9, 'Industrials': 8, 'Healthcare': 6, 'Consumer Cyclical': 5, 'Consumer Defensive': 4, 'Basic Materials': 3, 'Communication Services': 3, 'Real Estate': 2, 'Utilities': 1}\n",
    "\n",
    "d1 = test(house_input_df)\n",
    "# d2 = test(senate_input_df)\n",
    "# d3 = test(input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curtis, John (R-UT)\n"
     ]
    }
   ],
   "source": [
    "name = 'Curtis, John'\n",
    "\n",
    "link = input_all_officials_name[name]\n",
    "_, obj = input_officials_objects[link]\n",
    "print(obj.get_label())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Committee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Senate Health Committee'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/y3/llvqw9gd7nz5vkbmv014r2kc0000gn/T/ipykernel_94608/2334833607.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdir_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakesubdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"profile/committees\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0md1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprofile_committee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_house_officials_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile_committee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhouse_officials_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0md2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprofile_committee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_senate_officials_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile_committee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msenate_officials_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0md3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprofile_committee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_officials_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile_committee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mofficials_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/y3/llvqw9gd7nz5vkbmv014r2kc0000gn/T/ipykernel_94608/2334833607.py\u001b[0m in \u001b[0;36mprofile_committee\u001b[0;34m(group, normalized)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Normalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnormalized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/Senior/Thesis/publicinterest/src/utils/dict_utils.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(d, normalized, percent, raw)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mnew_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mnormalized\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                 \u001b[0mnew_d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mnormalized\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Senate Health Committee'"
     ]
    }
   ],
   "source": [
    "def profile_committee(group, normalized=None):\n",
    "    # {party_and_gender : 45_ppl}\n",
    "    d = {}\n",
    "        \n",
    "    for _, (_, obj) in group.items(): \n",
    "        for a in obj.get_asgts():\n",
    "            a = a[ : a.find(\" (\")]\n",
    "            d = dict_utils.increment_dictionary(d, a)\n",
    "\n",
    "    # Normalize\n",
    "    if normalized: \n",
    "        d = dict_utils.normalize(d, normalized, percent=True)\n",
    "\n",
    "    return d\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"profile/committees\")\n",
    "\n",
    "d1 = profile_committee(input_house_officials_objects, profile_committee(house_officials_objects))\n",
    "d2 = profile_committee(input_senate_officials_objects, profile_committee(senate_officials_objects))\n",
    "d3 = profile_committee(input_officials_objects, profile_committee(officials_objects))\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"profile/committee\")\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_committee_normalized\", (d1,d2,d3), [\"committee\", constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "\n",
    "d1 = profile_committee(input_house_officials_objects)\n",
    "d2 = profile_committee(input_senate_officials_objects)\n",
    "d3 = profile_committee(input_officials_objects)\n",
    "\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_committee\", (d1,d2,d3), [\"committee\", constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Party and Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_party_and_gender(group, normalized=None):\n",
    "    # {party_and_gender : 45_ppl}\n",
    "    d = {}\n",
    "        \n",
    "    # {link : (canonical_name_input_based, official_object), ... \n",
    "    for link, (_,obj) in group.items():\n",
    "        x = obj.party\n",
    "        gender = all_officials_gender[link]\n",
    "        grouped = x + \", \" + gender\n",
    "        d = dict_utils.increment_dictionary(d, grouped)\n",
    "\n",
    "    # Normalize\n",
    "    if normalized: \n",
    "        d = dict_utils.normalize(d, normalized, percent=True)\n",
    "\n",
    "    return d\n",
    "\n",
    "d1 = profile_party_and_gender(input_house_officials_objects, house_officials_party_and_gender)\n",
    "d2 = profile_party_and_gender(input_senate_officials_objects, senate_officials_party_and_gender)\n",
    "d3 = profile_party_and_gender(input_officials_objects, all_officials_party_and_gender)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"profile/partyandgender\")\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_party_and_gender_normalized\", (d1,d2,d3), [constants.PARTY + \", \" + constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "\n",
    "d1 = profile_party_and_gender(input_house_officials_objects)\n",
    "d2 = profile_party_and_gender(input_senate_officials_objects)\n",
    "d3 = profile_party_and_gender(input_officials_objects)\n",
    "\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_party_and_gender\", (d1,d2,d3), [constants.PARTY + \", \" + constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_active_party_and_gender(group, normalized=None):\n",
    "    # {party_and_gender : 45_transactions}\n",
    "    d_number = {}\n",
    "    # {party_and_gender : [gmean, gmean, ...]}\n",
    "    d_size = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "            name = official.get_name(t)\n",
    "            link = input_all_officials_name[name]\n",
    "\n",
    "            gender = all_officials_gender[link]\n",
    "            obj = t_to_obj(t)\n",
    "            x = obj.party\n",
    "            grouped = x + \", \" + gender\n",
    "\n",
    "            \n",
    "            d_number =  dict_utils.increment_dictionary(d_number, grouped)\n",
    "            \n",
    "            mean =  ptr_utils.get_gmean(t[constants.AMOUNT])             \n",
    "            d_size = dict_utils.increment_list_in_dictionary(d_size, grouped, mean)\n",
    "\n",
    "    d_size = dict_utils.flatten_gmean(d_size)\n",
    "\n",
    "    # Normalize\n",
    "    if normalized: \n",
    "        d_number = dict_utils.normalize(d_number, normalized, percent=True)\n",
    "        d_number = dict_utils.sort_dictionary_by_tuple(d_number)\n",
    "        \n",
    "        d_size = dict_utils.normalize(d_size, normalized, percent=True)\n",
    "        d_size = dict_utils.sort_dictionary_by_tuple(d_size)\n",
    "\n",
    "    return d_number, d_size\n",
    "    \n",
    "d1,d4 = profile_active_party_and_gender(house_input_df, house_officials_party_and_gender)\n",
    "d2,d5 = profile_active_party_and_gender(senate_input_df, senate_officials_party_and_gender)\n",
    "d3,d6 = profile_active_party_and_gender(input_df, all_officials_party_and_gender)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"active\")\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_party_and_gender_number_normalized\", (d1,d2,d3), [constants.PARTY + \", \" + constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_party_and_gender_size_normalized\", (d4,d5,d6), [constants.PARTY + \", \" + constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "\n",
    "d1,d4 = profile_active_party_and_gender(house_input_df)\n",
    "d2,d5 = profile_active_party_and_gender(senate_input_df)\n",
    "d3,d6 = profile_active_party_and_gender(input_df)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_party_and_gender_number\", (d1,d2,d3), [constants.PARTY + \", \" + constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_party_and_gender_size\", (d4,d5,d6), [constants.PARTY + \", \" + constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age (Lowest, Highest, Average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_age(group):\n",
    "    # {age, age, ...}\n",
    "    l = []\n",
    "    \n",
    "    # group = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for _, (_, off_obj) in group.items(): \n",
    "        l.append(off_obj.get_age())\n",
    "    \n",
    "    l.sort()\n",
    "    \n",
    "    d = {}\n",
    "    d[\"0. Youngest\"] = l[0]\n",
    "    d[\"1. Average\"] = round((sum(l) / len(l)))\n",
    "    d[\"2. Oldest\"] = l[len(l)-1]\n",
    "    \n",
    "    return d \n",
    "    \n",
    "d1 = profile_age(input_house_officials_objects)\n",
    "d2 = profile_age(input_senate_officials_objects)\n",
    "d3 = profile_age(input_officials_objects)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"profile/age\")\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_age\", (d1,d2,d3), [\"Age\", constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "\n",
    "def profile_age_2(group, normalized=None):\n",
    "    # {age : #_of_people, ...}\n",
    "    d = dict(constants.age_groups)\n",
    "    \n",
    "    for (_, off_obj) in group.values(): \n",
    "        age = off_obj.get_age()\n",
    "        d = dict_utils.increment_dictionary(d, ptr_utils.which_age_group(age)) \n",
    "    \n",
    "    if normalized: \n",
    "        d_prime = dict_utils.normalize(d, normalized, percent=True)\n",
    "        return d, d_prime\n",
    "        \n",
    "    return d \n",
    "\n",
    "d1, d4 = profile_age_2(input_house_officials_objects, profile_age_2(house_officials_objects))\n",
    "d2, d5 = profile_age_2(input_senate_officials_objects, profile_age_2(senate_officials_objects))\n",
    "d3, d6 = profile_age_2(input_officials_objects, profile_age_2(officials_objects))\n",
    "\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_age_2\", (d1,d2,d3), [\"Age\", constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_age_2_normalized\", (d4,d5,d6), [\"Age\", constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "\n",
    "def profile_age_3(group):\n",
    "    # {age: freq_count , .... }\n",
    "    d = {}\n",
    "    \n",
    "    # group = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for _, (_, off_obj) in group.items(): \n",
    "        d = dict_utils.increment_dictionary(d, off_obj.get_age())\n",
    "    \n",
    "    return d \n",
    "    \n",
    "d1 = profile_age_3(input_house_officials_objects)\n",
    "d2 = profile_age_3(input_senate_officials_objects)\n",
    "d3 = profile_age_3(input_officials_objects)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"profile/age\")\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_age_3\", (d1,d2,d3), [\"Age\", constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "\n",
    "def profile_age_box(group):\n",
    "    # {age, age, ...}\n",
    "    l = []\n",
    "    \n",
    "    # group = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for _, (_, off_obj) in group.items(): \n",
    "        l.append([off_obj.get_age()])\n",
    "        \n",
    "    return l \n",
    "    \n",
    "d1 = profile_age_box(input_house_officials_objects)\n",
    "d2 = profile_age_box(input_senate_officials_objects)\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"profile/age\")\n",
    "csv_utils.make_csv_base(dir, \"profile_age_box_house\", [\"Age_House\"], d1)\n",
    "csv_utils.make_csv_base(dir, \"profile_age_box_senate\", [\"Age_Senate\"], d2)\n",
    "\n",
    "\n",
    "d1 = profile_age_box(house_officials_objects)\n",
    "d2 = profile_age_box(senate_officials_objects)\n",
    "csv_utils.make_csv_base(dir, \"profile_age_box_house_ALL\", [\"Age_House\"], d1)\n",
    "csv_utils.make_csv_base(dir, \"profile_age_box_senate_ALL\", [\"Age_Senate\"], d2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age (Which age is most active?) Active = No. of Trades &  Size of Transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_active_age(group, normalized=None):\n",
    "    # {age : 45_transactions}\n",
    "    d_number = dict(constants.age_groups)\n",
    "    \n",
    "    # {age : [gmean, gmean, ...]}\n",
    "    d_size = dict(constants.age_groups)\n",
    "    for k,_ in d_size.items():\n",
    "        d_size[k] = []\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "            obj = t_to_obj(t)\n",
    "            age = obj.get_age()\n",
    "            \n",
    "            age_group = ptr_utils.which_age_group(age)\n",
    "            d_number =  dict_utils.increment_dictionary(d_number, age_group)\n",
    "            \n",
    "            mean =  ptr_utils.get_gmean(t[constants.AMOUNT])             \n",
    "            d_size = dict_utils.increment_list_in_dictionary(d_size, age_group, mean)\n",
    "\n",
    "    d_size = dict_utils.flatten_gmean(d_size)\n",
    "\n",
    "    # Normalize\n",
    "    if normalized: \n",
    "        d_number = dict_utils.normalize(d_number, normalized, percent=True)\n",
    "        d_number = dict_utils.sort_dictionary_by_tuple(d_number)\n",
    "        \n",
    "        d_size = dict_utils.normalize(d_size, normalized, percent=True)\n",
    "        d_size = dict_utils.sort_dictionary_by_tuple(d_size)\n",
    "\n",
    "    return d_number, d_size\n",
    "    \n",
    "d1,d4 = profile_active_age(house_input_df, profile_age_2(input_house_officials_objects))\n",
    "d2,d5 = profile_active_age(senate_input_df, profile_age_2(input_senate_officials_objects))\n",
    "d3,d6 = profile_active_age(input_df, profile_age_2(input_officials_objects))\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"active\")\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_age_active_number_normalized\", (d1,d2,d3), [constants.AGE, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_age_active_size_normalized\", (d4,d5,d6), [constants.AGE, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "d1,d4 = profile_active_age(house_input_df)\n",
    "d2,d5 = profile_active_age(senate_input_df)\n",
    "d3,d6 = profile_active_age(input_df)\n",
    "\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_age_active_number\", (d1,d2,d3), [constants.AGE, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_age_active_size\", (d4,d5,d6), [constants.AGE, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oldest and Most Recent Dates (transaction and disclosure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_dates(group, type):\n",
    "    lowest_tdate = lowest_ddate = highest_tdate = highest_ddate = None\n",
    "    lowest_tdate_obj = lowest_ddate_obj = highest_tdate_obj = highest_ddate_obj = None\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        curr = t[constants.TDATE]            \n",
    "        if not lowest_tdate or curr < lowest_tdate:\n",
    "            lowest_tdate = curr \n",
    "            lowest_tdate_obj = t\n",
    "        if not highest_tdate or curr > highest_tdate:\n",
    "            highest_tdate = curr  \n",
    "            highest_tdate_obj = t\n",
    "\n",
    "        curr = t[constants.DDATE]\n",
    "        if not lowest_ddate or curr < lowest_ddate:\n",
    "            lowest_ddate = curr \n",
    "            lowest_ddate_obj = t\n",
    "        if not highest_ddate or curr > highest_ddate:\n",
    "            highest_ddate = curr \n",
    "            highest_ddate_obj = t\n",
    "\n",
    "    print(\"Oldest transaction_date for {}: {} by {} \\n {}\".format(type, lowest_tdate, official.get_name(lowest_tdate_obj), lowest_tdate_obj[constants.PTR_LINK]))\n",
    "    print(\"Most recent transaction_date for {}: {} by {} \\n {} \".format(type, highest_tdate, official.get_name(highest_tdate_obj), highest_tdate_obj[constants.PTR_LINK]))\n",
    "    \n",
    "    print(\"Oldest disclosure_date for {}: {} by {} \\n {}\".format(type, lowest_ddate,  official.get_name(lowest_ddate_obj), lowest_ddate_obj[constants.PTR_LINK]))\n",
    "    print(\"Most recent disclosure_date for {}: {} by {}  \\n {}\\n\".format(type, highest_ddate,  official.get_name(highest_ddate_obj), highest_ddate_obj[constants.PTR_LINK]))\n",
    "    \n",
    "\n",
    "profile_dates(house_input_df, constants.HOUSE)\n",
    "profile_dates(senate_input_df, constants.SENATE)\n",
    "profile_dates(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_gender(group, normalized=None):\n",
    "    # d_prime = {'Female' : set(Officials), 'Male' : set(Officials), ...}\n",
    "    d_prime = {}\n",
    "\n",
    "    for link, name in group.items(): \n",
    "        gender = all_officials_gender[link]\n",
    "        d_prime = dict_utils.increment_set_in_dictionary(d_prime, gender, name)\n",
    "\n",
    "    # d = {'Female' : #_of_officials, 'Male' : #_of_officials, ...}\n",
    "    d = dict_utils.flatten_len(d_prime, inner_set=True)\n",
    "    \n",
    "    if normalized:\n",
    "        d = dict_utils.normalize(d, normalized, percent=True)\n",
    "        d = dict_utils.sort_dictionary_by_tuple(d)\n",
    "                 \n",
    "    return d\n",
    "\n",
    "d1 = profile_gender(input_house_officials_link, profile_gender(house_officials))\n",
    "d2 = profile_gender(input_senate_officials_link, profile_gender(senate_officials))\n",
    "d3 = profile_gender(input_all_officials_link, profile_gender(all_officials))\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"profile/gender\")\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_gender_normalized\", (d1,d2,d3), [constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "\n",
    "d1 = profile_gender(input_house_officials_link)\n",
    "d2 = profile_gender(input_senate_officials_link)\n",
    "d3 = profile_gender(input_all_officials_link)\n",
    "\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_gender\", (d1,d2,d3), [constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender (Which gender is the most active?) Active = No. of Trades &  Size of Transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_active_gender(group, normalized=None):\n",
    "    # {'gender' : 5_trades, ...}\n",
    "    d_number = {}\n",
    "    \n",
    "    # {gender : [gmean of amount, gmean of amount....] }\n",
    "    d_size = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "            name = official.get_name(t)\n",
    "            link = input_all_officials_name[name]\n",
    "            g = all_officials_gender[link]\n",
    "            \n",
    "            d_number =  dict_utils.increment_dictionary(d_number, g)\n",
    "            \n",
    "            mean =  ptr_utils.get_gmean(t[constants.AMOUNT])             \n",
    "            d_size = dict_utils.increment_list_in_dictionary(d_size, g, mean)\n",
    "\n",
    "    d_size = dict_utils.flatten_gmean(d_size)\n",
    "        \n",
    "    # Normalize\n",
    "    if normalized:\n",
    "        d_number = dict_utils.normalize(d_number, normalized, percent=True)\n",
    "        d_number = dict_utils.sort_dictionary_by_tuple(d_number)\n",
    "        \n",
    "        d_size = dict_utils.normalize(d_size, normalized, percent=True)\n",
    "        d_size = dict_utils.sort_dictionary_by_tuple(d_size)\n",
    "\n",
    "    return d_number, d_size\n",
    "\n",
    "\n",
    "d1,d4 = profile_active_gender(house_input_df, profile_gender(house_officials))\n",
    "d2,d5 = profile_active_gender(senate_input_df, profile_gender(senate_officials))\n",
    "d3,d6 = profile_active_gender(input_df, profile_gender(all_officials))\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"active\")\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_gender_number_normalized\", (d1,d2,d3), [constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_gender_size_normalized\", (d4,d5,d6), [constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "\n",
    "d1,d4 = profile_active_gender(house_input_df)\n",
    "d2,d5 = profile_active_gender(senate_input_df)\n",
    "d3,d6 = profile_active_gender(input_df)\n",
    "\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_gender_number\", (d1,d2,d3), [constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_gender_size\", (d4,d5,d6), [constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_party(group, normalized=None):\n",
    "    # d_prime = {'Republican' : set(Officials), 'Democrat' : set(Officials), ...}\n",
    "    d_prime = {}\n",
    "    \n",
    "    for (_, off_obj) in group.values(): \n",
    "        d_prime = dict_utils.increment_set_in_dictionary(d_prime, off_obj.party, off_obj.name)\n",
    "        \n",
    "    # d = {'Republican' : #_of_officials, 'Democrat' : #_of_officials, ...}\n",
    "    d = dict_utils.flatten_len(d_prime, inner_set=True)\n",
    "    \n",
    "    if normalized:         \n",
    "        d = dict_utils.normalize(d, normalized, percent=True)\n",
    "        d = dict_utils.sort_dictionary_by_tuple(d)\n",
    "\n",
    "    return d\n",
    "\n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "d1 = profile_party(input_house_officials_objects, house_officials_party)\n",
    "d2 = profile_party(input_senate_officials_objects, senate_officials_party)\n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "d3 = profile_party(input_officials_objects, all_officials_party)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"profile/party\")\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_party_normalized\", (d1,d2,d3), [constants.PARTY, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "d1 = profile_party(input_house_officials_objects)\n",
    "d2 = profile_party(input_senate_officials_objects)\n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "d3 = profile_party(input_officials_objects)\n",
    "\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_party\", (d1,d2,d3), [constants.PARTY, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Party (Which party is the most active?) Active = No. of Trades &  Size of Transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_active_party(group, normalized=None):\n",
    "    # {'party' : 5_trades, ...}\n",
    "    d_number = {}\n",
    "    \n",
    "    # {party : [gmean of amount, gmean of amount....] }\n",
    "    d_size = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "            obj = t_to_obj(t)\n",
    "            party = obj.party        \n",
    "            \n",
    "            d_number =  dict_utils.increment_dictionary(d_number, party)\n",
    "            \n",
    "            mean =  ptr_utils.get_gmean(t[constants.AMOUNT])             \n",
    "            d_size = dict_utils.increment_list_in_dictionary(d_size, party, mean)\n",
    "\n",
    "    d_size = dict_utils.flatten_gmean(d_size)\n",
    "        \n",
    "    # Normalize\n",
    "    if normalized:\n",
    "        d_number = dict_utils.normalize(d_number, normalized, percent=True)\n",
    "        d_number = dict_utils.sort_dictionary_by_tuple(d_number)\n",
    "        \n",
    "        d_size = dict_utils.normalize(d_size, normalized, percent=True)\n",
    "        d_size = dict_utils.sort_dictionary_by_tuple(d_size)\n",
    "    \n",
    "    return d_number, d_size\n",
    "\n",
    "d1,d4 = profile_active_party(house_input_df, house_officials_party)\n",
    "d2,d5 = profile_active_party(senate_input_df, senate_officials_party)\n",
    "d3,d6 = profile_active_party(input_df, all_officials_party)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"active\")\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_party_number_normalized\", (d1,d2,d3), [constants.PARTY, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_party_size_normalized\", (d4,d5,d6), [constants.PARTY, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "\n",
    "d1,d4 = profile_active_party(house_input_df)\n",
    "d2,d5 = profile_active_party(senate_input_df)\n",
    "d3,d6 = profile_active_party(input_df)\n",
    "\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_party_number\", (d1,d2,d3), [constants.PARTY, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_party_size\", (d4,d5,d6), [constants.PARTY, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_state(group, normalized=None):\n",
    "    # d_prime = {'Maryland' : set(Officials), 'California' : set(Officials), ...}\n",
    "    d_prime = {}\n",
    "    \n",
    "    # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for _, off_obj in group.values(): \n",
    "        d_prime = dict_utils.increment_set_in_dictionary(d_prime, off_obj.state, off_obj.name)\n",
    "\n",
    "    # d = {'Maryland' : #_of_officials, 'California' : #_of_officials, ...}\n",
    "    d = dict_utils.flatten_len(d_prime, inner_set=True)\n",
    "    \n",
    "    if normalized:\n",
    "        d = dict_utils.normalize(d, normalized, percent=True)\n",
    "        d = dict_utils.sort_dictionary_by_tuple(d)\n",
    "            \n",
    "    return d \n",
    "\n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "d1 = profile_state(input_house_officials_objects, house_officials_state_count)\n",
    "d2 = profile_state(input_senate_officials_objects, senate_officials_state_count)\n",
    "\n",
    "# {link : (canonical_name_input_based, official_object) ... }\n",
    "d3 = profile_state(input_officials_objects, all_officials_state_count)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"profile/state\")\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_state_normalized\", (d1,d2,d3), [constants.STATE, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "d1 = profile_state(input_house_officials_objects)\n",
    "d2 = profile_state(input_senate_officials_objects)\n",
    "\n",
    "# {link : (canonical_name_input_based, official_object) ... }\n",
    "d3 = profile_state(input_officials_objects)\n",
    "\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_state\", (d1,d2,d3), [constants.STATE, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State (Which state is the most active?) Active = No. of Trades &  Size of Transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_active_state(group, normalized=None):\n",
    "    # {'state' : 5_trades, ...}\n",
    "    d_number = {}\n",
    "    \n",
    "    # {state : [gmean of amount, gmean of amount....] }\n",
    "    d_size = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "            obj =  t_to_obj(t)\n",
    "            \n",
    "            d_number =  dict_utils.increment_dictionary(d_number, obj.state)\n",
    "            \n",
    "            mean =  ptr_utils.get_gmean(t[constants.AMOUNT])             \n",
    "            d_size = dict_utils.increment_list_in_dictionary(d_size, obj.state, mean)\n",
    "\n",
    "    d_size = dict_utils.flatten_gmean(d_size)\n",
    "    \n",
    "    if normalized:\n",
    "        d_number = dict_utils.normalize(d_number, normalized, percent=True)\n",
    "        d_number = dict_utils.sort_dictionary_by_tuple(d_number)\n",
    "        \n",
    "        d_size = dict_utils.normalize(d_size, normalized, percent=True)\n",
    "        d_size = dict_utils.sort_dictionary_by_tuple(d_size)\n",
    "\n",
    "    return d_number, d_size\n",
    "\n",
    "d1,d4 = profile_active_state(house_input_df, house_officials_state_count)\n",
    "d2,d5 = profile_active_state(senate_input_df, senate_officials_state_count)\n",
    "d3,d6 = profile_active_state(input_df, all_officials_state_count)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"active\")\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_state_number_normalized\", (d1,d2,d3), [constants.STATE, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_state_size_normalized\", (d4,d5,d6), [constants.STATE, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "\n",
    "d1,d4 = profile_active_state(house_input_df)\n",
    "d2,d5 = profile_active_state(senate_input_df)\n",
    "d3,d6 = profile_active_state(input_df)\n",
    "\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_state_number\", (d1,d2,d3), [constants.STATE, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_state_size\", (d4,d5,d6), [constants.STATE, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seniority (Lowest, Highest, Average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_seniority(group):\n",
    "    # d = {x_years_in_congress, y_years_in_congres, ...}\n",
    "    l = []\n",
    "    \n",
    "    # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for _, (_, off_obj) in group.items(): \n",
    "        l.append(off_obj.get_seniority())\n",
    "    \n",
    "    l.sort()\n",
    "    \n",
    "    d = {}\n",
    "    d[\"0. Lowest\"] = l[0]\n",
    "    d[\"1. Average\"] = round((sum(l) / len(l)))\n",
    "    d[\"2. Highest\"] = l[len(l)-1]\n",
    "\n",
    "    return d \n",
    "\n",
    "d1 = profile_seniority(input_house_officials_objects)\n",
    "d2 = profile_seniority(input_senate_officials_objects)\n",
    "d3 = profile_seniority(input_officials_objects)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"profile/seniority\")\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_seniority\", (d1,d2,d3), [constants.SENIORITY, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "def profile_seniority_normalized(group, normalized=None):\n",
    "    d = {}\n",
    "    \n",
    "    for (_, off_obj) in group.values(): \n",
    "        d = dict_utils.increment_dictionary(d, off_obj.get_seniority()) \n",
    "    \n",
    "    if normalized: \n",
    "        d_prime = dict_utils.normalize(d, normalized, percent=True)\n",
    "        return d, d_prime\n",
    "        \n",
    "    return d \n",
    "    \n",
    "d1, d4 = profile_seniority_normalized(input_house_officials_objects, profile_seniority_normalized(house_officials_objects))\n",
    "d2, d5 = profile_seniority_normalized(input_senate_officials_objects, profile_seniority_normalized(senate_officials_objects))\n",
    "d3, d6 = profile_seniority_normalized(input_officials_objects, profile_seniority_normalized(officials_objects))\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_seniority2\", (d1,d2,d3), [constants.SENIORITY, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_seniority2_normalized\", (d4,d5,d6), [constants.SENIORITY, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "\n",
    "def profile_seniority_box(group):\n",
    "    # d = {x_years_in_congress, y_years_in_congres, ...}\n",
    "    l = []\n",
    "    \n",
    "    # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for _, (_, off_obj) in group.items(): \n",
    "        l.append([off_obj.get_seniority()])\n",
    "    \n",
    "    return l\n",
    "    \n",
    "d1 = profile_seniority_box(input_house_officials_objects)\n",
    "d2 = profile_seniority_box(input_senate_officials_objects)\n",
    "csv_utils.make_csv_base(dir, \"profile_seniority_box_house\", [\"Seniority_House\"], d1)\n",
    "csv_utils.make_csv_base(dir, \"profile_seniority_box_senate\", [\"Seniority_Senate\"], d2)\n",
    "\n",
    "\n",
    "d1 = profile_seniority_box(house_officials_objects)\n",
    "d2 = profile_seniority_box(senate_officials_objects)\n",
    "csv_utils.make_csv_base(dir, \"profile_seniority_box_house_ALL\", [\"Seniority_House\"], d1)\n",
    "csv_utils.make_csv_base(dir, \"profile_seniority_box_senate_ALL\", [\"Seniority_Senate\"], d2)\n",
    "\n",
    "\n",
    "\n",
    "def profile_seniority_2(group):\n",
    "    # d = {x_years_in_congress : #_of_people, }\n",
    "    d = {}\n",
    "    \n",
    "    # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for (_, off_obj) in group.values(): \n",
    "        d =  dict_utils.increment_dictionary(d, off_obj.get_seniority())\n",
    "    \n",
    "    return d \n",
    "\n",
    "d1 = profile_seniority_2(input_house_officials_objects)\n",
    "d2 = profile_seniority_2(input_senate_officials_objects)\n",
    "d3 = profile_seniority_2(input_officials_objects)\n",
    "\n",
    "\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_seniority_2\", (d1,d2,d3), [constants.SENIORITY, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seniority (Which seniority is most active?) Active = No. of Trades & Size of Transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_active_seniority(group, normalized=None):\n",
    "    # {'seniority' : 5_peeps_with_it, ...}\n",
    "    d_number = {}\n",
    "    \n",
    "    # {'seniority' :  [gmean of amount, gmean of amount....] }\n",
    "    d_size = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "            obj = t_to_obj(t)\n",
    "            seniority = obj.get_seniority()\n",
    "            \n",
    "            d_number =  dict_utils.increment_dictionary(d_number, seniority)\n",
    "            \n",
    "            mean =  ptr_utils.get_gmean(t[constants.AMOUNT])             \n",
    "            d_size = dict_utils.increment_list_in_dictionary(d_size, seniority, mean)\n",
    "    \n",
    "    d_size = dict_utils.flatten_gmean(d_size)\n",
    "\n",
    "    # Normalize\n",
    "    if normalized: \n",
    "        d_number = dict_utils.normalize(d_number, normalized, percent=True)\n",
    "        d_size = dict_utils.normalize(d_size, normalized, percent=True)\n",
    "\n",
    "    return d_number, d_size\n",
    "\n",
    "d1,d4 = profile_active_seniority(house_input_df, profile_seniority_2(input_house_officials_objects))\n",
    "d2,d5 = profile_active_seniority(senate_input_df, profile_seniority_2(input_senate_officials_objects))\n",
    "d3,d6 = profile_active_seniority(input_df, profile_seniority_2(input_officials_objects))\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"activity\")\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_seniority_number_normalized\", (d1,d2,d3), [constants.AGE, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_seniority_size_normalized\", (d4,d5,d6), [constants.AGE, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "\n",
    "d1,d4 = profile_active_seniority(house_input_df)\n",
    "d2,d5 = profile_active_seniority(senate_input_df)\n",
    "d3,d6 = profile_active_seniority(input_df)\n",
    "\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_seniority_number\", (d1,d2,d3), [constants.AGE, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_seniority_size\", (d4,d5,d6), [constants.AGE, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get_Congress (Lowest, Highest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_congress(group):\n",
    "    lowest = highest = None \n",
    "    lowest_person = highest_person = None \n",
    "    \n",
    "    # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for (name, off_obj) in group.values():\n",
    "        res = off_obj.get_congress()\n",
    "        \n",
    "        if not lowest or res[0] < lowest:\n",
    "            lowest = res[0]\n",
    "            lowest_person = name\n",
    "    \n",
    "        if not highest or res[len(res) - 1] > highest:\n",
    "            highest = res[len(res) - 1]\n",
    "            highest_person = name \n",
    "                    \n",
    "    d = {}\n",
    "    d[\"Lowest Congress\"] = lowest, lowest_person\n",
    "    d[\"Highest Congress\"] = highest, highest_person\n",
    "\n",
    "    return d \n",
    "                        \n",
    "d1 = profile_congress(input_house_officials_objects)\n",
    "d2 = profile_congress(input_senate_officials_objects)\n",
    "d3 = profile_congress(input_officials_objects)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"profile/congress\")\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_congress\", (d1,d2,d3), [\"\", constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Degrees (Lowest, Highest, Average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_degrees_2(group, normalized=None):\n",
    "    d = {}\n",
    "    for (_, off_obj) in group.values(): \n",
    "        d = dict_utils.increment_dictionary(d, off_obj.get_num_of_degrees()) \n",
    "    \n",
    "    \n",
    "    if normalized: \n",
    "        d_prime = dict_utils.normalize(d, normalized, percent=True)\n",
    "        return d, d_prime \n",
    "    \n",
    "    return d\n",
    "    \n",
    "d1, d4 = profile_degrees_2(input_house_officials_objects, profile_degrees_2(house_officials_objects))\n",
    "d2, d5 = profile_degrees_2(input_senate_officials_objects, profile_degrees_2(senate_officials_objects))\n",
    "d3, d6 = profile_degrees_2(input_officials_objects, profile_degrees_2(officials_objects))\n",
    "\n",
    "  \n",
    "def profile_degrees(group):    \n",
    "    # d = {x_degrees, y_degrees, ...}\n",
    "    l = []\n",
    "    \n",
    "    # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for (_, off_obj) in group.values(): \n",
    "        l.append(off_obj.get_num_of_degrees())\n",
    "    \n",
    "    l.sort()\n",
    "    \n",
    "    d = {}\n",
    "    d[\"0. Lowest\"] = l[0]\n",
    "    d[\"1. Average\"] = round((sum(l) / len(l)))\n",
    "    d[\"2. Highest\"] = l[len(l)-1]\n",
    "\n",
    "    return d \n",
    "    \n",
    "d1 = profile_degrees(input_house_officials_objects)\n",
    "d2 = profile_degrees(input_senate_officials_objects)\n",
    "d3 = profile_degrees(input_officials_objects)       \n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"profile/degrees\")\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_degrees\", (d1,d2,d3), [\"No. of Degrees\", constants.HOUSE, constants.SENATE, constants.INPUT]) \n",
    "\n",
    "def profile_degrees_box(group):    \n",
    "    # d = {x_degrees, y_degrees, ...}\n",
    "    l = []\n",
    "    \n",
    "    # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for (_, off_obj) in group.values(): \n",
    "        l.append([off_obj.get_num_of_degrees()])\n",
    "    \n",
    "    return l\n",
    "    \n",
    "d1 = profile_degrees_box(input_house_officials_objects)\n",
    "d2 = profile_degrees_box(input_senate_officials_objects)\n",
    "csv_utils.make_csv_base(dir, \"profile_degrees_box_house\", [\"Degrees_House\"], d1)\n",
    "csv_utils.make_csv_base(dir, \"profile_degrees_box_senate\", [\"Degrees_Senate\"], d2)\n",
    "\n",
    "d1 = profile_degrees_box(house_officials_objects)\n",
    "d2 = profile_degrees_box(senate_officials_objects)\n",
    "csv_utils.make_csv_base(dir, \"profile_degrees_box_house_ALL\", [\"Degrees_House\"], d1)\n",
    "csv_utils.make_csv_base(dir, \"profile_degrees_box_senate_ALL\", [\"Degrees_Senate\"], d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_JD(group):\n",
    "    # d = {x_degrees, y_degrees, ...}\n",
    "    yes = total = 0 \n",
    "    \n",
    "    # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for (_, off_obj) in group.values(): \n",
    "        if off_obj.has_JD():\n",
    "            yes += 1 \n",
    "        total += 1 \n",
    "        \n",
    "    d = {}\n",
    "    \n",
    "    d[\"(Raw, Percent)\"] = (yes, round(yes/total, 2))\n",
    "    \n",
    "    return d \n",
    "    \n",
    "d1 = profile_JD(input_house_officials_objects)\n",
    "d2 = profile_JD(input_senate_officials_objects)\n",
    "d3 = profile_JD(input_officials_objects)        \n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"profile/degrees\")\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_JDs\", (d1,d2,d3), [\"\", constants.HOUSE, constants.SENATE, constants.INPUT]) \n",
    "\n",
    "\n",
    "d1 = profile_JD(house_officials_objects)\n",
    "d2 = profile_JD(senate_officials_objects)\n",
    "d3 = profile_JD(officials_objects)        \n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"profile/degrees\")\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_JDs_ALL\", (d1,d2,d3), [\"\", constants.HOUSE, constants.SENATE, constants.INPUT]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transaction Date (transaction_date) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency of Differences between Transaction and Disclosure Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_differences(group):\n",
    "    d = {}\n",
    "    # match = {}\n",
    "    total = num = 0 \n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        # Negative, X days BEFORE\n",
    "        # Positive, Y dayas AFTER\n",
    "        diff = ptr_utils.difference_between_dates(t)      \n",
    "        total += 1 \n",
    "        num += diff   \n",
    "        \n",
    "        # match = {5 days: {'Tom' : 1313, 'X': 3 , ...}. ..}\n",
    "        # match =  dict_utils.increment_dictionary_in_dictionary(match, diff, official.get_name(t))\n",
    "            \n",
    "        d =  dict_utils.increment_dictionary(d, int(diff))\n",
    "    \n",
    "    d[\"Average\"] = round(num/total, 2)\n",
    "    \n",
    "    return d \n",
    "    # return dict_utils.sort_dictionary_by_keys(d)\n",
    "\n",
    "d1 = frequency_of_differences(house_input_df)\n",
    "d2 = frequency_of_differences(senate_input_df)\n",
    "d3 = frequency_of_differences(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"frequency_of_differences\", (d1,d2,d3), [\"Difference\", constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each sector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_sector(group, diff):\n",
    "    # d_prime = {'sector' : {'date' : #_of_transactions, ....} , 'sector2' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            sector = dir_utils.search_mapping(sector_df, t[constants.TICKER], sector=True)            \n",
    "            d_prime =  dict_utils.increment_dictionary_in_dictionary(d_prime, sector, (t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    filename = \"transaction_date_wrt_sector\"  \n",
    "    if diff:\n",
    "        filename += \"_\" + diff \n",
    "    key_header = constants.SECTOR\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_sector(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_sector(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_sector(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each sector controlling for each official. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_sector_controlled(group, diff):    \n",
    "    # d_prime = { ('ticker' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            sector = dir_utils.search_mapping(sector_df, t[constants.TICKER], sector=True)  \n",
    "\n",
    "            d_prime = dict_utils.increment_set_in_inner_dictionary(d_prime, sector, t[constants.TDATE], official.get_name(t))\n",
    "       \n",
    "    \n",
    "    d_prime = dict_utils.flatten_len(d_prime)\n",
    "\n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    \n",
    "    filename = \"transaction_date_wrt_sector_controlled\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff \n",
    "     \n",
    "    key_header = constants.SECTOR\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_sector_controlled(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_sector_controlled(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_sector_controlled(input_df, constants.INPUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_industry(group, diff):    \n",
    "    # d_prime = {'industry' : {'date' : #_of_transactions, ....} , 'industry2' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            industry = dir_utils.search_mapping(industry_df, t[constants.TICKER], industry=True)\n",
    "\n",
    "            d_prime =  dict_utils.increment_dictionary_in_dictionary(d_prime, industry, (t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    filename = \"transaction_date_wrt_industry\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff  \n",
    "    key_header = constants.INDUSTRY\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_industry(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_industry(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_industry(input_df, constants.INPUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each industry controlling for official. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_industry_controlled(group, diff):\n",
    "    \n",
    "    # d_prime = { ('ticker' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            industry = dir_utils.search_mapping(industry_df, t[constants.TICKER], industry=True)\n",
    "            \n",
    "            d_prime = dict_utils.increment_set_in_inner_dictionary(d_prime, industry, t[constants.TDATE],  official.get_name(t))\n",
    "\n",
    "    d_prime = dict_utils.flatten_len(d_prime)\n",
    "    \n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "    \n",
    "    filename = \"transaction_date_wrt_industry_controlled\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff  \n",
    "    key_header = constants.INDUSTRY\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_industry_controlled(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_industry_controlled(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_industry_controlled(input_df, constants.INPUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each ticker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_ticker(group, diff):    \n",
    "    # d_prime = {'ticker' : {'date' : #_of_transactions, ....} , 'ticker2' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime =  dict_utils.increment_dictionary_in_dictionary(d_prime, t[constants.TICKER], (t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    filename = \"transaction_date_wrt_ticker\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "    key_header = constants.TICKER\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_ticker(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_ticker(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_ticker(input_df, constants.INPUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each ticker controlling for official."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_ticker_controlled(group, diff):    \n",
    "    # d_prime = { ('ticker' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():    \n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):    \n",
    "            name = official.get_name(t)\n",
    "            d_prime = dict_utils.increment_set_in_inner_dictionary(d_prime, t[constants.TICKER], t[constants.TDATE], name)\n",
    "       \n",
    "    d_prime = dict_utils.flatten_len_inner_set(d_prime)\n",
    "\n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    \n",
    "    filename = \"transaction_date_wrt_ticker_controlled\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff  \n",
    "        \n",
    "    key_header = constants.TICKER\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_ticker_controlled(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_ticker_controlled(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_ticker_controlled(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             type transaction_date  number_of_transactions\n",
      "0        Purchase       2020/03/18                     204\n",
      "1     Sale (Full)       2019/06/24                     204\n",
      "2  Sale (Partial)       2020/11/13                      60\n",
      "3        Exchange       2020/02/24                      18\n",
      "             type transaction_date  number_of_transactions\n",
      "0     Sale (Full)       2020/04/14                     116\n",
      "1        Purchase       2017/03/16                      78\n",
      "2  Sale (Partial)       2020/04/14                      26\n",
      "3        Exchange       2017/09/01                       5\n",
      "             type transaction_date  number_of_transactions\n",
      "0        Purchase       2020/03/18                     212\n",
      "1     Sale (Full)       2019/06/24                     204\n",
      "2  Sale (Partial)       2020/11/13                      60\n",
      "3        Exchange       2020/02/24                      18\n"
     ]
    }
   ],
   "source": [
    "def transaction_date_wrt_type(group, diff):        \n",
    "    # d_prime = {'type' : {'date' : #_of_transactions, ....} , 'type2' : .... }\n",
    "    d_prime = {}\n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime =  dict_utils.increment_dictionary_in_dictionary(d_prime, (t[constants.TYPE]), (t[constants.TDATE]))\n",
    "    \n",
    "    # d = {'type' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    filename = \"transaction_date_wrt_type\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff  \n",
    "    key_header = constants.TYPE\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df)\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_type(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_type(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_type(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for type controlling for official. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_type_controlled(group, diff):    \n",
    "    # d_prime = { ('type' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime = dict_utils.increment_set_in_inner_dictionary(d_prime, t[constants.TYPE], (t[constants.TDATE]), official.get_name(t))\n",
    "       \n",
    "\n",
    "    d_prime = dict_utils.flatten_len(d_prime)\n",
    "            \n",
    "    # d = {'type' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "    \n",
    "    \n",
    "    filename = \"transaction_date_wrt_type_controlled\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff  \n",
    "    key_header = constants.TYPE\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_type_controlled(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_type_controlled(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_type_controlled(input_df, constants.INPUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_amount(group, diff):\n",
    "    # d_prime = {'amount' : {'date' : #_of_transactions, ....} , 'amount1' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            amount = ptr_utils.consistency_amount(t)\n",
    "            d_prime =  dict_utils.increment_dictionary_in_dictionary(d_prime, amount, (t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'type' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "    d = dict_utils.add_sort_key_for_amount(d)\n",
    "    d = dict_utils.sort_dictionary_by_sort_key(d)\n",
    "\n",
    "    filename = \"transaction_date_wrt_amount\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff  \n",
    "    key_header = constants.TYPE\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, key_header)\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_amount(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_amount(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_amount(input_df, constants.INPUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for amount controlling for official."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_amount_controlled(group, diff):\n",
    "    # d_prime = { ('amount' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "            amount = ptr_utils.consistency_amount(t)\n",
    "            d_prime = dict_utils.increment_set_in_inner_dictionary(d_prime, amount, (t[constants.TDATE]), official.get_name(t))\n",
    "       \n",
    "\n",
    "    d_prime = dict_utils.flatten_len(d_prime)\n",
    "        \n",
    "    # d = {'amount' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "    d = dict_utils.add_sort_key_for_amount(d)\n",
    "    d = dict_utils.sort_dictionary_by_sort_key(d)\n",
    "    \n",
    "    \n",
    "    filename = \"transaction_date_wrt_amount_controlled\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff  \n",
    "    key_header = constants.AMOUNT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, key_header)\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_amount_controlled(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_amount_controlled(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_amount_controlled(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each official."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_official(group, diff):\n",
    "    # d_prime = {'person1' : {'date' : #_of_transactions, ....} , 'person2' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime =  dict_utils.increment_dictionary_in_dictionary(d_prime, official.get_name(t), (t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'person' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    filename = \"transaction_date_wrt_official\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff \n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [constants.OFFICIAL, constants.TDATE, constants.NUMT])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "transaction_date_wrt_official_res = transaction_date_wrt_official(house_input_df, constants.HOUSE)\n",
    "transaction_date_wrt_official_res = transaction_date_wrt_official(senate_input_df, constants.SENATE)\n",
    "transaction_date_wrt_official_res = transaction_date_wrt_official(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_per_date(group):\n",
    "    d={}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        d =  dict_utils.increment_dictionary(d, (t[constants.TDATE]))\n",
    "\n",
    "    return d \n",
    "\n",
    "d1 = num_of_trans_per_date(house_input_df)\n",
    "d2 = num_of_trans_per_date(senate_input_df)\n",
    "d3 = num_of_trans_per_date(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_per_date\", (d1,d2,d3), [constants.TDATE, constants.HOUSE, constants.SENATE, constants.INPUT])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Transactions per Date Controlled\n",
    "_Number of transactions per date controlled by official. E.g. if Ted Baker made 40 transactions on 1/1/02 and Sam Wall made 2 transactions on 1/1/02, we conclude that there were two transactions on 1/1/02._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_per_date_controlled(group):    \n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        d =  dict_utils.increment_dictionary_in_dictionary(d, (t[constants.TDATE]), official.get_name(t))\n",
    "\n",
    "    return dict_utils.flatten_len(d, inner_set=True)\n",
    "    \n",
    "d1 = num_of_trans_per_date_controlled(house_input_df)\n",
    "d2 = num_of_trans_per_date_controlled(senate_input_df)\n",
    "d3 = num_of_trans_per_date_controlled(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_per_date_controlled\", (d1,d2,d3), [constants.TDATE, constants.HOUSE, constants.SENATE, constants.INPUT])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Transactions Within 2 Weeks Prior to Quarterly Tax Date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_within_tax_date(group):        \n",
    "        total = within = 0 \n",
    "        d = {}\n",
    "\n",
    "        for _,t in group.iterrows():  \n",
    "                total += 1 \n",
    "                if ptr_utils.within_tax_date(t[constants.TDATE]):\n",
    "                        within += 1 \n",
    "\n",
    "        d[\"(No. of transactions within 2 weeks of tax deadline, %)\"] = (within,  round(within/total, 2))\n",
    "\n",
    "        return d \n",
    "\n",
    "d1 = num_of_trans_within_tax_date(house_input_df)\n",
    "d2 = num_of_trans_within_tax_date(senate_input_df)\n",
    "d3 = num_of_trans_within_tax_date(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_within_tax_date\", (d1,d2,d3), [\"\", constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Transactions Within 2 Weeks Prior to Quarterly Tax Date Semi-Controlled \n",
    "\n",
    "_Given dict='09/03/2021': {'Thomas H Tuberville': 1, 'Cynthia M Lummis': 1, 'A. Mitchell Mcconnell, Jr.': 1}...I only incremement the number of within (tax date) once per date per official. So, if an official does 100 transactions on a date within two weeks of a quarterly deadline, then I only count it as one transaction._\n",
    "\n",
    "_A Note: total === number of transactions per person per date (so not really all transactions) because someone could have potentially made 60 transactions on one date which we don't include in neither total or within, if applicable._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_within_tax_date_controlled(group):\n",
    "        total = within = 0 \n",
    "        people = set()\n",
    "        d = {}\n",
    "\n",
    "        for _, t in group.iterrows():\n",
    "                name = official.get_name(t)\n",
    "                if ptr_utils.within_tax_date(t[constants.TDATE]) and name not in people:\n",
    "                        people.add(name)\n",
    "                        within += 1 \n",
    "                total += 1         \n",
    "                \n",
    "        d[\"(No. of transactions within 2 weeks of tax deadline, %)\"] = (within,  round(within/total, 2))\n",
    "\n",
    "        return d\n",
    "\n",
    "d1 = num_of_trans_within_tax_date_controlled(house_input_df)\n",
    "d2 = num_of_trans_within_tax_date_controlled(senate_input_df)\n",
    "d3 = num_of_trans_within_tax_date_controlled(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_within_tax_date_controlled\", (d1,d2,d3), [\"\", constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def people_and_within_tax_date(people):        \n",
    "#         # todo get number of senators. \n",
    "#         # todo is the monetary value of that equal!!!! \n",
    "#         d = {}\n",
    "#         for i in people:\n",
    "#                 d[i] = \"\"\n",
    "                \n",
    "#         d = dict_utils.sort_dictionary_by_keys(d)\n",
    "        \n",
    "#         dir = dir_utils.makesubdir(constants.path_csv, \"transaction_date/tax\")\n",
    "#         wd = csv_utils.make_csv(dir, \"people_and_within_tax_date_list\", d, [\"Officials\"])\n",
    "#         df = pd.read_csv(wd)\n",
    "#         print(\"People who posted transactions within two weeks of quarterly tax deadline:\\n {}\\n\".format(df.head(5)))\n",
    "\n",
    "#         print(\"Number of people who posted transactions within two weeks of quarterly tax deadline: {}\\n\".format(len(people)))\n",
    "        \n",
    "#         party = {}\n",
    "#         for p in people:\n",
    "#                 link = search.get_wiki_link(p)\n",
    "#                 _, obj = input_officials_objects[link]\n",
    "#                 party =  dict_utils.increment_dictionary(party, obj.party)\n",
    "                \n",
    "#         party = dict_utils.sort_dictionary_by_values(party)\n",
    "        \n",
    "#         wd = csv_utils.make_csv(dir, \"people_and_within_tax_date_list_w_aff\", party, [\"party\", \"number_of_filing_within_tax_date\"])\n",
    "#         df = pd.read_csv(wd)\n",
    "#         print(\"Party breakdown of people who posted transactions within two weeks of quarterly tax deadline:\\n {}\\n\".format(df.head(5)))\n",
    "\n",
    "# people_and_within_tax_date(num_of_trans_within_tax_date_controlled_res_house)\n",
    "# people_and_within_tax_date(num_of_trans_within_tax_date_controlled_res_senate)\n",
    "# people_and_within_tax_date(num_of_trans_within_tax_date_controlled_res_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def people_and_within_tax_date_how_often(people):\n",
    "\n",
    "#         d = {}\n",
    "#         d_controlled_by_dates = {}\n",
    "        \n",
    "#         for _,t in input_df.iterrows():\n",
    "#                 if official.get_canonical_name(t[title]) in people and ptr_utils.within_tax_date(t[constants.TDATE]):\n",
    "#                         d =  dict_utils.increment_dictionary(d, t[title])\n",
    "#                         d_controlled_by_dates =  dict_utils.increment_dictionary_in_dictionary(d_controlled_by_dates, t[constants.TDATE], t[title])\n",
    "\n",
    "#         d_controlled_by_dates_res  = {}\n",
    "#         for date in d_controlled_by_dates:\n",
    "#                 for person in d_controlled_by_dates[date]:\n",
    "#                         d_controlled_by_dates_res =  dict_utils.increment_dictionary(d_controlled_by_dates_res, person)\n",
    "\n",
    "#         d = dict_utils.sort_dictionary_by_values(d)\n",
    "#         d_controlled_by_dates_res = dict_utils.sort_dictionary_by_values(d_controlled_by_dates_res)\n",
    "\n",
    "#         dir = dir_utils.makesubdir(constants.path_csv, \"transaction_date/tax\")\n",
    "#         wd = csv_utils.make_csv(dir, \"people_and_within_tax_date_how_often\", d, [title, \"number_of_filing_within_tax_date\"])\n",
    "#         df = pd.read_csv(wd)\n",
    "#         print(\"People who posted transactions within two weeks of quarterly tax deadline and the number of transactions posted:\\n {}\\n\".format(df.head(5)))\n",
    "\n",
    "#         wd = csv_utils.make_csv(dir, \"people_and_within_tax_date_how_often_date_controlled\", d_controlled_by_dates_res, [title, \"number_of_filing_within_tax_date_date_controlled\"])\n",
    "#         df = pd.read_csv(wd)\n",
    "#         print(\"People who posted transactions within two weeks of quarterly tax deadline and the number of transactions posted controlled by date:\\n {}\\n\".format(df.head(5)))\n",
    "\n",
    "          \n",
    "# people_and_within_tax_date_how_often(num_of_trans_within_tax_date_controlled_res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Owner (owner) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Count of Owner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_count_of_owner(group):\n",
    "    # d = {'Joint' : 5}\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if constants.OWNER in t and ptr_utils.isvalid(t[constants.OWNER]):                \n",
    "            d =  dict_utils.increment_dictionary(d, t[constants.OWNER].capitalize())\n",
    "        \n",
    "    return dict_utils.sort_dictionary_by_values(d)\n",
    "    \n",
    "    \n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "d1 = freq_count_of_owner(house_input_df)\n",
    "d2 = freq_count_of_owner(senate_input_df)\n",
    "\n",
    "# {link : (canonical_name_input_based, official_object) ... }\n",
    "d3 = freq_count_of_owner(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.OWNER)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"freq_count_of_owner\", (d1,d2,d3), [\"Owner\", constants.HOUSE, constants.SENATE, constants.INPUT]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'Carper, Thomas R. (D-DE)': 957, 'Roberts, Pat (R-KS)': 451, 'Collins, Susan M. (R-ME)': 395, 'Capito, Shelley M. (R-WV)': 350, 'Wyden, Ronald L. (D-OR)': 230, 'Loeffler, Kelly (R-GA)': 169, 'Cassidy, William (R-LA)': 163, 'Murray, Patty (D-WA)': 161, 'Scott, Rick (R-FL)': 142, 'Moran, Jerry (R-KS)': 72, 'Whitehouse, Sheldon (D-RI)': 68, 'King Jr., Angus S. (I-ME)': 67, 'Alexander, Lamar (R-TN)': 57, 'McConnell Jr., A. M. (R-KY)': 22, 'Smith, Tina (D-MN)': 20, 'Manchin III, Joseph (D-WV)': 12, 'Hickenlooper, John W. (D-CO)': 11, 'Blunt, Roy D. (R-MO)': 8, 'Wicker, Roger F. (R-MS)': 8, 'Warner, Mark R. (D-VA)': 7, 'Cardin, Benjamin L. (D-MD)': 6, 'Toomey, Patrick J. (R-PA)': 6, 'Coons, Christopher A. (D-DE)': 5, 'Hoeven, John (R-ND)': 4, 'Shaheen, Jeanne (D-NH)': 3, 'Peters, Gary C. (D-MI)': 2, 'Rosen, Jacklyn S. (D-NV)': 1, 'Marshall, Roger W. (R-KS)': 1, 'Paul, Rand (R-KY)': 1, 'Kaine, Timothy M. (D-VA)': 1, 'Sullivan, Daniel S. (R-AK)': 1, 'Perdue Jr., David A. (R-GA)': 1, 'Rounds, Mike (R-SD)': 1, 'Tillis, Thomas R. (R-NC)': 1}\n",
      "{'Carper, Thomas R. (D-DE)': 957, 'Roberts, Pat (R-KS)': 451, 'Collins, Susan M. (R-ME)': 395, 'Capito, Shelley M. (R-WV)': 350, 'Wyden, Ronald L. (D-OR)': 230, 'Loeffler, Kelly (R-GA)': 169, 'Cassidy, William (R-LA)': 163, 'Murray, Patty (D-WA)': 161, 'Scott, Rick (R-FL)': 142, 'Moran, Jerry (R-KS)': 72, 'Whitehouse, Sheldon (D-RI)': 68, 'King Jr., Angus S. (I-ME)': 67, 'Alexander, Lamar (R-TN)': 57, 'McConnell Jr., A. M. (R-KY)': 22, 'Smith, Tina (D-MN)': 20, 'Manchin III, Joseph (D-WV)': 12, 'Hickenlooper, John W. (D-CO)': 11, 'Blunt, Roy D. (R-MO)': 8, 'Wicker, Roger F. (R-MS)': 8, 'Warner, Mark R. (D-VA)': 7, 'Cardin, Benjamin L. (D-MD)': 6, 'Toomey, Patrick J. (R-PA)': 6, 'Coons, Christopher A. (D-DE)': 5, 'Hoeven, John (R-ND)': 4, 'Shaheen, Jeanne (D-NH)': 3, 'Peters, Gary C. (D-MI)': 2, 'Rosen, Jacklyn S. (D-NV)': 1, 'Marshall, Roger W. (R-KS)': 1, 'Paul, Rand (R-KY)': 1, 'Kaine, Timothy M. (D-VA)': 1, 'Sullivan, Daniel S. (R-AK)': 1, 'Perdue Jr., David A. (R-GA)': 1, 'Rounds, Mike (R-SD)': 1, 'Tillis, Thomas R. (R-NC)': 1}\n"
     ]
    }
   ],
   "source": [
    "def freq_count_by_spouse(group):\n",
    "    # d = {'x_spouse' : 5}\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if constants.OWNER in t and ptr_utils.isvalid(t[constants.OWNER]) and t[constants.OWNER].capitalize() == 'Spouse':\n",
    "            obj = t_to_obj(t)\n",
    "            d =  dict_utils.increment_dictionary(d, obj.get_label())\n",
    "    \n",
    "    d = dict_utils.sort_dictionary_by_values(d)\n",
    "    print(d)\n",
    "    return d\n",
    "    \n",
    "    \n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "d1 = freq_count_by_spouse(house_input_df)\n",
    "d2 = freq_count_by_spouse(senate_input_df)\n",
    "\n",
    "# {link : (canonical_name_input_based, official_object) ... }\n",
    "d3 = freq_count_by_spouse(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.OWNER)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"freq_count_by_spouse\", (d1,d2,d3), [\"Owner\", constants.HOUSE, constants.SENATE, constants.INPUT]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ticker (ticker) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_tickers(group):\n",
    "    # d = {'ticker' : #_of_times }\n",
    "    d = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d =  dict_utils.increment_dictionary(d, t[constants.TICKER])\n",
    "       \n",
    "\n",
    "    return dict_utils.sort_dictionary_by_values(d, reverse=True)\n",
    "\n",
    "d1 = num_of_tickers(house_input_df)\n",
    "d2 = num_of_tickers(senate_input_df)\n",
    "d3 = num_of_tickers(input_df)\n",
    "    \n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.TICKER)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_tickers\", (d1,d2,d3), [constants.TICKER, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Ticker per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_ticker_breakdown_year(group, diff):\n",
    "    d = {}\n",
    "\n",
    "    # {\"ticker\" : {\"year\" : number, \"year\" : number, ...}}\n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d = dict_utils.increment_dictionary_in_dictionary(d, t[constants.TICKER], ptr_utils.get_year(t[constants.TDATE]))\n",
    "            d = dict_utils.increment_dictionary_in_dictionary(d, t[constants.TICKER], 9999)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_keys(d)\n",
    "    filename = \"frequency_of_ticker_breakdown_year\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "    key_header = constants.TICKER\n",
    "    \n",
    "    \n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TICKER)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "\n",
    "frequency_of_ticker_breakdown_year(house_input_df, constants.HOUSE)\n",
    "frequency_of_ticker_breakdown_year(senate_input_df, constants.SENATE)\n",
    "frequency_of_ticker_breakdown_year(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Ticker per Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_ticker_by_date(group, diff):\n",
    "    # {ticker : {date : ___}}\n",
    "    d = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d = dict_utils.increment_dictionary_in_dictionary(d, t[constants.TICKER], t[constants.TDATE])\n",
    "\n",
    "    \n",
    "    d = dict_utils.flatten_best(d)\n",
    "    \n",
    "\n",
    "    filename = \"frequency_of_ticker_by_date\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "    \n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TICKER)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, constants.TICKER)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "\n",
    "d1 = frequency_of_ticker_by_date(house_input_df, constants.HOUSE)\n",
    "d2 = frequency_of_ticker_by_date(senate_input_df, constants.SENATE)\n",
    "d3 = frequency_of_ticker_by_date(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Industry & Sector "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Transactions per Industry\n",
    "_Not controlled in any way._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_transactions_per_indusry(group):        \n",
    "    d = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            industry = dir_utils.search_mapping(industry_df, t[constants.TICKER], industry=True)\n",
    "            d = dict_utils.increment_dictionary(d, industry)\n",
    "\n",
    "    return dict_utils.sort_dictionary_by_values(d)\n",
    "    \n",
    "\n",
    "d1 = number_of_transactions_per_indusry(house_input_df)\n",
    "d2 = number_of_transactions_per_indusry(senate_input_df)\n",
    "d3 = number_of_transactions_per_indusry(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.INDUSTRY)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"number_of_transactions_per_indusry\", (d1,d2,d3), [constants.INDUSTRY, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "\n",
    "\n",
    "def number_of_transactions_per_sector(group):        \n",
    "    d = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            sector = dir_utils.search_mapping(sector_df, t[constants.TICKER], sector=True)\n",
    "            d = dict_utils.increment_dictionary(d, sector)\n",
    "\n",
    "    return dict_utils.sort_dictionary_by_values(d)\n",
    "    \n",
    "\n",
    "d1 = number_of_transactions_per_sector(house_input_df)\n",
    "d2 = number_of_transactions_per_sector(senate_input_df)\n",
    "d3 = number_of_transactions_per_sector(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.SECTOR)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"number_of_transactions_per_sector\", (d1,d2,d3), [constants.SECTOR, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Industry Breakdown per Official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_industry_breakdown_official(group, diff):\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            industry = dir_utils.search_mapping(industry_df, t[constants.TICKER], industry=True)\n",
    "            d = dict_utils.increment_dictionary_in_dictionary(d, official.get_name(t), industry)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_keys(d)\n",
    "    \n",
    "    filename = \"frequency_of_industry_breakdown_official\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.INDUSTRY)\n",
    "\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, constants.OFFICIAL)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "    \n",
    "    return d \n",
    "\n",
    "d1 = frequency_of_industry_breakdown_official(house_input_df, constants.HOUSE)\n",
    "d2 = frequency_of_industry_breakdown_official(senate_input_df, constants.SENATE)\n",
    "d3 = frequency_of_industry_breakdown_official(input_df, constants.INPUT)\n",
    "\n",
    "\n",
    "\n",
    "def frequency_of_sector_breakdown_official(group, diff):\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            sector = dir_utils.search_mapping(sector_df, t[constants.TICKER], sector=True)\n",
    "            d = dict_utils.increment_dictionary_in_dictionary(d, official.get_name(t), sector)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_keys(d)\n",
    "    \n",
    "    filename = \"frequency_of_sector_breakdown_official\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.SECTOR)\n",
    "\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, constants.OFFICIAL)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "    \n",
    "    return d \n",
    "\n",
    "d1 = frequency_of_sector_breakdown_official(house_input_df, constants.HOUSE)\n",
    "d2 = frequency_of_sector_breakdown_official(senate_input_df, constants.SENATE)\n",
    "d3 = frequency_of_sector_breakdown_official(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency of Industry per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_industry_breakdown(group, diff):\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():     \n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            industry = dir_utils.search_mapping(industry_df, t[constants.TICKER], industry=True)  \n",
    "            d = dict_utils.increment_dictionary_in_dictionary(d, industry, ptr_utils.get_year(t[constants.TDATE]))\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_keys(d)\n",
    "    \n",
    "    filename = \"frequency_of_industry_breakdown\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff \n",
    "    key_header = \"industry\"\n",
    "    \n",
    "    \n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.INDUSTRY)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "    return d \n",
    "\n",
    "d1 = frequency_of_industry_breakdown(house_input_df, constants.HOUSE)\n",
    "d2 = frequency_of_industry_breakdown(senate_input_df, constants.SENATE)\n",
    "d3 = frequency_of_industry_breakdown(input_df, constants.INPUT)\n",
    "\n",
    "\n",
    "def frequency_of_sector_breakdown(group, diff):\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():     \n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            sector = dir_utils.search_mapping(sector_df, t[constants.TICKER], sector=True)  \n",
    "            d = dict_utils.increment_dictionary_in_dictionary(d, sector, ptr_utils.get_year(t[constants.TDATE]))\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_keys(d)\n",
    "    \n",
    "    filename = \"frequency_of_sector_breakdown\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff \n",
    "    key_header = \"sector\"\n",
    "    \n",
    "    \n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.SECTOR)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "    return d \n",
    "\n",
    "d1 = frequency_of_sector_breakdown(house_input_df, constants.HOUSE)\n",
    "d2 = frequency_of_sector_breakdown(senate_input_df, constants.SENATE)\n",
    "d3 = frequency_of_sector_breakdown(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asset Description (asset_description) and Comment (comment) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_options(group):\n",
    "    count = total = 0 \n",
    "    d = {}\n",
    "    # [this_person_placed_an_option, ...]\n",
    "    people = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if constants.ASSET_DESCRIPTION in t and ptr_utils.isvalid(t[constants.ASSET_DESCRIPTION]) and (\"Put\" in t[constants.ASSET_DESCRIPTION]  or \"put\" in t[constants.ASSET_DESCRIPTION]  or \"Call\" in t[constants.ASSET_DESCRIPTION]  or \"call\" in t[constants.ASSET_DESCRIPTION]  or \"Option\" in t[constants.ASSET_DESCRIPTION] or \"option\" in t[constants.ASSET_DESCRIPTION]): \n",
    "            count += 1 \n",
    "            obj = t_to_obj(t)\n",
    "            people = dict_utils.increment_dictionary(people, (obj.get_label(), obj.get_color()))\n",
    "        total += 1 \n",
    "\n",
    "    d[\"(No. of Options, %)\"] = (count, round(count/total, 2))\n",
    "\n",
    "    return d \n",
    "            \n",
    "d1 = number_of_options(house_input_df)\n",
    "d2 = number_of_options(senate_input_df)\n",
    "d3 = number_of_options(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.COMMENT)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"number_of_options\", (d1,d2,d3), [\"\", constants.HOUSE, constants.SENATE, constants.INPUT])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Scanned PDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_scanned_pdfs(group):\n",
    "    count = total = 0 \n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if t[constants.ASSET_DESCRIPTION] == constants.DISCLOSED:\n",
    "            count += 1 \n",
    "        total += 1 \n",
    "            \n",
    "    d[\"(No. of Scanned PDFS, %)\"] = (count, round(count/total, 2))\n",
    "\n",
    "    return d \n",
    "            \n",
    "d1 = number_of_scanned_pdfs(house_input_df)\n",
    "d2 = number_of_scanned_pdfs(senate_input_df)\n",
    "d3 = number_of_scanned_pdfs(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.COMMENT)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"number_of_scanned_pdfs\", (d1,d2,d3), [\"\", constants.HOUSE, constants.SENATE, constants.INPUT])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asset Type (asset_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Asset Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_asset_type(group):\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if constants.ATYPE in t and ptr_utils.isvalid(t[constants.ATYPE]):\n",
    "            d = dict_utils.increment_dictionary(d, t[constants.ATYPE])\n",
    "      \n",
    "    return dict_utils.sort_dictionary_by_values(d)\n",
    "\n",
    "d1 = frequency_of_asset_type(house_input_df)\n",
    "d2 = frequency_of_asset_type(senate_input_df)\n",
    "d3 = frequency_of_asset_type(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.ATYPE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"frequency_of_asset_type\", (d1,d2,d3), [constants.ATYPE, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amount "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Amount by Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_amount_by_persom(group, diff):\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        amount = ptr_utils.consistency_amount(t)\n",
    "        d = dict_utils.increment_dictionary_in_dictionary(d, official.get_name(t), amount)\n",
    "    \n",
    "    d = dict_utils.sort_dictionary_by_keys(d)\n",
    "    \n",
    "    filename = \"frequency_of_amount_by_person\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff \n",
    "        \n",
    "    key_header = constants.AMOUNT\n",
    "    \n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.AMOUNT)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "    \n",
    "    return d \n",
    "   \n",
    "    \n",
    "d1 = frequency_of_amount_by_persom(house_input_df, constants.HOUSE)\n",
    "d2 = frequency_of_amount_by_persom(senate_input_df, constants.SENATE)\n",
    "# d3 = frequency_of_amount_by_persom(input_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Transactions by Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "def frequency_of_amount_total(group):\n",
    "    d = {}        \n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        amount = ptr_utils.consistency_amount(t)                    \n",
    "        d = dict_utils.increment_dictionary(d, amount)\n",
    "\n",
    "    return d\n",
    "    \n",
    "d1 = frequency_of_amount_total(house_input_df)\n",
    "d2 = frequency_of_amount_total(senate_input_df)\n",
    "d3 = frequency_of_amount_total(input_df)\n",
    "\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.AMOUNT)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"frequency_of_amount_total\", (d1,d2,d3), [constants.AMOUNT, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Amount by Gender "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_amount_by_gender(group, diff, normalized=None):\n",
    "    d = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        name = official.get_name(t)\n",
    "        link = input_all_officials_name[name]\n",
    "        amount = ptr_utils.consistency_amount(t)\n",
    "        d = dict_utils.increment_dictionary_in_dictionary(d, amount, all_officials_gender[link])\n",
    "\n",
    "    if normalized: \n",
    "        for amount in d:\n",
    "            for gender in d[amount]:\n",
    "                d[amount][gender] /= normalized[gender]\n",
    "        \n",
    "    d = dict_utils.add_sort_key_for_amount(d)\n",
    "    d = dict_utils.sort_dictionary_by_sort_key(d)\n",
    "\n",
    "\n",
    "    filename = \"frequency_of_amount_by_gender\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "    if normalized:\n",
    "        filename += \"_normalized\"\n",
    "    \n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.AMOUNT)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, constants.AMOUNT)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "    return d \n",
    "   \n",
    "d1 = frequency_of_amount_by_gender(house_input_df, constants.HOUSE, profile_gender(input_house_officials_link))\n",
    "d2 = frequency_of_amount_by_gender(senate_input_df, constants.SENATE, profile_gender(input_senate_officials_link))\n",
    "d3 = frequency_of_amount_by_gender(input_df, constants.INPUT, profile_gender(input_all_officials_link))\n",
    "    \n",
    "d1 = frequency_of_amount_by_gender(house_input_df, constants.HOUSE)\n",
    "d2 = frequency_of_amount_by_gender(senate_input_df, constants.SENATE)\n",
    "d3 = frequency_of_amount_by_gender(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Transactions by Political Affiliation and Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_amount_by_aff(group, diff):\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        obj = t_to_obj(t)\n",
    "        amount = ptr_utils.consistency_amount(t)            \n",
    "        d = dict_utils.increment_dictionary_in_dictionary(d, amount, obj.party)\n",
    "\n",
    "\n",
    "    d = dict_utils.add_sort_key_for_amount(d)\n",
    "    d = dict_utils.sort_dictionary_by_sort_key(d)\n",
    "    \n",
    "        \n",
    "    filename = \"frequency_of_amount_by_aff\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "    \n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.AMOUNT)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, constants.AMOUNT)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "    \n",
    "    return d \n",
    "   \n",
    "    \n",
    "d1 = frequency_of_amount_by_aff(house_input_df, constants.HOUSE)\n",
    "d2 = frequency_of_amount_by_aff(senate_input_df, constants.SENATE)\n",
    "d3 = frequency_of_amount_by_aff(input_df, constants.INPUT) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_activity(group, diff):\n",
    "    d={}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "                        \n",
    "            mean = ptr_utils.get_gmean(t[constants.AMOUNT])\n",
    "\n",
    "            d = dict_utils.increment_list_in_dictionary(d, official.get_name(t), mean)\n",
    "\n",
    "\n",
    "    d = dict_utils.flatten_gmean(d)        \n",
    "            \n",
    "    filename = \"average_activity\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "\n",
    "    key_header = constants.OFFICIAL \n",
    "    value_header = \"average_size_of_transactions\"\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_values(d)\n",
    "    d = dict_utils.commify(d)\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.AMOUNT)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "\n",
    "    return d \n",
    "\n",
    "d1 = average_activity(house_input_df, constants.HOUSE)\n",
    "d2 = average_activity(senate_input_df, constants.SENATE)\n",
    "d3 = average_activity(input_df, constants.INPUT) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types (type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Actions Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_act(group):\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TYPE]):\n",
    "            d = dict_utils.increment_dictionary(d, t[constants.TYPE])\n",
    "    \n",
    "    return dict_utils.sort_dictionary_by_values(d)\n",
    "    \n",
    "     \n",
    "d1 = frequency_of_act(house_input_df)\n",
    "d2 = frequency_of_act(senate_input_df)\n",
    "d3 = frequency_of_act(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.TYPE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"frequency_of_act\", (d1,d2,d3), [constants.TYPE, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Transactions per Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def types_of_transactions_per_person(group, diff, normalized=None):\n",
    "    d={}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        d = dict_utils.increment_dictionary_in_dictionary(d, official.get_name(t), t[constants.TYPE])\n",
    "        d = dict_utils.increment_dictionary_in_dictionary(d, official.get_name(t), constants.TOTAL)\n",
    "\n",
    "\n",
    "    if normalized: \n",
    "        for k,v in d.items():\n",
    "            newinner = {}\n",
    "            for ik, iv in v.items():\n",
    "                link = input_all_officials_name[k]\n",
    "                _, obj = input_officials_objects[link]\n",
    "                newinner[ik] = round(iv/obj.get_seniority(), 2)\n",
    "                \n",
    "            d[k] = newinner\n",
    "    \n",
    "    filename = \"types_of_transactions_per_person\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "    if normalized:\n",
    "        filename += \"_normalized\"\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_keys(d)\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TYPE)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, constants.OFFICIAL)\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "\n",
    "    return d \n",
    "\n",
    "d1 = types_of_transactions_per_person(house_input_df, constants.HOUSE)\n",
    "d2 = types_of_transactions_per_person(senate_input_df, constants.SENATE)\n",
    "d3 = types_of_transactions_per_person(input_df, constants.INPUT)\n",
    "\n",
    "d1 = types_of_transactions_per_person(house_input_df, constants.HOUSE, normalized=True)\n",
    "d2 = types_of_transactions_per_person(senate_input_df, constants.SENATE, normalized=True)\n",
    "d3 = types_of_transactions_per_person(input_df, constants.INPUT, normalized=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_per_year(group, normalized=None):\n",
    "    d={}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        d =  dict_utils.increment_dictionary(d, ptr_utils.get_year(t[constants.TDATE]))\n",
    "\n",
    "    if normalized:\n",
    "        d2 = {}\n",
    "        for k,v in d.items():\n",
    "            d2[k] = v/normalized\n",
    "            \n",
    "        \n",
    "    return dict_utils.sort_dictionary_by_values(d), dict_utils.sort_dictionary_by_values(d2)\n",
    "\n",
    "d1, d4 = num_of_trans_per_year(house_input_df, len(input_house_officials_objects))\n",
    "d2, d5 = num_of_trans_per_year(senate_input_df, len(input_senate_officials_objects))\n",
    "d3, d6 = num_of_trans_per_year(input_df, len(input_officials_objects))\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.FREQ)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_per_year\", (d1,d2,d3), [\"year\", constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_per_year_normalized\", (d4,d5,d6), [\"year\", constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Person \n",
    "_Not controlling for number of years in position or size of transaction._ For each official, we want their total number of transactions.  {'Sam': 5, 'Alex': 2424, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_per_person(group):\n",
    "    d={}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        d = dict_utils.increment_dictionary(d, official.get_name(t))\n",
    "\n",
    "    return dict_utils.sort_dictionary_by_values(d)\n",
    "    \n",
    "d1 = num_of_trans_per_person(house_input_df)\n",
    "d2 = num_of_trans_per_person(senate_input_df)    \n",
    "d3 = num_of_trans_per_person(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_per_person\", (d1,d2,d3), [constants.OFFICIAL, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "\n",
    "def num_of_trans_per_person_normalized(group):\n",
    "    d={}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        d = dict_utils.increment_dictionary(d, official.get_name(t))\n",
    "\n",
    "    new_d = {}\n",
    "    for k,v in d.items():\n",
    "        link = input_all_officials_name[k]\n",
    "        _, obj = input_officials_objects[link]\n",
    "        new_d[k] = round(v/obj.get_seniority(), 2) if round(v/obj.get_seniority(), 2) != 0 else 1 \n",
    "        \n",
    "    return new_d\n",
    "    \n",
    "d1 = num_of_trans_per_person_normalized(house_input_df)\n",
    "d2 = num_of_trans_per_person_normalized(senate_input_df)    \n",
    "d3 = num_of_trans_per_person_normalized(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_per_person_normalized\", (d1,d2,d3), [constants.OFFICIAL, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e534e48711db4d1e1c48977d0d14ff85b1f16d41bcc4fdfd88268a329b3c9d66"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
