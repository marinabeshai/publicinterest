{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHASE 1: PROFILE + GEN Q'S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.csv_utils as csv_utils \n",
    "import utils.dir_utils as dir_utils\n",
    "import utils.dict_utils as dict_utils \n",
    "import utils.ptr_utils as ptr_utils\n",
    "import utils.constants as constants \n",
    "import helpers.official as official\n",
    "import helpers.search as search\n",
    "import helpers.congress as congress\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transactions: 22,123 \n",
      "\n",
      "Number of transactions by House Representatives: 13,082, 59.13%\n",
      "Number of transactions by House Representatives controlled: 83.32 transactions per representative \n",
      "\n",
      "Number of transactions by Senators: 9,041, 40.87%\n",
      "Number of transactions by Senators controlled: 143.51 transactions per senator \n",
      "\n",
      "Number of officials in input: 220\n",
      "Number of officials in input controlled: 22.70%\n",
      "\n",
      "Number of representatives in input: 157, 71.36%\n",
      "Number of representatives in input controlled: 18.87% \n",
      "\n",
      "Number of senators in input: 63, 28.64%\n",
      "Number of senators in input controlled: 38.41% \n",
      "\n",
      "Number of officials in total (from 112-117th congress): 969\n",
      "Number of representatives in total (from 112-117th congress): 832\n",
      "Number of senators in total (from 112-117th congress): 164\n",
      "\n",
      "Number of officials from 112-117th congress who did NOT engage in the market: 749, 77.30%\n",
      "Number of officials from 112-117th congress who DID engage in the market: 749, 22.70% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, input_df = dir_utils.get_data(combined=True)\n",
    "_, house_input_df = dir_utils.get_data(house=True)\n",
    "_, senate_input_df = dir_utils.get_data(senate=True)\n",
    "\n",
    "num_of_transactions = input_df.shape[0]\n",
    "num_of_house_transactions = house_input_df.shape[0]\n",
    "num_of_senate_transactions = senate_input_df.shape[0]\n",
    "\n",
    "sector_df = dir_utils.get_mapping(sector=True)\n",
    "industry_df = dir_utils.get_mapping(industry=True)\n",
    "\n",
    "# {canonical_name_input_based : link, ...}\n",
    "input_all_officials_name = {}\n",
    "\n",
    "# {link : canonical_name_input_based, ....}\n",
    "input_all_officials_link = {}\n",
    "input_house_officials_link = {}\n",
    "input_senate_officials_link = {}\n",
    "\n",
    "# (canonical_name_input_based, ...)\n",
    "names = set()\n",
    "\n",
    "for _,t in input_df.iterrows():        \n",
    "    name = official.get_name(t)\n",
    "        \n",
    "    if name not in names:    \n",
    "        link = search.get_wiki_link(name)\n",
    "                \n",
    "        if ptr_utils.isvalid(t[constants.REPRESENTATIVE]) and link not in input_house_officials_link:\n",
    "            input_house_officials_link =  dict_utils.increment_dictionary(input_house_officials_link, link, name, not_math=True)\n",
    "        if ptr_utils.isvalid(t[constants.SENATOR]) and link not in input_senate_officials_link:\n",
    "            input_senate_officials_link =  dict_utils.increment_dictionary(input_senate_officials_link, link, name, not_math=True)\n",
    "        \n",
    "        input_all_officials_link =  dict_utils.increment_dictionary(input_all_officials_link, link, name, not_math=True)\n",
    "        input_all_officials_name =  dict_utils.increment_dictionary(input_all_officials_name, name, link, not_math=True)\n",
    "\n",
    "        names.add(name)\n",
    "\n",
    "print(\"Number of transactions: {} \\n\".format(ptr_utils.commify_str(len(input_df.index))))\n",
    "\n",
    "print(\"Number of transactions by House Representatives: {}, {}\".format(ptr_utils.commify_str(num_of_house_transactions), ptr_utils.make_percent(num_of_house_transactions, len(input_df.index))))\n",
    "print(\"Number of transactions by House Representatives controlled: {0:.2f} transactions per representative \\n\".format((num_of_house_transactions / len(input_house_officials_link))))\n",
    "\n",
    "print(\"Number of transactions by Senators: {}, {}\".format(ptr_utils.commify_str(num_of_senate_transactions), ptr_utils.make_percent(num_of_senate_transactions, len(input_df.index))))\n",
    "print(\"Number of transactions by Senators controlled: {0:.2f} transactions per senator \\n\".format( (num_of_senate_transactions /  len(input_senate_officials_link))))\n",
    "\n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "input_house_officials_objects = {}\n",
    "for link, person in input_house_officials_link.items(): \n",
    "    off = search.wiki_search(person)        \n",
    "    input_house_officials_objects[link] = (person, off)\n",
    "        \n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "input_senate_officials_objects = {}\n",
    "for link, person in input_senate_officials_link.items():\n",
    "    off = search.wiki_search(person)        \n",
    "    input_senate_officials_objects[link] = (person, off)\n",
    "\n",
    "# {link : (canonical_name_input_based, official_object) ... }\n",
    "input_officials_objects = {**input_house_officials_objects, **input_senate_officials_objects}\n",
    "\n",
    "# {link : canonical_name_wiki_based, ... }\n",
    "all_officials = congress.get_all_officials()\n",
    "house_officials = congress.get_house_officials()\n",
    "senate_officials = congress.get_senate_officials()\n",
    "\n",
    "# {link : gender, ...}\n",
    "officials_gender = {}\n",
    "for link, name in all_officials.items():\n",
    "    gender = official.get_gender(name)\n",
    "    officials_gender[link] = gender\n",
    "\n",
    "# {'California' :  #_of_representatives_from_112_to_117, ...}\n",
    "all_officials_state_count = congress.get_officials_state(everyone=list(all_officials.values()))\n",
    "house_officials_state_count = congress.get_officials_state(house=list(house_officials.values()))\n",
    "senate_officials_state_count = congress.get_officials_state(everyone=list(senate_officials.values()))\n",
    "\n",
    "congress_objects = []\n",
    "house_officials_party = {}\n",
    "senate_officials_party = {}\n",
    "for i in range(112, 118):\n",
    "    c = search.get_congress(i)\n",
    "    congress_objects.append(c)\n",
    "    house_officials_party.update(c.get_house_party())\n",
    "    senate_officials_party.update(c.get_senate_party())\n",
    "all_officials_party = {**house_officials_party, **senate_officials_party}\n",
    "\n",
    "for link, name in all_officials.items():\n",
    "    gender = official.get_gender(name)\n",
    "    officials_gender[link] = gender\n",
    "    \n",
    "# {link : canonical_name_wiki_based, ... }\n",
    "all_officials_not_in_input = dict(all_officials)\n",
    "\n",
    "for link_input in input_all_officials_link.keys():\n",
    "    del all_officials_not_in_input[link_input]\n",
    "    \n",
    "print(\"Number of officials in input: {}\".format(len(input_all_officials_link)))\n",
    "print(\"Number of officials in input controlled: {}\\n\".format(ptr_utils.make_percent(len(input_all_officials_link), len(all_officials))))\n",
    "\n",
    "print(\"Number of representatives in input: {}, {}\".format(len(input_house_officials_link), ptr_utils.make_percent(len(input_house_officials_link), len(input_all_officials_link))))\n",
    "print(\"Number of representatives in input controlled: {} \\n\".format(ptr_utils.make_percent(len(input_house_officials_link), len(house_officials))))\n",
    "\n",
    "print(\"Number of senators in input: {}, {}\".format(len(input_senate_officials_link), ptr_utils.make_percent(len(input_senate_officials_link), len(input_all_officials_link))))\n",
    "print(\"Number of senators in input controlled: {} \\n\".format(ptr_utils.make_percent(len(input_senate_officials_link), len(senate_officials))))\n",
    "\n",
    "print(\"Number of officials in total (from 112-117th congress): {}\".format(ptr_utils.commify_str(len(all_officials))))\n",
    "print(\"Number of representatives in total (from 112-117th congress): {}\".format(ptr_utils.commify_str(len(house_officials))))\n",
    "print(\"Number of senators in total (from 112-117th congress): {}\\n\".format(ptr_utils.commify_str(len(senate_officials))))\n",
    "\n",
    "print(\"Number of officials from 112-117th congress who did NOT engage in the market: {}, {}\".format(len(all_officials_not_in_input), ptr_utils.make_percent(len(all_officials_not_in_input), len(all_officials) ) ))\n",
    "\n",
    "print(\"Number of officials from 112-117th congress who DID engage in the market: {}, {} \\n\".format(len(all_officials_not_in_input), ptr_utils.make_percent(len(input_all_officials_link), len(all_officials) ) ))\n",
    "\n",
    "def t_to_obj(t):\n",
    "    name = official.get_name(t)\n",
    "    link = input_all_officials_name[name]\n",
    "    _, obj = input_officials_objects[link]\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miller, Carol D. 2018/12/27 t[constants.TDATE]\n"
     ]
    }
   ],
   "source": [
    "def validate_dates():\n",
    "    for _,t in input_df.iterrows():\n",
    "        canonical_name = official.get_name(t)\n",
    "        obj = t_to_obj(t)\n",
    "        \n",
    "        if not ptr_utils.validate_date(obj, t[constants.TDATE]):\n",
    "            print(canonical_name, t[constants.TDATE], \"t[constants.TDATE]\")\n",
    "            break\n",
    "        if not ptr_utils.validate_date(obj, t[constants.DDATE], ddate=True):\n",
    "            print(canonical_name, t[constants.DDATE], \"t[constants.DDATE]\")\n",
    "            break \n",
    "\n",
    "validate_dates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age (Lowest, Highest, Average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_age(group):\n",
    "    # {age, age, ...}\n",
    "    l = []\n",
    "    \n",
    "    # group = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for _, (_, off_obj) in group.items(): \n",
    "        l.append(off_obj.get_age())\n",
    "    \n",
    "    l.sort()\n",
    "    \n",
    "    d = {}\n",
    "    d[\"0. Youngest\"] = l[0]\n",
    "    d[\"1. Average\"] = round((sum(l) / len(l)))\n",
    "    d[\"2. Oldest\"] = l[len(l)-1]\n",
    "    \n",
    "    return d \n",
    "    \n",
    "d1 = profile_age(input_house_officials_objects)\n",
    "d2 = profile_age(input_senate_officials_objects)\n",
    "d3 = profile_age(input_officials_objects)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_age\", (d1,d2,d3), [\"Age\", constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "def profile_age_2(group):\n",
    "    # {age : #_of_people, ...}\n",
    "    d = dict(constants.age_groups)\n",
    "    \n",
    "    for (_, off_obj) in group.values(): \n",
    "        age = off_obj.get_age()\n",
    "        d = dict_utils.increment_dictionary(d, ptr_utils.which_age_group(age)) \n",
    "    \n",
    "    return d \n",
    "    \n",
    "d1 = profile_age_2(input_house_officials_objects)\n",
    "d2 = profile_age_2(input_senate_officials_objects)\n",
    "d3 = profile_age_2(input_officials_objects)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_age_2\", (d1,d2,d3), [\"Age\", constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age (Which age is most active?) Active = No. of Trades &  Size of Transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_active_age(group, normalized):\n",
    "    # {age : 45_transactions}\n",
    "    d_number = dict(constants.age_groups)\n",
    "    \n",
    "    # {age : [gmean, gmean, ...]}\n",
    "    d_size = dict(constants.age_groups)\n",
    "    for k,_ in d_size.items():\n",
    "        d_size[k] = []\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "            obj = t_to_obj(t)\n",
    "            age = obj.get_age()\n",
    "            \n",
    "            age_group = ptr_utils.which_age_group(age)\n",
    "            d_number =  dict_utils.increment_dictionary(d_number, age_group)\n",
    "            \n",
    "            mean =  ptr_utils.get_gmean(t[constants.AMOUNT])             \n",
    "            d_size = dict_utils.increment_list_in_dictionary(d_size, age_group, mean)\n",
    "\n",
    "    d_size = dict_utils.flatten_gmean(d_size)\n",
    "\n",
    "    # Normalize\n",
    "    if normalized: \n",
    "        d_number = dict_utils.normalize(d_number, normalized)\n",
    "        d_number = dict_utils.sort_dictionary_by_tuple(d_number)\n",
    "        \n",
    "        d_size = dict_utils.normalize(d_size, normalized)\n",
    "        d_size = dict_utils.sort_dictionary_by_tuple(d_size)\n",
    "\n",
    "    return d_number, d_size\n",
    "    \n",
    "d1,d4 = profile_active_age(house_input_df, profile_age_2(input_house_officials_objects))\n",
    "d2,d5 = profile_active_age(senate_input_df, profile_age_2(input_senate_officials_objects))\n",
    "d3,d6 = profile_active_age(input_df, profile_age_2(input_officials_objects))\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_age_active_number\", (d1,d2,d3), [\"Age\", constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_age_active_size\", (d4,d5,d6), [\"Age\", constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oldest and Most Recent Dates (transaction and disclosure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oldest transaction_date for house: 2018/09/08 \n",
      " https://disclosures-clerk.house.gov/public_disc/ptr-pdfs/2021/8218371.pdf\n",
      "Most recent transaction_date for house: 2021/12/31 \n",
      " https://disclosures-clerk.house.gov/public_disc/ptr-pdfs/2022/20020182.pdf \n",
      "Oldest disclosure_date for house: 2020/01/02 \n",
      " https://disclosures-clerk.house.gov/public_disc/ptr-pdfs/2020/20013832.pdf\n",
      "Most recent disclosure_date for house: 2022/01/25 \n",
      " https://disclosures-clerk.house.gov/public_disc/ptr-pdfs/2022/20020300.pdf\n",
      "\n",
      "Oldest transaction_date for senate: 2012/06/14 \n",
      " https://efdsearch.senate.gov/search/view/ptr/86e969b3-64e7-4a51-84d7-da82847b501e/\n",
      "Most recent transaction_date for senate: 2021/12/31 \n",
      " https://efdsearch.senate.gov/search/view/ptr/41868f55-ad42-4855-9aca-1764a05fb956/ \n",
      "Oldest disclosure_date for senate: 2012/07/25 \n",
      " https://efdsearch.senate.gov/search/view/paper/CDFDAF62-18EA-4298-B0C5-62085A6EC3CD/\n",
      "Most recent disclosure_date for senate: 2022/01/21 \n",
      " https://efdsearch.senate.gov/search/view/ptr/bfd4faf3-88b4-445a-8559-11ee5269ba7b/\n",
      "\n",
      "Oldest transaction_date for input: 2012/06/14 \n",
      " https://efdsearch.senate.gov/search/view/ptr/86e969b3-64e7-4a51-84d7-da82847b501e/\n",
      "Most recent transaction_date for input: 2021/12/31 \n",
      " https://efdsearch.senate.gov/search/view/ptr/41868f55-ad42-4855-9aca-1764a05fb956/ \n",
      "Oldest disclosure_date for input: 2012/07/25 \n",
      " https://efdsearch.senate.gov/search/view/paper/CDFDAF62-18EA-4298-B0C5-62085A6EC3CD/\n",
      "Most recent disclosure_date for input: 2022/01/25 \n",
      " https://disclosures-clerk.house.gov/public_disc/ptr-pdfs/2022/20020300.pdf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def profile_dates(group, type):\n",
    "    lowest_tdate = lowest_ddate = highest_tdate = highest_ddate = None\n",
    "    lowest_tdate_obj = lowest_ddate_obj = highest_tdate_obj = highest_ddate_obj = None\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        curr = t[constants.TDATE]            \n",
    "        if not lowest_tdate or curr < lowest_tdate:\n",
    "            lowest_tdate = curr \n",
    "            lowest_tdate_obj = t\n",
    "        if not highest_tdate or curr > highest_tdate:\n",
    "            highest_tdate = curr  \n",
    "            highest_tdate_obj = t\n",
    "\n",
    "        curr = t[constants.DDATE]\n",
    "        if not lowest_ddate or curr < lowest_ddate:\n",
    "            lowest_ddate = curr \n",
    "            lowest_ddate_obj = t\n",
    "        if not highest_ddate or curr > highest_ddate:\n",
    "            highest_ddate = curr \n",
    "            highest_ddate_obj = t\n",
    "\n",
    "    print(\"Oldest transaction_date for {}: {} \\n {}\".format(type, lowest_tdate, lowest_tdate_obj[constants.PTR_LINK]))\n",
    "    print(\"Most recent transaction_date for {}: {} \\n {} \".format(type, highest_tdate, highest_tdate_obj[constants.PTR_LINK]))\n",
    "    \n",
    "    print(\"Oldest disclosure_date for {}: {} \\n {}\".format(type, lowest_ddate, lowest_ddate_obj[constants.PTR_LINK]))\n",
    "    print(\"Most recent disclosure_date for {}: {} \\n {}\\n\".format(type, highest_ddate, highest_ddate_obj[constants.PTR_LINK]))\n",
    "    \n",
    "\n",
    "profile_dates(house_input_df, constants.HOUSE)\n",
    "profile_dates(senate_input_df, constants.SENATE)\n",
    "profile_dates(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_gender(group, normalized=None):\n",
    "    # d_prime = {'Female' : set(Officials), 'Male' : set(Officials), ...}\n",
    "    d_prime = {}\n",
    "\n",
    "    for link, name in group.items(): \n",
    "        gender = officials_gender[link]\n",
    "        d_prime = dict_utils.increment_set_in_dictionary(d_prime, gender, name)\n",
    "\n",
    "    # d = {'Female' : #_of_officials, 'Male' : #_of_officials, ...}\n",
    "    d = dict_utils.flatten_len(d_prime, inner_set=True)\n",
    "    \n",
    "    if normalized:\n",
    "        d = dict_utils.normalize(d, normalized)\n",
    "        d = dict_utils.sort_dictionary_by_tuple(d)\n",
    "                 \n",
    "    return d\n",
    "\n",
    "# {link : canonical_name_input_based, ....}\n",
    "d1 = profile_gender(input_house_officials_link, profile_gender(house_officials))\n",
    "d2 = profile_gender(input_senate_officials_link, profile_gender(senate_officials))\n",
    "d3 = profile_gender(input_all_officials_link, profile_gender(all_officials))\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_gender\", (d1,d2,d3), [constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT, constants.TOTAL])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender (Which gender is the most active?) Active = No. of Trades &  Size of Transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_active_gender(group, normalized):\n",
    "    # {'gender' : 5_trades, ...}\n",
    "    d_number = {}\n",
    "    \n",
    "    # {gender : [gmean of amount, gmean of amount....] }\n",
    "    d_size = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "            name = official.get_name(t)\n",
    "            link = input_all_officials_name[name]\n",
    "            g = officials_gender[link]\n",
    "            \n",
    "            d_number =  dict_utils.increment_dictionary(d_number, g)\n",
    "            \n",
    "            mean =  ptr_utils.get_gmean(t[constants.AMOUNT])             \n",
    "            d_size = dict_utils.increment_list_in_dictionary(d_size, g, mean)\n",
    "\n",
    "    d_size = dict_utils.flatten_gmean(d_size)\n",
    "        \n",
    "    # Normalize\n",
    "    if normalized:\n",
    "        d_number = dict_utils.normalize(d_number, normalized)\n",
    "        d_number = dict_utils.sort_dictionary_by_tuple(d_number)\n",
    "        \n",
    "        d_size = dict_utils.normalize(d_size, normalized)\n",
    "        d_size = dict_utils.sort_dictionary_by_tuple(d_size)\n",
    "\n",
    "    return d_number, d_size\n",
    "\n",
    "\n",
    "d1,d4 = profile_active_gender(house_input_df, profile_gender(house_officials))\n",
    "d2,d5 = profile_active_gender(senate_input_df, profile_gender(senate_officials))\n",
    "d3,d6 = profile_active_gender(input_df, profile_gender(all_officials))\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_gender_number\", (d1,d2,d3), [constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_gender_size\", (d4,d5,d6), [constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_party(group, normalized=None):\n",
    "    # d_prime = {'Republican' : set(Officials), 'Democrat' : set(Officials), ...}\n",
    "    d_prime = {}\n",
    "    \n",
    "    for (_, off_obj) in group.values(): \n",
    "        d_prime = dict_utils.increment_set_in_dictionary(d_prime, off_obj.party, off_obj.name)\n",
    "        \n",
    "    # d = {'Republican' : #_of_officials, 'Democrat' : #_of_officials, ...}\n",
    "    d = dict_utils.flatten_len(d_prime, inner_set=True)\n",
    "    \n",
    "    if normalized: \n",
    "        d = dict_utils.normalize(d, normalized)\n",
    "        d = dict_utils.sort_dictionary_by_tuple(d)\n",
    "\n",
    "    return d\n",
    "\n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "d1 = profile_party(input_house_officials_objects, house_officials_party)\n",
    "d2 = profile_party(input_senate_officials_objects, senate_officials_party)\n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "d3 = profile_party(input_officials_objects, all_officials_party)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_party\", (d1,d2,d3), [constants.PARTY, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Party (Which party is the most active?) Active = No. of Trades &  Size of Transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_active_party(group, normalized=None):\n",
    "    # {'party' : 5_trades, ...}\n",
    "    d_number = {}\n",
    "    \n",
    "    # {party : [gmean of amount, gmean of amount....] }\n",
    "    d_size = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "            obj = t_to_obj(t)\n",
    "            party = obj.party        \n",
    "            \n",
    "            d_number =  dict_utils.increment_dictionary(d_number, party)\n",
    "            \n",
    "            mean =  ptr_utils.get_gmean(t[constants.AMOUNT])             \n",
    "            d_size = dict_utils.increment_list_in_dictionary(d_size, party, mean)\n",
    "\n",
    "    d_size = dict_utils.flatten_gmean(d_size)\n",
    "        \n",
    "    # Normalize\n",
    "    if normalized:\n",
    "        d_number = dict_utils.normalize(d_number, normalized)\n",
    "        d_number = dict_utils.sort_dictionary_by_tuple(d_number)\n",
    "        \n",
    "        d_size = dict_utils.normalize(d_size, normalized)\n",
    "        d_size = dict_utils.sort_dictionary_by_tuple(d_size)\n",
    "    \n",
    "    return d_number, d_size\n",
    "\n",
    "d1,d4 = profile_active_party(house_input_df, house_officials_party)\n",
    "d2,d5 = profile_active_party(senate_input_df, senate_officials_party)\n",
    "d3,d6 = profile_active_party(input_df, all_officials_party)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_party_number\", (d1,d2,d3), [constants.PARTY, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_party_size\", (d4,d5,d6), [constants.PARTY, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_state(group, normalized=None):\n",
    "    # d_prime = {'Maryland' : set(Officials), 'California' : set(Officials), ...}\n",
    "    d_prime = {}\n",
    "    \n",
    "    # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for _, off_obj in group.values(): \n",
    "        d_prime = dict_utils.increment_set_in_dictionary(d_prime, off_obj.state, off_obj.name)\n",
    "\n",
    "    # d = {'Maryland' : #_of_officials, 'California' : #_of_officials, ...}\n",
    "    d = dict_utils.flatten_len(d_prime, inner_set=True)\n",
    "    \n",
    "    if normalized:\n",
    "        d = dict_utils.normalize(d, normalized)\n",
    "        d = dict_utils.sort_dictionary_by_tuple(d)\n",
    "            \n",
    "    return d \n",
    "\n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "d1 = profile_state(input_house_officials_objects, house_officials_state_count)\n",
    "d2 = profile_state(input_senate_officials_objects, senate_officials_state_count)\n",
    "\n",
    "# {link : (canonical_name_input_based, official_object) ... }\n",
    "d3 = profile_state(input_officials_objects, all_officials_state_count)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_state\", (d1,d2,d3), [constants.STATE, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State (Which state is the most active?) Active = No. of Trades &  Size of Transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_active_state(group, normalized=None):\n",
    "    # {'state' : 5_trades, ...}\n",
    "    d_number = {}\n",
    "    \n",
    "    # {state : [gmean of amount, gmean of amount....] }\n",
    "    d_size = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "            obj =  t_to_obj(t)\n",
    "            \n",
    "            d_number =  dict_utils.increment_dictionary(d_number, obj.state)\n",
    "            \n",
    "            mean =  ptr_utils.get_gmean(t[constants.AMOUNT])             \n",
    "            d_size = dict_utils.increment_list_in_dictionary(d_size, obj.state, mean)\n",
    "\n",
    "    d_size = dict_utils.flatten_gmean(d_size)\n",
    "    \n",
    "    if normalized:\n",
    "        d_number = dict_utils.normalize(d_number, normalized)\n",
    "        d_number = dict_utils.sort_dictionary_by_tuple(d_number)\n",
    "        \n",
    "        d_size = dict_utils.normalize(d_size, normalized)\n",
    "        d_size = dict_utils.sort_dictionary_by_tuple(d_size)\n",
    "\n",
    "    return d_number, d_size\n",
    "\n",
    "d1,d4 = profile_active_state(house_input_df, house_officials_state_count)\n",
    "d2,d5 = profile_active_state(senate_input_df, senate_officials_state_count)\n",
    "d3,d6 = profile_active_state(input_df, all_officials_state_count)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_state_number\", (d1,d2,d3), [constants.STATE, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_state_size\", (d4,d5,d6), [constants.STATE, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seniority (Lowest, Highest, Average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_seniority(group):\n",
    "    # d = {x_years_in_congress, y_years_in_congres, ...}\n",
    "    l = []\n",
    "    \n",
    "    # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for _, (_, off_obj) in group.items(): \n",
    "        l.append(off_obj.get_seniority())\n",
    "    \n",
    "    l.sort()\n",
    "    \n",
    "    d = {}\n",
    "    d[\"0. Lowest\"] = l[0]\n",
    "    d[\"1. Average\"] = round((sum(l) / len(l)))\n",
    "    d[\"2. Highest\"] = l[len(l)-1]\n",
    "\n",
    "    return d \n",
    "\n",
    "d1 = profile_seniority(input_house_officials_objects)\n",
    "d2 = profile_seniority(input_senate_officials_objects)\n",
    "d3 = profile_seniority(input_officials_objects)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_seniority\", (d1,d2,d3), [constants.SENIORITY, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "def profile_seniority_2(group):\n",
    "    # d = {x_years_in_congress : #_of_people, }\n",
    "    d = {}\n",
    "    \n",
    "    # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for (_, off_obj) in group.values(): \n",
    "        d =  dict_utils.increment_dictionary(d, off_obj.get_seniority())\n",
    "    \n",
    "    return d \n",
    "\n",
    "d1 = profile_seniority_2(input_house_officials_objects)\n",
    "d2 = profile_seniority_2(input_senate_officials_objects)\n",
    "d3 = profile_seniority_2(input_officials_objects)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_seniority_2\", (d1,d2,d3), [constants.SENIORITY, constants.HOUSE, constants.SENATE, constants.INPUT])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seniority (Which seniority is most active?) Active = No. of Trades & Size of Transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_active_age(group):\n",
    "    # {'seniority' : 5_peeps_with_it, ...}\n",
    "    d_number = {}\n",
    "    \n",
    "    # {'seniority' :  [gmean of amount, gmean of amount....] }\n",
    "    d_size = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "            obj = t_to_obj(t)\n",
    "            seniority = obj.get_seniority()\n",
    "            \n",
    "            d_number =  dict_utils.increment_dictionary(d_number, seniority)\n",
    "            \n",
    "            mean =  ptr_utils.get_gmean(t[constants.AMOUNT])             \n",
    "            d_size = dict_utils.increment_list_in_dictionary(d_size, seniority, mean)\n",
    "    \n",
    "    d_size = dict_utils.flatten_gmean(d_size)\n",
    "\n",
    "    # Normalize\n",
    "    total = profile_seniority_2(input_officials_objects)\n",
    "    \n",
    "    for k,v in d_number.items():\n",
    "        d_number[k] = round(v/total[k], 0)\n",
    "    \n",
    "    for k,v in d_size.items():\n",
    "        d_size[k] = round(v/total[k], 0)\n",
    "\n",
    "    return d_number, d_size\n",
    "    \n",
    "d1,d4 = profile_active_age(house_input_df)\n",
    "d2,d5 = profile_active_age(senate_input_df)\n",
    "d3,d6 = profile_active_age(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_age_number\", (d1,d2,d3), [constants.AGE, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_age_size\", (d4,d5,d6), [constants.AGE, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get_Congress (Lowest, Highest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_congress(group):\n",
    "    lowest = highest = None \n",
    "    \n",
    "    # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for (_, off_obj) in group.values():\n",
    "        res = off_obj.get_congress()\n",
    "        \n",
    "        if not lowest or res[0] < lowest:\n",
    "            lowest = res[0]\n",
    "    \n",
    "        if not highest or res[len(res) - 1] > highest:\n",
    "            highest = res[len(res) - 1]\n",
    "                    \n",
    "    d = {}\n",
    "    d[\"Lowest Congress\"] = lowest\n",
    "    d[\"Highest Congress\"] = highest\n",
    "\n",
    "    return d \n",
    "                        \n",
    "d1 = profile_congress(input_house_officials_objects)\n",
    "d2 = profile_congress(input_senate_officials_objects)\n",
    "d3 = profile_congress(input_officials_objects)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_congress\", (d1,d2,d3), [\"\", constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Degrees (Lowest, Highest, Average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_degrees(group):    \n",
    "    # d = {x_degrees, y_degrees, ...}\n",
    "    l = []\n",
    "    \n",
    "    # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for (_, off_obj) in group.values(): \n",
    "        l.append(off_obj.get_num_of_degrees())\n",
    "    \n",
    "    l.sort()\n",
    "    \n",
    "    d = {}\n",
    "    d[\"0. Lowest\"] = l[0]\n",
    "    d[\"1. Average\"] = round((sum(l) / len(l)))\n",
    "    d[\"2. Highest\"] = l[len(l)-1]\n",
    "\n",
    "    return d \n",
    "    \n",
    "d1 = profile_degrees(input_house_officials_objects)\n",
    "d2 = profile_degrees(input_senate_officials_objects)\n",
    "d3 = profile_degrees(input_officials_objects)       \n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_degrees\", (d1,d2,d3), [\"No. of Degrees\", constants.HOUSE, constants.SENATE, constants.INPUT]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_JD(group):\n",
    "    # d = {x_degrees, y_degrees, ...}\n",
    "    yes = total = 0 \n",
    "    \n",
    "    # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for (_, off_obj) in group.values(): \n",
    "        if off_obj.has_JD():\n",
    "            yes += 1 \n",
    "        total += 1 \n",
    "        \n",
    "    d = {}\n",
    "    \n",
    "    d[\"(Raw, Percent)\"] = (yes, ptr_utils.make_percent(yes, total))\n",
    "    \n",
    "    return d \n",
    "    \n",
    "d1 = profile_JD(input_house_officials_objects)\n",
    "d2 = profile_JD(input_senate_officials_objects)\n",
    "d3 = profile_JD(input_officials_objects)        \n",
    "\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_JDs\", (d1,d2,d3), [\"\", constants.HOUSE, constants.SENATE, constants.INPUT]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transaction Date (transaction_date) CONFIRMED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency of Differences between Transaction and Disclosure Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_differences(group):\n",
    "    d = {}\n",
    "    # match = {}\n",
    "    total = num = 0 \n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        # Negative, X days BEFORE\n",
    "        # Positive, Y dayas AFTER\n",
    "        diff = ptr_utils.difference_between_dates(t)      \n",
    "        total += 1 \n",
    "        num += diff   \n",
    "        \n",
    "        # match = {5 days: {'Tom' : 1313, 'X': 3 , ...}. ..}\n",
    "        # match =  dict_utils.increment_dictionary_in_dictionary(match, diff, official.get_name(t))\n",
    "            \n",
    "        d =  dict_utils.increment_dictionary(d, int(diff))\n",
    "    \n",
    "    d[\"Average\"] = ptr_utils.make_percent(num, total)\n",
    "    \n",
    "    return d \n",
    "    # return dict_utils.sort_dictionary_by_keys(d)\n",
    "\n",
    "d1 = frequency_of_differences(house_input_df)\n",
    "d2 = frequency_of_differences(senate_input_df)\n",
    "d3 = frequency_of_differences(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"frequency_of_differences\", (d1,d2,d3), [\"Difference\", constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each sector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               sector transaction_date  number_of_transactions\n",
      "0  Financial Services       2020/03/18                      63\n",
      "1   Consumer Cyclical       2020/03/18                      45\n",
      "2         Industrials       2020/03/18                      37\n",
      "3          Technology       2019/06/24                      37\n",
      "4          Healthcare       2019/06/24                      32\n",
      "               sector transaction_date  number_of_transactions\n",
      "0  Financial Services       2020/04/14                      30\n",
      "1                Fund       2020/04/02                      27\n",
      "2   Consumer Cyclical       2020/04/14                      23\n",
      "3          Technology       2020/04/14                      20\n",
      "4         Industrials       2020/04/07                      20\n",
      "               sector transaction_date  number_of_transactions\n",
      "0  Financial Services       2020/03/18                      65\n",
      "1   Consumer Cyclical       2020/03/18                      48\n",
      "2         Industrials       2020/03/18                      39\n",
      "3          Technology       2019/06/24                      37\n",
      "4          Healthcare       2019/06/24                      32\n"
     ]
    }
   ],
   "source": [
    "def transaction_date_wrt_sector(group, diff):\n",
    "    # d_prime = {'sector' : {'date' : #_of_transactions, ....} , 'sector2' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            sector = dir_utils.search_mapping(sector_df, t[constants.TICKER], sector=True)            \n",
    "            d_prime =  dict_utils.increment_dictionary_in_dictionary(d_prime, sector, (t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    filename = \"transaction_date_wrt_sector\"  \n",
    "    if diff:\n",
    "        filename += \"_\" + diff \n",
    "    key_header = constants.SECTOR\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_sector(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_sector(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_sector(input_df, constants.INPUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each sector controlling for each official. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sector transaction_date  number_of_transactions\n",
      "0   MSFT       2021/04/30                       3\n",
      "1   TSLA       2021/03/22                       3\n",
      "2   AAPL       2020/03/23                       3\n",
      "3    UNH       2020/03/23                       3\n",
      "4    DIS       2020/03/18                       3\n",
      "  sector transaction_date  number_of_transactions\n",
      "0   AAPL       2020/08/27                       3\n",
      "1   DWDP       2017/09/01                       3\n",
      "2   AMZN       2020/06/26                       2\n",
      "3    XOM       2020/04/14                       2\n",
      "4    CVS       2020/04/14                       2\n",
      "  sector transaction_date  number_of_transactions\n",
      "0   AAPL       2021/10/29                       3\n",
      "1   TSLA       2021/03/22                       3\n",
      "2   GOOG       2020/04/17                       3\n",
      "3    RTX       2020/04/07                       3\n",
      "4   SBUX       2020/03/27                       3\n"
     ]
    }
   ],
   "source": [
    "# confirmed \n",
    "def transaction_date_wrt_sector_controlled(group, diff):    \n",
    "    # d_prime = { ('ticker' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime = dict_utils.increment_set_in_inner_dictionary(d_prime, t[constants.TICKER], t[constants.TDATE], official.get_name(t))\n",
    "       \n",
    "    \n",
    "    d_prime = dict_utils.flatten_len(d_prime)\n",
    "\n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    \n",
    "    filename = \"transaction_date_wrt_sector_controlled\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff \n",
    "     \n",
    "    key_header = constants.SECTOR\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_sector_controlled(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_sector_controlled(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_sector_controlled(input_df, constants.INPUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                industry transaction_date  number_of_transactions\n",
      "0                   Fund       2020/10/09                      28\n",
      "1         Semiconductors       2020/07/13                      24\n",
      "2  Oil & Gas - Midstream       2020/06/10                      22\n",
      "3                  Banks       2020/03/18                      19\n",
      "4   Application Software       2020/02/13                      18\n",
      "                  industry transaction_date  number_of_transactions\n",
      "0                     Fund       2020/04/02                      27\n",
      "1    Oil & Gas - Midstream       2020/04/15                      16\n",
      "2            Entertainment       2020/04/14                      14\n",
      "3       Drug Manufacturers       2020/04/14                      11\n",
      "4  Consumer Packaged Goods       2020/04/07                      10\n",
      "                industry transaction_date  number_of_transactions\n",
      "0                   Fund       2020/04/02                      28\n",
      "1         Semiconductors       2020/07/13                      24\n",
      "2  Oil & Gas - Midstream       2020/06/10                      22\n",
      "3                  Banks       2020/03/18                      20\n",
      "4   Application Software       2020/02/13                      18\n"
     ]
    }
   ],
   "source": [
    "# confirmed\n",
    "def transaction_date_wrt_industry(group, diff):    \n",
    "    # d_prime = {'industry' : {'date' : #_of_transactions, ....} , 'industry2' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            industry = dir_utils.search_mapping(industry_df, t[constants.TICKER], industry=True)\n",
    "\n",
    "            d_prime =  dict_utils.increment_dictionary_in_dictionary(d_prime, industry, (t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    filename = \"transaction_date_wrt_industry\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff  \n",
    "    key_header = constants.INDUSTRY\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_industry(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_industry(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_industry(input_df, constants.INPUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each industry controlling for official. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               industry transaction_date  number_of_transactions\n",
      "0  Application Software       2020/03/26                       6\n",
      "1   Brokers & Exchanges       2021/03/01                       4\n",
      "2   Aerospace & Defense       2020/04/03                       4\n",
      "3                  Fund       2020/03/10                       4\n",
      "4       Credit Services       2021/11/08                       3\n",
      "            industry transaction_date  number_of_transactions\n",
      "0  Computer Hardware       2020/08/27                       3\n",
      "1  Health Care Plans       2020/04/14                       3\n",
      "2   Asset Management       2020/04/14                       3\n",
      "3    Credit Services       2020/04/14                       3\n",
      "4      Entertainment       2020/04/06                       3\n",
      "               industry transaction_date  number_of_transactions\n",
      "0  Application Software       2020/03/26                       7\n",
      "1         Entertainment       2020/04/06                       5\n",
      "2   Aerospace & Defense       2020/04/03                       5\n",
      "3                  Fund       2020/03/10                       5\n",
      "4   Brokers & Exchanges       2021/03/01                       4\n"
     ]
    }
   ],
   "source": [
    "# confirmed\n",
    "def transaction_date_wrt_industry_controlled(group, diff):\n",
    "    \n",
    "    # d_prime = { ('ticker' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            industry = dir_utils.search_mapping(industry_df, t[constants.TICKER], industry=True)\n",
    "            \n",
    "            d_prime = dict_utils.increment_set_in_inner_dictionary(d_prime, industry, t[constants.TDATE],  official.get_name(t))\n",
    "       \n",
    "\n",
    "    d_prime = dict_utils.flatten_len(d_prime)\n",
    "    \n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "    \n",
    "    \n",
    "    filename = \"transaction_date_wrt_industry_controlled\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff  \n",
    "    key_header = constants.INDUSTRY\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_industry_controlled(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_industry_controlled(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_industry_controlled(input_df, constants.INPUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each ticker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ticker transaction_date  number_of_transactions\n",
      "0    RUN       2020/07/13                      24\n",
      "1   MSFT       2020/02/13                      18\n",
      "2     SO       2020/03/16                      16\n",
      "3    AMN       2020/09/02                       9\n",
      "4   CRWD       2021/10/01                       8\n",
      "  ticker transaction_date  number_of_transactions\n",
      "0   ECOM       2021/02/10                       8\n",
      "1      X       2021/05/06                       6\n",
      "2    OXY       2021/02/16                       6\n",
      "3    CLF       2021/07/21                       5\n",
      "4     AA       2021/01/06                       5\n",
      "  ticker transaction_date  number_of_transactions\n",
      "0    RUN       2020/07/13                      24\n",
      "1   MSFT       2020/02/13                      18\n",
      "2     SO       2020/03/16                      16\n",
      "3    AMN       2020/09/02                       9\n",
      "4   CRWD       2021/10/01                       8\n"
     ]
    }
   ],
   "source": [
    "# confirmed \n",
    "def transaction_date_wrt_ticker(group, diff):    \n",
    "    # d_prime = {'ticker' : {'date' : #_of_transactions, ....} , 'ticker2' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime =  dict_utils.increment_dictionary_in_dictionary(d_prime, t[constants.TICKER], (t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    filename = \"transaction_date_wrt_ticker\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "    key_header = constants.TICKER\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_ticker(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_ticker(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_ticker(input_df, constants.INPUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each ticker controlling for official."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirmed\n",
    "def transaction_date_wrt_ticker_controlled(group, diff):    \n",
    "    # d_prime = { ('ticker' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():        \n",
    "        name = official.get_name(t)\n",
    "        d_prime = dict_utils.increment_set_in_inner_dictionary(d_prime, t[constants.TICKER], t[constants.TDATE], name)\n",
    "       \n",
    "    for k,v in d_prime.items():\n",
    "        for date, s in v.items():\n",
    "            v[date] = len(s)\n",
    "        d_prime[k] = v\n",
    "        \n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    \n",
    "    filename = \"transaction_date_wrt_ticker_controlled\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff  \n",
    "        \n",
    "    key_header = constants.TICKER\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    # df = pd.read_csv(wd)\n",
    "    # print(df.head(5))\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_ticker_controlled(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_ticker_controlled(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_ticker_controlled(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             type transaction_date  number_of_transactions\n",
      "0        Purchase       2020/03/18                     204\n",
      "1     Sale (Full)       2019/06/24                     204\n",
      "2  Sale (Partial)       2020/11/13                      60\n",
      "3        Exchange       2020/02/24                      18\n",
      "             type transaction_date  number_of_transactions\n",
      "0     Sale (Full)       2020/04/14                     116\n",
      "1        Purchase       2017/03/16                      78\n",
      "2  Sale (Partial)       2020/04/14                      26\n",
      "3        Exchange       2017/09/01                       5\n",
      "             type transaction_date  number_of_transactions\n",
      "0        Purchase       2020/03/18                     212\n",
      "1     Sale (Full)       2019/06/24                     204\n",
      "2  Sale (Partial)       2020/11/13                      60\n",
      "3        Exchange       2020/02/24                      18\n"
     ]
    }
   ],
   "source": [
    "def transaction_date_wrt_type(group, diff):        \n",
    "    # d_prime = {'type' : {'date' : #_of_transactions, ....} , 'type2' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime =  dict_utils.increment_dictionary_in_dictionary(d_prime, ptr_utils.format_type(t[constants.TYPE]), (t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'type' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    filename = \"transaction_date_wrt_type\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff  \n",
    "    key_header = constants.TYPE\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df)\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_type(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_type(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_type(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for type controlling for official. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             type transaction_date  number_of_transactions\n",
      "0        Purchase       2020/11/13                      12\n",
      "1     Sale (Full)       2020/03/23                       9\n",
      "2  Sale (Partial)       2020/03/18                       6\n",
      "3        Exchange       2020/04/03                       5\n",
      "             type transaction_date  number_of_transactions\n",
      "0     Sale (Full)       2020/07/07                       4\n",
      "1        Purchase       2019/02/27                       4\n",
      "2  Sale (Partial)       2020/03/17                       3\n",
      "3        Exchange       2017/09/01                       3\n",
      "             type transaction_date  number_of_transactions\n",
      "0        Purchase       2021/01/15                      12\n",
      "1     Sale (Full)       2020/03/23                       9\n",
      "2  Sale (Partial)       2020/03/18                       7\n",
      "3        Exchange       2020/04/03                       6\n"
     ]
    }
   ],
   "source": [
    "def transaction_date_wrt_type_controlled(group, diff):    \n",
    "    # d_prime = { ('type' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "    d_prime = {}\n",
    "\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime = dict_utils.increment_set_in_inner_dictionary(d_prime, t[constants.TYPE], (t[constants.TDATE]), official.get_name(t))\n",
    "       \n",
    "\n",
    "    d_prime = dict_utils.flatten_len(d_prime)\n",
    "            \n",
    "    \n",
    "    # d = {'type' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "    \n",
    "    \n",
    "    filename = \"transaction_date_wrt_type_controlled\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff  \n",
    "    key_header = constants.TYPE\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_type_controlled(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_type_controlled(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_type_controlled(input_df, constants.INPUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                type  2020/03/18  2020/07/13  2020/11/17  2020/11/19  \\\n",
      "0           $1,001 -         NaN        12.0         NaN         NaN   \n",
      "1   $1,001 - $15,000       257.0         NaN         NaN         NaN   \n",
      "2   $1,000 - $15,000         NaN         NaN         NaN         NaN   \n",
      "3  $15,001 - $50,000         NaN         NaN         NaN        68.0   \n",
      "4  $15,000 - $50,000         NaN         NaN         NaN         NaN   \n",
      "\n",
      "   2021/01/19  2021/02/12  2021/04/09  2021/04/27  2021/05/20  2021/08/16  \\\n",
      "0         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "1         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "2         NaN         NaN         NaN         NaN         4.0         NaN   \n",
      "3         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "4         NaN         NaN         NaN         NaN         3.0         NaN   \n",
      "\n",
      "   2021/11/15  sort_key  \n",
      "0         NaN      1001  \n",
      "1         NaN     15000  \n",
      "2         NaN     15000  \n",
      "3         NaN     50000  \n",
      "4         NaN     50000  \n",
      "                  type  2015/02/13  2015/02/20  2020/03/11  2020/04/07  \\\n",
      "0     $1,001 - $15,000        96.0         NaN         NaN         NaN   \n",
      "1    $15,001 - $50,000         NaN         NaN         NaN         NaN   \n",
      "2   $50,001 - $100,000         NaN         NaN         NaN         NaN   \n",
      "3  $100,001 - $250,000         NaN         NaN         NaN        43.0   \n",
      "4  $250,001 - $500,000         NaN         NaN         NaN         8.0   \n",
      "\n",
      "   2020/04/14  2020/05/20  2021/11/01  sort_key  \n",
      "0         NaN         NaN         NaN     15000  \n",
      "1        69.0         NaN         NaN     50000  \n",
      "2        23.0         NaN         NaN    100000  \n",
      "3         NaN         NaN         NaN    250000  \n",
      "4         NaN         NaN         NaN    500000  \n",
      "                type  2015/02/20  2020/03/11  2020/03/18  2020/04/07  \\\n",
      "0           $1,001 -         NaN         NaN         NaN         NaN   \n",
      "1   $1,001 - $15,000         NaN         NaN       265.0         NaN   \n",
      "2   $1,000 - $15,000         NaN         NaN         NaN         NaN   \n",
      "3  $15,001 - $50,000         NaN         NaN         NaN         NaN   \n",
      "4  $15,000 - $50,000         NaN         NaN         NaN         NaN   \n",
      "\n",
      "   2020/04/14  2020/07/13  2021/02/12  2021/04/27  2021/05/20  2021/08/16  \\\n",
      "0         NaN        12.0         NaN         NaN         NaN         NaN   \n",
      "1         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "2         NaN         NaN         NaN         NaN         4.0         NaN   \n",
      "3        70.0         NaN         NaN         NaN         NaN         NaN   \n",
      "4         NaN         NaN         NaN         NaN         3.0         NaN   \n",
      "\n",
      "   sort_key  \n",
      "0      1001  \n",
      "1     15000  \n",
      "2     15000  \n",
      "3     50000  \n",
      "4     50000  \n"
     ]
    }
   ],
   "source": [
    "def transaction_date_wrt_amount(group, diff):\n",
    "    \n",
    "    # d_prime = {'amount' : {'date' : #_of_transactions, ....} , 'amount1' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime =  dict_utils.increment_dictionary_in_dictionary(d_prime, t[constants.AMOUNT], (t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'type' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "    d = dict_utils.add_sort_key_for_amount(d)\n",
    "    d = dict_utils.sort_dictionary_by_sort_key(d)\n",
    "\n",
    "    filename = \"transaction_date_wrt_amount\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff  \n",
    "    key_header = constants.TYPE\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, key_header)\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_amount(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_amount(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_amount(input_df, constants.INPUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for amount controlling for official."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              amount  2020/01/09  2020/03/13  2020/03/18  2020/08/07  \\\n",
      "0           $1,001 -         NaN         NaN         NaN         NaN   \n",
      "1   $1,001 - $15,000         NaN         NaN        13.0         NaN   \n",
      "2   $1,000 - $15,000         NaN         NaN         NaN         NaN   \n",
      "3  $15,001 - $50,000         NaN         NaN         NaN         NaN   \n",
      "4  $15,000 - $50,000         NaN         NaN         NaN         NaN   \n",
      "\n",
      "   2020/09/02  2020/11/17  2021/01/04  2021/01/15  2021/01/22  2021/02/16  \\\n",
      "0         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "1         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "2         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "3         NaN         NaN         NaN         NaN         NaN         8.0   \n",
      "4         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "\n",
      "   2021/02/22  2021/05/20  sort_key  \n",
      "0         2.0         NaN      1001  \n",
      "1         NaN         NaN     15000  \n",
      "2         NaN         1.0     15000  \n",
      "3         NaN         NaN     50000  \n",
      "4         NaN         1.0     50000  \n",
      "                amount  2015/02/20  2015/10/05  2016/02/11  2016/08/12  \\\n",
      "0              Unknown         NaN         NaN         NaN         3.0   \n",
      "1     $1,001 - $15,000         NaN         NaN         5.0         NaN   \n",
      "2    $15,001 - $50,000         NaN         NaN         NaN         NaN   \n",
      "3   $50,001 - $100,000         NaN         NaN         NaN         NaN   \n",
      "4  $100,001 - $250,000         NaN         NaN         NaN         NaN   \n",
      "\n",
      "   2017/02/01  2018/12/27  2019/10/11  2020/07/31  2021/03/01  2021/07/23  \\\n",
      "0         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "1         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "2         5.0         NaN         NaN         NaN         NaN         NaN   \n",
      "3         NaN         NaN         NaN         3.0         NaN         NaN   \n",
      "4         NaN         3.0         NaN         NaN         NaN         NaN   \n",
      "\n",
      "   2021/11/08  sort_key  \n",
      "0         NaN        -1  \n",
      "1         NaN     15000  \n",
      "2         NaN     50000  \n",
      "3         NaN    100000  \n",
      "4         NaN    250000  \n",
      "              amount  2015/02/20  2015/10/05  2016/08/12  2020/01/09  \\\n",
      "0            Unknown         NaN         NaN         3.0         NaN   \n",
      "1           $1,001 -         NaN         NaN         NaN         NaN   \n",
      "2   $1,001 - $15,000         NaN         NaN         NaN         NaN   \n",
      "3   $1,000 - $15,000         NaN         NaN         NaN         NaN   \n",
      "4  $15,001 - $50,000         NaN         NaN         NaN         NaN   \n",
      "\n",
      "   2020/03/13  2020/11/16  2021/01/04  2021/01/15  2021/01/22  2021/02/16  \\\n",
      "0         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "1         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "2         NaN        15.0         NaN         NaN         NaN         NaN   \n",
      "3         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "4         NaN         NaN         NaN         NaN         NaN        10.0   \n",
      "\n",
      "   2021/02/22  2021/03/01  2021/05/20  2021/07/23  2021/11/08  sort_key  \n",
      "0         NaN         NaN         NaN         NaN         NaN        -1  \n",
      "1         2.0         NaN         NaN         NaN         NaN      1001  \n",
      "2         NaN         NaN         NaN         NaN         NaN     15000  \n",
      "3         NaN         NaN         1.0         NaN         NaN     15000  \n",
      "4         NaN         NaN         NaN         NaN         NaN     50000  \n"
     ]
    }
   ],
   "source": [
    "def transaction_date_wrt_amount_controlled(group, diff):\n",
    "    # d_prime = { ('amount' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "       d_prime = dict_utils.increment_set_in_inner_dictionary(d_prime, t[constants.AMOUNT], (t[constants.TDATE]), official.get_name(t))\n",
    "       \n",
    "\n",
    "    d_prime = dict_utils.flatten_len(d_prime)\n",
    "        \n",
    "    # d = {'amount' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "    d = dict_utils.add_sort_key_for_amount(d)\n",
    "    d = dict_utils.sort_dictionary_by_sort_key(d)\n",
    "    \n",
    "    \n",
    "    filename = \"transaction_date_wrt_amount_controlled\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff  \n",
    "    key_header = constants.AMOUNT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, key_header)\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_amount_controlled(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_amount_controlled(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_amount_controlled(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each official."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            official transaction_date  number_of_transactions\n",
      "0     Shalala, Donna       2019/06/24                     204\n",
      "1  Cisneros, Gilbert       2020/03/18                     160\n",
      "2      Meijer, Peter       2021/02/16                     150\n",
      "3     Phillips, Dean       2020/04/02                     114\n",
      "4    Sherrill, Mikie       2020/02/20                     113\n",
      "               official transaction_date  number_of_transactions\n",
      "0       Loeffler, Kelly       2020/04/07                     111\n",
      "1  Perdue Jr., David A.       2020/04/14                     110\n",
      "2     Tillis, Thomas R.       2015/02/13                      93\n",
      "3         Murray, Patty       2017/06/15                      83\n",
      "4     Collins, Susan M.       2014/05/07                      64\n",
      "            official transaction_date  number_of_transactions\n",
      "0     Shalala, Donna       2019/06/24                     204\n",
      "1  Cisneros, Gilbert       2020/03/18                     160\n",
      "2      Meijer, Peter       2021/02/16                     150\n",
      "3     Phillips, Dean       2020/04/02                     114\n",
      "4    Sherrill, Mikie       2020/02/20                     113\n"
     ]
    }
   ],
   "source": [
    "def transaction_date_wrt_official(group, diff):\n",
    "\n",
    "    # d_prime = {'person1' : {'date' : #_of_transactions, ....} , 'person2' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime =  dict_utils.increment_dictionary_in_dictionary(d_prime, official.get_name(t), (t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'person' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    filename = \"transaction_date_wrt_official\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff \n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [constants.OFFICIAL, constants.TDATE, constants.NUMT])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "transaction_date_wrt_official_res = transaction_date_wrt_official(house_input_df, constants.HOUSE)\n",
    "transaction_date_wrt_official_res = transaction_date_wrt_official(senate_input_df, constants.SENATE)\n",
    "transaction_date_wrt_official_res = transaction_date_wrt_official(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_per_date(group):\n",
    "    d={}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        d =  dict_utils.increment_dictionary(d, (t[constants.TDATE]))\n",
    "        \n",
    "\n",
    "    # filename = \"num_of_trans_per_date\"\n",
    "    # if diff:\n",
    "    #     filename += \"_\" + diff  \n",
    "    # key_header = \"date\"\n",
    "    # value_header = \"number_of_transactions\"\n",
    "    \n",
    "    # d = dict_utils.sort_dictionary_by_values(d)\n",
    "    \n",
    "    # dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    # wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header])\n",
    "    # df = pd.read_csv(wd)\n",
    "    # print(df.head(5))\n",
    "    return d \n",
    "\n",
    "d1 = num_of_trans_per_date(house_input_df)\n",
    "d2 = num_of_trans_per_date(senate_input_df)\n",
    "d3 = num_of_trans_per_date(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_per_date\", (d1,d2,d3), [constants.TDATE, constants.HOUSE, constants.SENATE, constants.INPUT])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Transactions per Date Controlled\n",
    "_Number of transactions per date controlled by official. E.g. if Ted Baker made 40 transactions on 1/1/02 and Sam Wall made 2 transactions on 1/1/02, we conclude that there were two transactions on 1/1/02._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_per_date_controlled(group):    \n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        d =  dict_utils.increment_dictionary_in_dictionary(d, (t[constants.TDATE]), official.get_name(t))\n",
    "    d = dict_utils.flatten_len(d, inner_set=True)\n",
    "    # d2 = {}\n",
    "    # for date in d:\n",
    "    #     d2[date] =  len(d[date])\n",
    "        \n",
    "    # d2 = dict_utils.sort_dictionary_by_values(d2)\n",
    "        \n",
    "    # filename = \"num_of_trans_per_date_controlled\"\n",
    "    # if diff:\n",
    "    #     filename += \"_\" + diff  \n",
    "    # key_header = \"date\"\n",
    "    # value_header = \"number_of_transactions_unique\"\n",
    "\n",
    "\n",
    "    # dir = dir_utils.makesubdir(constants.path_csv, \"transaction_date\")\n",
    "    # wd = csv_utils.make_csv(dir, filename, d2, [key_header, value_header])\n",
    "    # df = pd.read_csv(wd)\n",
    "    # print(df.head(5))\n",
    "    return d \n",
    "    \n",
    "d1 = num_of_trans_per_date_controlled(house_input_df)\n",
    "d2 = num_of_trans_per_date_controlled(senate_input_df)\n",
    "d3 = num_of_trans_per_date_controlled(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_per_date_controlled\", (d1,d2,d3), [constants.TDATE, constants.HOUSE, constants.SENATE, constants.INPUT])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Transactions Within 2 Weeks Prior to Quarterly Tax Date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_within_tax_date(group):        \n",
    "        total = within = 0 \n",
    "        d = {}\n",
    "\n",
    "        for _,t in group.iterrows():  \n",
    "                total += 1 \n",
    "                if ptr_utils.within_tax_date(t[constants.TDATE]):\n",
    "                        within += 1 \n",
    "\n",
    "        d[\"(No. of transactions within 2 weeks of tax deadline, %)\"] = (within,  ptr_utils.make_percent(within, total))\n",
    "\n",
    "        return d \n",
    "\n",
    "d1 = num_of_trans_within_tax_date(house_input_df)\n",
    "d2 = num_of_trans_within_tax_date(senate_input_df)\n",
    "d3 = num_of_trans_within_tax_date(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_within_tax_date\", (d1,d2,d3), [\"\", constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Transactions Within 2 Weeks Prior to Quarterly Tax Date Semi-Controlled \n",
    "\n",
    "_Given dict='09/03/2021': {'Thomas H Tuberville': 1, 'Cynthia M Lummis': 1, 'A. Mitchell Mcconnell, Jr.': 1}...I only incremement the number of within (tax date) once per date per official. So, if an official does 100 transactions on a date within two weeks of a quarterly deadline, then I only count it as one transaction._\n",
    "\n",
    "_A Note: total === number of transactions per person per date (so not really all transactions) because someone could have potentially made 60 transactions on one date which we don't include in neither total or within, if applicable._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_within_tax_date_controlled(group):\n",
    "        total = within = 0 \n",
    "        people = set()\n",
    "        d = {}\n",
    "\n",
    "        for _, t in group.iterrows():\n",
    "                name = official.get_name(t)\n",
    "                if ptr_utils.within_tax_date(t[constants.TDATE]) and name not in people:\n",
    "                        people.add(name)\n",
    "                        within += 1 \n",
    "                total += 1         \n",
    "                \n",
    "        d[\"(No. of transactions within 2 weeks of tax deadline, %)\"] = (within,  ptr_utils.make_percent(within, total))\n",
    "\n",
    "        return d\n",
    "\n",
    "d1 = num_of_trans_within_tax_date_controlled(house_input_df)\n",
    "d2 = num_of_trans_within_tax_date_controlled(senate_input_df)\n",
    "d3 = num_of_trans_within_tax_date_controlled(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_within_tax_date_controlled\", (d1,d2,d3), [\"\", constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def people_and_within_tax_date(people):        \n",
    "#         # todo get number of senators. \n",
    "#         # todo is the monetary value of that equal!!!! \n",
    "#         d = {}\n",
    "#         for i in people:\n",
    "#                 d[i] = \"\"\n",
    "                \n",
    "#         d = dict_utils.sort_dictionary_by_keys(d)\n",
    "        \n",
    "#         dir = dir_utils.makesubdir(constants.path_csv, \"transaction_date/tax\")\n",
    "#         wd = csv_utils.make_csv(dir, \"people_and_within_tax_date_list\", d, [\"Officials\"])\n",
    "#         df = pd.read_csv(wd)\n",
    "#         print(\"People who posted transactions within two weeks of quarterly tax deadline:\\n {}\\n\".format(df.head(5)))\n",
    "\n",
    "#         print(\"Number of people who posted transactions within two weeks of quarterly tax deadline: {}\\n\".format(len(people)))\n",
    "        \n",
    "#         party = {}\n",
    "#         for p in people:\n",
    "#                 link = search.get_wiki_link(p)\n",
    "#                 _, obj = input_officials_objects[link]\n",
    "#                 party =  dict_utils.increment_dictionary(party, obj.party)\n",
    "                \n",
    "#         party = dict_utils.sort_dictionary_by_values(party)\n",
    "        \n",
    "#         wd = csv_utils.make_csv(dir, \"people_and_within_tax_date_list_w_aff\", party, [\"party\", \"number_of_filing_within_tax_date\"])\n",
    "#         df = pd.read_csv(wd)\n",
    "#         print(\"Party breakdown of people who posted transactions within two weeks of quarterly tax deadline:\\n {}\\n\".format(df.head(5)))\n",
    "\n",
    "# people_and_within_tax_date(num_of_trans_within_tax_date_controlled_res_house)\n",
    "# people_and_within_tax_date(num_of_trans_within_tax_date_controlled_res_senate)\n",
    "# people_and_within_tax_date(num_of_trans_within_tax_date_controlled_res_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def people_and_within_tax_date_how_often(people):\n",
    "\n",
    "#         d = {}\n",
    "#         d_controlled_by_dates = {}\n",
    "        \n",
    "#         for _,t in input_df.iterrows():\n",
    "#                 if official.get_canonical_name(t[title]) in people and ptr_utils.within_tax_date(t[constants.TDATE]):\n",
    "#                         d =  dict_utils.increment_dictionary(d, t[title])\n",
    "#                         d_controlled_by_dates =  dict_utils.increment_dictionary_in_dictionary(d_controlled_by_dates, t[constants.TDATE], t[title])\n",
    "\n",
    "#         d_controlled_by_dates_res  = {}\n",
    "#         for date in d_controlled_by_dates:\n",
    "#                 for person in d_controlled_by_dates[date]:\n",
    "#                         d_controlled_by_dates_res =  dict_utils.increment_dictionary(d_controlled_by_dates_res, person)\n",
    "\n",
    "#         d = dict_utils.sort_dictionary_by_values(d)\n",
    "#         d_controlled_by_dates_res = dict_utils.sort_dictionary_by_values(d_controlled_by_dates_res)\n",
    "\n",
    "#         dir = dir_utils.makesubdir(constants.path_csv, \"transaction_date/tax\")\n",
    "#         wd = csv_utils.make_csv(dir, \"people_and_within_tax_date_how_often\", d, [title, \"number_of_filing_within_tax_date\"])\n",
    "#         df = pd.read_csv(wd)\n",
    "#         print(\"People who posted transactions within two weeks of quarterly tax deadline and the number of transactions posted:\\n {}\\n\".format(df.head(5)))\n",
    "\n",
    "#         wd = csv_utils.make_csv(dir, \"people_and_within_tax_date_how_often_date_controlled\", d_controlled_by_dates_res, [title, \"number_of_filing_within_tax_date_date_controlled\"])\n",
    "#         df = pd.read_csv(wd)\n",
    "#         print(\"People who posted transactions within two weeks of quarterly tax deadline and the number of transactions posted controlled by date:\\n {}\\n\".format(df.head(5)))\n",
    "\n",
    "          \n",
    "# people_and_within_tax_date_how_often(num_of_trans_within_tax_date_controlled_res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Owner (owner) CONFIRMED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Count of Owner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_count_of_owner(group):\n",
    "    \n",
    "    # d = {'Joint' : 5}\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if constants.OWNER in t and ptr_utils.isvalid(t[constants.OWNER]) :\n",
    "            d =  dict_utils.increment_dictionary(d, t[constants.OWNER].capitalize())\n",
    "        \n",
    "    return dict_utils.sort_dictionary_by_values(d)\n",
    "    \n",
    "    \n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "d1 = freq_count_of_owner(house_input_df)\n",
    "d2 = freq_count_of_owner(senate_input_df)\n",
    "\n",
    "# {link : (canonical_name_input_based, official_object) ... }\n",
    "d3 = freq_count_of_owner(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.OWNER)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"freq_count_of_owner\", (d1,d2,d3), [\"Owner\", constants.HOUSE, constants.SENATE, constants.INPUT]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ticker (ticker) CONFIRMED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_tickers(group):\n",
    "\n",
    "    # d = {'ticker' : #_of_times }\n",
    "    d = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d =  dict_utils.increment_dictionary(d, t[constants.TICKER])\n",
    "       \n",
    "\n",
    "    return dict_utils.sort_dictionary_by_values(d, reverse=True)\n",
    "\n",
    "d1 = num_of_tickers(house_input_df)\n",
    "d2 = num_of_tickers(senate_input_df)\n",
    "d3 = num_of_tickers(input_df)\n",
    "    \n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.TICKER)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_tickers\", (d1,d2,d3), [constants.TICKER, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Ticker per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ticker  2018  2019  2020  2021  Total\n",
      "0  35G.SG   NaN   NaN   NaN   2.0      2\n",
      "1     7XY   NaN   NaN   NaN   1.0      1\n",
      "    ticker  2012  2013  2014  2015  2016  2017  2018  2019  2020  2021  Total\n",
      "0  0QZI.IL   NaN   NaN   NaN   NaN   NaN   NaN   NaN   2.0   NaN   NaN      2\n",
      "1  3V64.TI   NaN   NaN   NaN   NaN   NaN   NaN   NaN   2.0   NaN   NaN      2\n",
      "    ticker  2012  2013  2014  2015  2016  2017  2018  2019  2020  2021  Total\n",
      "0  0QZI.IL   NaN   NaN   NaN   NaN   NaN   NaN   NaN   2.0   NaN   NaN      2\n",
      "1   35G.SG   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   2.0      2\n"
     ]
    }
   ],
   "source": [
    "def frequency_of_ticker_breakdown_year(group, diff):\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d = dict_utils.increment_dictionary_in_dictionary(d, t[constants.TICKER], ptr_utils.get_year(t[constants.TDATE]))\n",
    "            d = dict_utils.increment_dictionary_in_dictionary(d, t[constants.TICKER], \"Total\")\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_keys(d)\n",
    "    \n",
    "    filename = \"frequency_of_ticker_breakdown_year\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "    key_header = constants.TICKER\n",
    "    \n",
    "    \n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TICKER)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "\n",
    "frequency_of_ticker_breakdown_year(house_input_df, constants.HOUSE)\n",
    "frequency_of_ticker_breakdown_year(senate_input_df, constants.SENATE)\n",
    "frequency_of_ticker_breakdown_year(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Ticker per Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_ticker_by_date(group, diff):\n",
    "    # {ticker : {date : ___}}\n",
    "    d = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d = dict_utils.increment_dictionary_in_dictionary(d, t[constants.TICKER], t[constants.TDATE])\n",
    "\n",
    "    \n",
    "    d = dict_utils.flatten_best(d)\n",
    "    \n",
    "\n",
    "    filename = \"frequency_of_ticker_by_date\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "    \n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TICKER)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, constants.TICKER)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "\n",
    "d1 = frequency_of_ticker_by_date(house_input_df, constants.HOUSE)\n",
    "d2 = frequency_of_ticker_by_date(senate_input_df, constants.SENATE)\n",
    "d3 = frequency_of_ticker_by_date(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Industry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Transactions per Industry\n",
    "_Not controlled in any way._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_transactions_per_indusry(group):        \n",
    "    d = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            industry = dir_utils.search_mapping(industry_df, t[constants.TICKER], industry=True)\n",
    "            d = dict_utils.increment_dictionary(d, industry)\n",
    "\n",
    "    return dict_utils.sort_dictionary_by_values(d)\n",
    "    \n",
    "\n",
    "d1 = number_of_transactions_per_indusry(house_input_df)\n",
    "d2 = number_of_transactions_per_indusry(senate_input_df)\n",
    "d3 = number_of_transactions_per_indusry(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.INDUSTRY)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"number_of_transactions_per_indusry\", (d1,d2,d3), [constants.INDUSTRY, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Industry Breakdown per Official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            official  Advertising & Marketing Services  Advertising Agencies  \\\n",
      "0  Allen, Richard W.                               NaN                   NaN   \n",
      "1      Amash, Justin                               NaN                   NaN   \n",
      "\n",
      "   Aerospace & Defense  Agricultural Inputs  Agriculture  Airlines  \\\n",
      "0                  1.0                  NaN          NaN       NaN   \n",
      "1                  NaN                  NaN          NaN       NaN   \n",
      "\n",
      "   Apparel Manufacturing  Apparel Retail  Application Software  ...  Trust  \\\n",
      "0                    NaN             NaN                   1.0  ...    NaN   \n",
      "1                    NaN             NaN                   NaN  ...    NaN   \n",
      "\n",
      "   Utilities - Independent Power Producers  Utilities - Regulated  \\\n",
      "0                                      NaN                    3.0   \n",
      "1                                      NaN                    NaN   \n",
      "\n",
      "   Utilities - Regulated Water  Utilities—Diversified  \\\n",
      "0                          NaN                    NaN   \n",
      "1                          NaN                    NaN   \n",
      "\n",
      "   Utilities—Regulated Electric  Utilities—Regulated Gas  \\\n",
      "0                           NaN                      NaN   \n",
      "1                           NaN                      NaN   \n",
      "\n",
      "   Utilities—Regulated Water  Utilities—Renewable  Waste Management  \n",
      "0                        NaN                  NaN               NaN  \n",
      "1                        NaN                  NaN               NaN  \n",
      "\n",
      "[2 rows x 181 columns]\n",
      "             official  Advertising & Marketing Services  Aerospace & Defense  \\\n",
      "0  Bennet, Michael F.                               NaN                  NaN   \n",
      "1       Blunt, Roy D.                               NaN                  NaN   \n",
      "\n",
      "   Aerospace/Defense  Agricultural Inputs  Agriculture  Airlines  \\\n",
      "0                NaN                  NaN          NaN       NaN   \n",
      "1                NaN                  NaN          NaN       NaN   \n",
      "\n",
      "   Apparel Manufacturing  Application Software  Asset Management  ...  \\\n",
      "0                    NaN                   NaN               NaN  ...   \n",
      "1                    NaN                   NaN               NaN  ...   \n",
      "\n",
      "   Travel & Leisure  Travel Services  Truck Manufacturing  Trust  Utilities  \\\n",
      "0               NaN              NaN                  NaN    NaN        NaN   \n",
      "1               NaN              NaN                  NaN    NaN        NaN   \n",
      "\n",
      "   Utilities - Independent Power Producers  Utilities - Regulated  \\\n",
      "0                                      NaN                    NaN   \n",
      "1                                      NaN                    NaN   \n",
      "\n",
      "   Utilities--Regulated Electric  Utilities—Renewable  Waste Management  \n",
      "0                            NaN                  NaN               NaN  \n",
      "1                            NaN                  NaN               NaN  \n",
      "\n",
      "[2 rows x 147 columns]\n",
      "            official  Advertising & Marketing Services  Advertising Agencies  \\\n",
      "0  Allen, Richard W.                               NaN                   NaN   \n",
      "1      Amash, Justin                               NaN                   NaN   \n",
      "\n",
      "   Aerospace & Defense  Aerospace/Defense  Agricultural Inputs  Agriculture  \\\n",
      "0                  1.0                NaN                  NaN          NaN   \n",
      "1                  NaN                NaN                  NaN          NaN   \n",
      "\n",
      "   Airlines  Apparel Manufacturing  Apparel Retail  ...  \\\n",
      "0       NaN                    NaN             NaN  ...   \n",
      "1       NaN                    NaN             NaN  ...   \n",
      "\n",
      "   Utilities - Independent Power Producers  Utilities - Regulated  \\\n",
      "0                                      NaN                    3.0   \n",
      "1                                      NaN                    NaN   \n",
      "\n",
      "   Utilities - Regulated Water  Utilities--Regulated Electric  \\\n",
      "0                          NaN                            NaN   \n",
      "1                          NaN                            NaN   \n",
      "\n",
      "   Utilities—Diversified  Utilities—Regulated Electric  \\\n",
      "0                    NaN                           NaN   \n",
      "1                    NaN                           NaN   \n",
      "\n",
      "   Utilities—Regulated Gas  Utilities—Regulated Water  Utilities—Renewable  \\\n",
      "0                      NaN                        NaN                  NaN   \n",
      "1                      NaN                        NaN                  NaN   \n",
      "\n",
      "   Waste Management  \n",
      "0               NaN  \n",
      "1               NaN  \n",
      "\n",
      "[2 rows x 208 columns]\n"
     ]
    }
   ],
   "source": [
    "def frequency_of_industry_breakdown_official(group, diff):\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            industry = dir_utils.search_mapping(industry_df, t[constants.TICKER], industry=True)\n",
    "            d = dict_utils.increment_dictionary_in_dictionary(d, official.get_name(t), industry)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_keys(d)\n",
    "    \n",
    "    filename = \"frequency_of_industry_breakdown_official\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.INDUSTRY)\n",
    "\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, constants.OFFICIAL)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "    \n",
    "    return d \n",
    "\n",
    "d1 = frequency_of_industry_breakdown_official(house_input_df, constants.HOUSE)\n",
    "d2 = frequency_of_industry_breakdown_official(senate_input_df, constants.SENATE)\n",
    "d3 = frequency_of_industry_breakdown_official(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency of Industry per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           industry  2018  2019  2020  2021  total\n",
      "0  Advertising & Marketing Services   NaN   3.0   6.0   1.0     10\n",
      "1              Advertising Agencies   NaN   5.0   5.0   NaN     10\n",
      "                           industry  2012  2013  2014  2015  2016  2017  2018  \\\n",
      "0  Advertising & Marketing Services   NaN   NaN   NaN   1.0   NaN   NaN   NaN   \n",
      "1               Aerospace & Defense   NaN   NaN  15.0  12.0   8.0  19.0  33.0   \n",
      "\n",
      "   2019  2020  2021  total  \n",
      "0   NaN   NaN   NaN      1  \n",
      "1  37.0  28.0   4.0    156  \n",
      "                           industry  2012  2013  2014  2015  2016  2017  2018  \\\n",
      "0  Advertising & Marketing Services   NaN   NaN   NaN   1.0   NaN   NaN   NaN   \n",
      "1              Advertising Agencies   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "\n",
      "   2019  2020  2021  total  \n",
      "0   3.0   6.0   1.0     11  \n",
      "1   5.0   5.0   NaN     10  \n"
     ]
    }
   ],
   "source": [
    "def frequency_of_industry_breakdown(group, diff):\n",
    "    \n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():     \n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            industry = dir_utils.search_mapping(industry_df, t[constants.TICKER], industry=True)  \n",
    "            d = dict_utils.increment_dictionary_in_dictionary(d, industry, ptr_utils.get_year(t[constants.TDATE]))\n",
    "            d = dict_utils.increment_dictionary_in_dictionary(d, industry, constants.TOTAL)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_keys(d)\n",
    "    \n",
    "    filename = \"frequency_of_industry_breakdown\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff \n",
    "    key_header = \"industry\"\n",
    "    \n",
    "    \n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.INDUSTRY)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "    return d \n",
    "\n",
    "d1 = frequency_of_industry_breakdown(house_input_df, constants.HOUSE)\n",
    "d2 = frequency_of_industry_breakdown(senate_input_df, constants.SENATE)\n",
    "d3 = frequency_of_industry_breakdown(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asset Description (asset_description) and Comment (comment) CONFIRMED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'float' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/y3/llvqw9gd7nz5vkbmv014r2kc0000gn/T/ipykernel_12610/841614371.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0md1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumber_of_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhouse_input_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0md2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumber_of_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msenate_input_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0md3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumber_of_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/y3/llvqw9gd7nz5vkbmv014r2kc0000gn/T/ipykernel_12610/841614371.py\u001b[0m in \u001b[0;36mnumber_of_options\u001b[0;34m(group)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# constants.ASSET_DESCRIPTION in t and ptr_utils.isvalid(t[constants.ASSET_DESCRIPTION]) and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mptr_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misvalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mASSET_DESCRIPTION\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"Option\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mASSET_DESCRIPTION\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"option\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mASSET_DESCRIPTION\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mpeople\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mofficial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'float' is not iterable"
     ]
    }
   ],
   "source": [
    "def number_of_options(group):\n",
    "    count = total = 0 \n",
    "    d = {}\n",
    "    # [this_person_placed_an_option, ...]\n",
    "    people = set()\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if constants.ASSET_DESCRIPTION in t and ptr_utils.isvalid(constants.ASSET_DESCRIPTION): \n",
    "            if \"Option\" in t[constants.ASSET_DESCRIPTION] or \"option\" in t[constants.ASSET_DESCRIPTION]:\n",
    "                count += 1 \n",
    "                people.add(official.get_name(t))\n",
    "        total += 1 \n",
    "\n",
    "    d[\"(No. of Options, %)\"] = (count, ptr_utils.make_percent(count, total))\n",
    "\n",
    "    return d \n",
    "            \n",
    "d1 = number_of_options(house_input_df)\n",
    "d2 = number_of_options(senate_input_df)\n",
    "d3 = number_of_options(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.COMMENT)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"number_of_options\", (d1,d2,d3), [\"\", constants.HOUSE, constants.SENATE, constants.INPUT])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Scanned PDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_scanned_pdfs(group):\n",
    "    count = 0 \n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if t[constants.ASSET_DESCRIPTION] == constants.DISCLOSED:\n",
    "            count += 1 \n",
    "            \n",
    "    d[\"(No. of Scanned PDFS, %)\"] = (count, ptr_utils.make_percent(count, len(input_df.index)))\n",
    "\n",
    "    return d \n",
    "            \n",
    "d1 = number_of_scanned_pdfs(house_input_df)\n",
    "d2 = number_of_scanned_pdfs(senate_input_df)\n",
    "d3 = number_of_scanned_pdfs(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.COMMENT)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"number_of_scanned_pdfs\", (d1,d2,d3), [\"\", constants.HOUSE, constants.SENATE, constants.INPUT])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions w/asset_description or comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_of_asset_description(group):\n",
    "    d = {}\n",
    "    count = total = 0\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if constants.ASSET_DESCRIPTION in t and ptr_utils.isvalid(t[constants.ASSET_DESCRIPTION]):\n",
    "            count += 1 \n",
    "        if constants.COMMENT in t and ptr_utils.isvalid(t[constants.COMMENT]):\n",
    "            count += 1 \n",
    "        total += 1 \n",
    "    \n",
    "    d[\"(No. of transactions with asset_description or comment, %)\"] = (count, ptr_utils.make_percent(count, total))\n",
    "\n",
    "    return d \n",
    "\n",
    "d1 = freq_of_asset_description(house_input_df)\n",
    "d2 = freq_of_asset_description(senate_input_df)\n",
    "d3 = freq_of_asset_description(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.COMMENT)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"freq_of_asset_description\", (d1,d2,d3), [\"\", constants.HOUSE, constants.SENATE, constants.INPUT])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asset Type (asset_type) CONFIRMED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Asset Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_asset_type(group):\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if constants.ATYPE in t and ptr_utils.isvalid(t[constants.ATYPE]):\n",
    "            d = dict_utils.increment_dictionary(d, t[constants.ATYPE])\n",
    "      \n",
    "    return dict_utils.sort_dictionary_by_values(d)\n",
    "\n",
    "d1 = frequency_of_asset_type(house_input_df)\n",
    "d2 = frequency_of_asset_type(senate_input_df)\n",
    "d3 = frequency_of_asset_type(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.ATYPE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"frequency_of_asset_type\", (d1,d2,d3), [constants.ATYPE, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amount CONFIRMED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Amount by Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              amount  $1,000 - $15,000  $1,000,000 +  $1,000,001 - $5,000,000  \\\n",
      "0  Allen, Richard W.               NaN           NaN                      NaN   \n",
      "1      Amash, Justin               NaN           NaN                      NaN   \n",
      "\n",
      "   $1,001 -  $1,001 - $15,000  $100,001 - $250,000  $15,000 - $50,000  \\\n",
      "0       NaN              15.0                  NaN                NaN   \n",
      "1       NaN               2.0                  NaN                NaN   \n",
      "\n",
      "   $15,001 - $50,000  $250,001 - $500,000  $5,000,001 - $25,000,000  \\\n",
      "0               21.0                  NaN                       NaN   \n",
      "1                1.0                  NaN                       NaN   \n",
      "\n",
      "   $50,000,000 +  $50,001 - $100,000  $500,001 - $1,000,000  \n",
      "0            NaN                 2.0                    NaN  \n",
      "1            NaN                 NaN                    NaN  \n",
      "              amount  $1,000,001 - $5,000,000  $1,001 - $15,000  \\\n",
      "0   Alexander, Lamar                      1.0               NaN   \n",
      "1  Barrasso, John A.                      NaN               NaN   \n",
      "\n",
      "   $100,001 - $250,000  $15,001 - $50,000  $25,000,001 - $50,000,000  \\\n",
      "0                  1.0               31.0                        NaN   \n",
      "1                  NaN                NaN                        NaN   \n",
      "\n",
      "   $250,001 - $500,000  $5,000,001 - $25,000,000  $50,001 - $100,000  \\\n",
      "0                  2.0                       NaN                22.0   \n",
      "1                  NaN                       NaN                 1.0   \n",
      "\n",
      "   $500,001 - $1,000,000  Over $50,000,000  \n",
      "0                    2.0               NaN  \n",
      "1                    NaN               NaN  \n"
     ]
    }
   ],
   "source": [
    "def frequency_of_amount_by_persom(group, diff):\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        d = dict_utils.increment_dictionary_in_dictionary(d, official.get_name(t), t[constants.AMOUNT])\n",
    "    \n",
    "    d = dict_utils.sort_dictionary_by_keys(d)\n",
    "    \n",
    "    filename = \"frequency_of_amount_by_persom\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff \n",
    "        \n",
    "    key_header = constants.AMOUNT\n",
    "    \n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.AMOUNT)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "    \n",
    "    return d \n",
    "   \n",
    "    \n",
    "d1 = frequency_of_amount_by_persom(house_input_df, constants.HOUSE)\n",
    "d2 = frequency_of_amount_by_persom(senate_input_df, constants.SENATE)\n",
    "# d3 = frequency_of_amount_by_persom(input_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Transactions by Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_amount_total(group):\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        d = dict_utils.increment_dictionary(d, t[constants.AMOUNT])\n",
    "\n",
    "    d = dict_utils.add_sort_key_for_amount(d, normal_header=\"num_of_transactions\", normal=True)\n",
    "    d = dict_utils.sort_dictionary_by_sort_key(d)\n",
    "\n",
    "    return d \n",
    "    \n",
    "d1 = frequency_of_amount_total(house_input_df)\n",
    "d2 = frequency_of_amount_total(senate_input_df)\n",
    "d3 = frequency_of_amount_total(input_df)\n",
    "\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.AMOUNT)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"frequency_of_amount_total\", (d1,d2,d3), [constants.AMOUNT, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Amount by Gender "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_amount_by_gender(group, diff):\n",
    "    d = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        name = official.get_name(t)\n",
    "        d = dict_utils.increment_dictionary_in_dictionary(d, t[constants.AMOUNT], official.get_gender(name))\n",
    "\n",
    "    d = dict_utils.add_sort_key_for_amount(d)\n",
    "    d = dict_utils.sort_dictionary_by_sort_key(d)\n",
    "    \n",
    "        \n",
    "    filename = \"frequency_of_amount_by_gender\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "    \n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.AMOUNT)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, constants.AMOUNT)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "    return d \n",
    "   \n",
    "    \n",
    "d1 = frequency_of_amount_by_gender(house_input_df, constants.HOUSE)\n",
    "d2 = frequency_of_amount_by_gender(senate_input_df, constants.SENATE)\n",
    "# d3 = frequency_of_amount_by_gender(input_df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Transactions by Political Affiliation and Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_amount_by_aff(group, diff):\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        obj = t_to_obj(t)\n",
    "        d = dict_utils.increment_dictionary_in_dictionary(d, t[constants.AMOUNT], obj.party)\n",
    "\n",
    "\n",
    "    d = dict_utils.add_sort_key_for_amount(d)\n",
    "    d = dict_utils.sort_dictionary_by_sort_key(d)\n",
    "    \n",
    "        \n",
    "    filename = \"frequency_of_amount_by_aff\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "    \n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.AMOUNT)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, constants.AMOUNT)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "    \n",
    "    return d \n",
    "   \n",
    "    \n",
    "d1 = frequency_of_amount_by_aff(house_input_df, constants.HOUSE)\n",
    "d2 = frequency_of_amount_by_aff(senate_input_df, constants.SENATE)\n",
    "# d3 = frequency_of_amount_by_aff(input_df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average For Buys and Sells per Official "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_per_person(group, diff):\n",
    "    d={}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.AMOUNT]) and (t[constants.TYPE] == constants.PURCHASE or t[constants.TYPE] == constants.SALE):\n",
    "                        \n",
    "            mean = ptr_utils.get_gmean(t[constants.AMOUNT])\n",
    "\n",
    "            if t[constants.TYPE] == constants.PURCHASE: \n",
    "                mean = -mean \n",
    "\n",
    "            d = dict_utils.increment_list_in_dictionary(d, official.get_name(t), mean)\n",
    "\n",
    "\n",
    "    d = dict_utils.flatten_gmean(d)        \n",
    "            \n",
    "    filename = \"average_per_person\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "\n",
    "    key_header = constants.OFFICIAL \n",
    "    value_header = \"average_size_of_transactions\"\n",
    "\n",
    "    d2 = dict_utils.sort_dictionary_by_values(d)\n",
    "    d = dict_utils.commify(d)\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.AMOUNT)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "\n",
    "    return d \n",
    "\n",
    "d1 = average_per_person(house_input_df, constants.HOUSE)\n",
    "d2 = average_per_person(senate_input_df, constants.SENATE)\n",
    "# d3 = average_per_person(input_df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_activity(group, diff):\n",
    "    d={}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "                        \n",
    "            mean = ptr_utils.get_gmean(t[constants.AMOUNT])\n",
    "\n",
    "            d = dict_utils.increment_list_in_dictionary(d, official.get_name(t), mean)\n",
    "\n",
    "\n",
    "    d = dict_utils.flatten_gmean(d)        \n",
    "            \n",
    "    filename = \"average_activity\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "\n",
    "    key_header = constants.OFFICIAL \n",
    "    value_header = \"average_size_of_transactions\"\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_values(d)\n",
    "    d = dict_utils.commify(d)\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.AMOUNT)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "\n",
    "    return d \n",
    "\n",
    "d1 = average_activity(house_input_df, constants.HOUSE)\n",
    "d2 = average_activity(senate_input_df, constants.SENATE)\n",
    "d3 = average_activity(input_df, constants.INPUT) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types (type) CONFIRMED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Actions Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_act(group):\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TYPE]): \n",
    "            d = dict_utils.increment_dictionary(d, t[constants.TYPE])\n",
    "    \n",
    "    return dict_utils.sort_dictionary_by_values(d)\n",
    "    \n",
    "     \n",
    "d1 = frequency_of_act(house_input_df)\n",
    "d2 = frequency_of_act(senate_input_df)\n",
    "d3 = frequency_of_act(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.TYPE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"frequency_of_act\", (d1,d2,d3), [constants.TYPE, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Transactions per Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def types_of_transactions_per_person(group, diff):\n",
    "    d={}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        d = dict_utils.increment_dictionary_in_dictionary(d, official.get_name(t), t[constants.TYPE])\n",
    "        d = dict_utils.increment_dictionary_in_dictionary(d, official.get_name(t), constants.TOTAL)\n",
    "\n",
    "\n",
    "    filename = \"types_of_transactions_per_person\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_keys(d)\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TYPE)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, constants.OFFICIAL)\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "\n",
    "    return d \n",
    "\n",
    "d1 = types_of_transactions_per_person(house_input_df, constants.HOUSE)\n",
    "d2 = types_of_transactions_per_person(senate_input_df, constants.SENATE)\n",
    "d3 = types_of_transactions_per_person(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency CONFIRMED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_per_year(group, normalized):\n",
    "    d={}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        d =  dict_utils.increment_dictionary(d, ptr_utils.get_year(t[constants.TDATE]))\n",
    "\n",
    "    for k,v in d.items():\n",
    "        d[k] = v/normalized\n",
    "        \n",
    "    return dict_utils.sort_dictionary_by_values(d)\n",
    "\n",
    "d1 = num_of_trans_per_year(house_input_df, len(input_house_officials_objects))\n",
    "d2 = num_of_trans_per_year(senate_input_df, len(input_senate_officials_objects))\n",
    "d3 = num_of_trans_per_year(input_df, len(input_officials_objects))\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.FREQ)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_per_year\", (d1,d2,d3), [\"Year\", constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Person \n",
    "_Not controlling for number of years in position or size of transaction._ For each official, we want their total number of transactions.  {'Sam': 5, 'Alex': 2424, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_per_person(group):\n",
    "    d={}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        d = dict_utils.increment_dictionary(d, official.get_name(t))\n",
    "\n",
    "    return dict_utils.sort_dictionary_by_values(d)\n",
    "    \n",
    "d1 = num_of_trans_per_person(house_input_df)\n",
    "d2 = num_of_trans_per_person(senate_input_df)    \n",
    "d3 = num_of_trans_per_person(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_per_person\", (d1,d2,d3), [constants.OFFICIAL, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Person Controlled\n",
    "_Divide number of transactions by number of years in official position.  Not controlling for size of transaction._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_per_person_controlled(group):    \n",
    "    d={}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        d = dict_utils.increment_dictionary(d, official.get_name(t))\n",
    "        \n",
    "    for k,v in d.items():\n",
    "        obj = t_to_obj(t)\n",
    "        d[k] = int(v/obj.get_seniority())\n",
    "\n",
    "    return dict_utils.sort_dictionary_by_values(d)\n",
    "\n",
    "\n",
    "d1 = num_of_trans_per_person_controlled(house_input_df)\n",
    "d2 = num_of_trans_per_person_controlled(senate_input_df)\n",
    "d3 = num_of_trans_per_person_controlled(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.FREQ)\n",
    "\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_per_person_controlled\", (d1, d2, d3), [constants.OFFICIAL, constants.HOUSE, constants.SENATE, constants.INPUT])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e534e48711db4d1e1c48977d0d14ff85b1f16d41bcc4fdfd88268a329b3c9d66"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
