{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHASE 1: PROFILE + GEN Q'S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.csv_utils as csv_utils \n",
    "import utils.dir_utils as dir_utils\n",
    "import utils.dict_utils as dict_utils \n",
    "import utils.ptr_utils as ptr_utils\n",
    "import utils.constants as constants \n",
    "import helpers.official as official\n",
    "import helpers.search as search\n",
    "import helpers.congress as congress\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, input_df = dir_utils.get_data(combined=True)\n",
    "_, house_input_df = dir_utils.get_data(house=True)\n",
    "_, senate_input_df = dir_utils.get_data(senate=True)\n",
    "\n",
    "num_of_transactions = input_df.shape[0]\n",
    "num_of_house_transactions = house_input_df.shape[0]\n",
    "num_of_senate_transactions = senate_input_df.shape[0]\n",
    "\n",
    "sector_df = dir_utils.get_mapping(sector=True)\n",
    "industry_df = dir_utils.get_mapping(industry=True)\n",
    "\n",
    "# {canonical_name_input_based : link, ...}\n",
    "input_all_officials_name = {}\n",
    "\n",
    "# {link : canonical_name_input_based, ....}\n",
    "input_all_officials_link = {}\n",
    "input_house_officials_link = {}\n",
    "input_senate_officials_link = {}\n",
    "\n",
    "# (canonical_name_input_based, ...)\n",
    "names = set()\n",
    "\n",
    "for _,t in input_df.iterrows():        \n",
    "    name = official.get_name(t)\n",
    "        \n",
    "    if name not in names:    \n",
    "        link = search.get_wiki_link(name)\n",
    "                \n",
    "        if ptr_utils.isvalid(t[constants.REPRESENTATIVE]) and link not in input_house_officials_link:\n",
    "            input_house_officials_link =  dict_utils.increment_dictionary(input_house_officials_link, link, name, not_math=True)\n",
    "        if ptr_utils.isvalid(t[constants.SENATOR]) and link not in input_senate_officials_link:\n",
    "            input_senate_officials_link =  dict_utils.increment_dictionary(input_senate_officials_link, link, name, not_math=True)\n",
    "        \n",
    "        input_all_officials_link =  dict_utils.increment_dictionary(input_all_officials_link, link, name, not_math=True)\n",
    "        input_all_officials_name =  dict_utils.increment_dictionary(input_all_officials_name, name, link, not_math=True)\n",
    "\n",
    "        names.add(name)\n",
    "\n",
    "print(\"Number of transactions: {} \\n\".format(ptr_utils.commify_str(len(input_df.index))))\n",
    "\n",
    "print(\"Number of transactions by House Representatives: {}, {}\".format(ptr_utils.commify_str(num_of_house_transactions), ptr_utils.make_percent(num_of_house_transactions, len(input_df.index))))\n",
    "print(\"Number of transactions by House Representatives controlled: {0:.2f} transactions per representative \\n\".format((num_of_house_transactions / len(input_house_officials_link))))\n",
    "\n",
    "print(\"Number of transactions by Senators: {}, {}\".format(ptr_utils.commify_str(num_of_senate_transactions), ptr_utils.make_percent(num_of_senate_transactions, len(input_df.index))))\n",
    "print(\"Number of transactions by Senators controlled: {0:.2f} transactions per senator \\n\".format( (num_of_senate_transactions /  len(input_senate_officials_link))))\n",
    "\n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "input_house_officials_objects = {}\n",
    "for link, person in input_house_officials_link.items(): \n",
    "    off = search.wiki_search(person)        \n",
    "    input_house_officials_objects[link] = (person, off)\n",
    "        \n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "input_senate_officials_objects = {}\n",
    "for link, person in input_senate_officials_link.items():\n",
    "    off = search.wiki_search(person)        \n",
    "    input_senate_officials_objects[link] = (person, off)\n",
    "\n",
    "# {link : (canonical_name_input_based, official_object) ... }\n",
    "input_officials_objects = {**input_house_officials_objects, **input_senate_officials_objects}\n",
    "\n",
    "# {link : canonical_name_wiki_based, ... }\n",
    "all_officials = congress.get_all_officials()\n",
    "house_officials = congress.get_house_officials()\n",
    "senate_officials = congress.get_senate_officials()\n",
    "\n",
    "# {link : gender, ...}\n",
    "officials_gender = {}\n",
    "for link, name in all_officials.items():\n",
    "    gender = official.get_gender(name, link)\n",
    "    officials_gender[link] = gender\n",
    "\n",
    "# {'California' :  #_of_representatives_from_112_to_117, ...}\n",
    "all_officials_state_count = congress.get_officials_state(everyone=list(all_officials.values()))\n",
    "house_officials_state_count = congress.get_officials_state(house=list(house_officials.values()))\n",
    "senate_officials_state_count = congress.get_officials_state(everyone=list(senate_officials.values()))\n",
    "\n",
    "congress_objects = []\n",
    "house_officials_party = {}\n",
    "senate_officials_party = {}\n",
    "for i in range(112, 118):\n",
    "    c = search.get_congress(i)\n",
    "    congress_objects.append(c)\n",
    "    house_officials_party.update(c.get_house_party())\n",
    "    senate_officials_party.update(c.get_senate_party())\n",
    "all_officials_party = {**house_officials_party, **senate_officials_party}\n",
    "\n",
    "    \n",
    "# {link : canonical_name_wiki_based, ... }\n",
    "all_officials_not_in_input = dict(all_officials)\n",
    "\n",
    "for link_input in input_all_officials_link.keys():\n",
    "    del all_officials_not_in_input[link_input]\n",
    "    \n",
    "print(\"Number of officials in input: {}\".format(len(input_all_officials_link)))\n",
    "print(\"Number of officials in input controlled: {}\\n\".format(ptr_utils.make_percent(len(input_all_officials_link), len(all_officials))))\n",
    "\n",
    "print(\"Number of representatives in input: {}, {}\".format(len(input_house_officials_link), ptr_utils.make_percent(len(input_house_officials_link), len(input_all_officials_link))))\n",
    "print(\"Number of representatives in input controlled: {} \\n\".format(ptr_utils.make_percent(len(input_house_officials_link), len(house_officials))))\n",
    "\n",
    "print(\"Number of senators in input: {}, {}\".format(len(input_senate_officials_link), ptr_utils.make_percent(len(input_senate_officials_link), len(input_all_officials_link))))\n",
    "print(\"Number of senators in input controlled: {} \\n\".format(ptr_utils.make_percent(len(input_senate_officials_link), len(senate_officials))))\n",
    "\n",
    "print(\"Number of officials in total (from 112-117th congress): {}\".format(ptr_utils.commify_str(len(all_officials))))\n",
    "print(\"Number of representatives in total (from 112-117th congress): {}\".format(ptr_utils.commify_str(len(house_officials))))\n",
    "print(\"Number of senators in total (from 112-117th congress): {}\\n\".format(ptr_utils.commify_str(len(senate_officials))))\n",
    "\n",
    "print(\"Number of officials from 112-117th congress who did NOT engage in the market: {}, {}\".format(len(all_officials_not_in_input), ptr_utils.make_percent(len(all_officials_not_in_input), len(all_officials) ) ))\n",
    "\n",
    "print(\"Number of officials from 112-117th congress who DID engage in the market: {}, {} \\n\".format(len(all_officials_not_in_input), ptr_utils.make_percent(len(input_all_officials_link), len(all_officials) ) ))\n",
    "\n",
    "def t_to_obj(t):\n",
    "    name = official.get_name(t)\n",
    "    link = input_all_officials_name[name]\n",
    "    _, obj = input_officials_objects[link]\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age (Lowest, Highest, Average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_age(group):\n",
    "    # {age, age, ...}\n",
    "    l = []\n",
    "    \n",
    "    # group = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for _, (_, off_obj) in group.items(): \n",
    "        l.append(off_obj.get_age())\n",
    "    \n",
    "    l.sort()\n",
    "    \n",
    "    d = {}\n",
    "    d[\"0. Youngest\"] = l[0]\n",
    "    d[\"1. Average\"] = round((sum(l) / len(l)))\n",
    "    d[\"2. Oldest\"] = l[len(l)-1]\n",
    "    \n",
    "    return d \n",
    "    \n",
    "d1 = profile_age(input_house_officials_objects)\n",
    "d2 = profile_age(input_senate_officials_objects)\n",
    "d3 = profile_age(input_officials_objects)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_age\", (d1,d2,d3), [\"Age\", constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "def profile_age_2(group):\n",
    "    # {age : #_of_people, ...}\n",
    "    d = dict(constants.age_groups)\n",
    "    \n",
    "    for (_, off_obj) in group.values(): \n",
    "        age = off_obj.get_age()\n",
    "        d = dict_utils.increment_dictionary(d, ptr_utils.which_age_group(age)) \n",
    "    \n",
    "    return d \n",
    "    \n",
    "d1 = profile_age_2(input_house_officials_objects)\n",
    "d2 = profile_age_2(input_senate_officials_objects)\n",
    "d3 = profile_age_2(input_officials_objects)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_age_2\", (d1,d2,d3), [\"Age\", constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age (Which age is most active?) Active = No. of Trades &  Size of Transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_active_age(group, normalized):\n",
    "    # {age : 45_transactions}\n",
    "    d_number = dict(constants.age_groups)\n",
    "    \n",
    "    # {age : [gmean, gmean, ...]}\n",
    "    d_size = dict(constants.age_groups)\n",
    "    for k,_ in d_size.items():\n",
    "        d_size[k] = []\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "            obj = t_to_obj(t)\n",
    "            age = obj.get_age()\n",
    "            \n",
    "            age_group = ptr_utils.which_age_group(age)\n",
    "            d_number =  dict_utils.increment_dictionary(d_number, age_group)\n",
    "            \n",
    "            mean =  ptr_utils.get_gmean(t[constants.AMOUNT])             \n",
    "            d_size = dict_utils.increment_list_in_dictionary(d_size, age_group, mean)\n",
    "\n",
    "    d_size = dict_utils.flatten_gmean(d_size)\n",
    "\n",
    "    # Normalize\n",
    "    if normalized: \n",
    "        d_number = dict_utils.normalize(d_number, normalized, percent=True)\n",
    "        d_number = dict_utils.sort_dictionary_by_tuple(d_number)\n",
    "        \n",
    "        d_size = dict_utils.normalize(d_size, normalized)\n",
    "        d_size = dict_utils.sort_dictionary_by_tuple(d_size)\n",
    "\n",
    "    return d_number, d_size\n",
    "    \n",
    "d1,d4 = profile_active_age(house_input_df, profile_age_2(input_house_officials_objects))\n",
    "d2,d5 = profile_active_age(senate_input_df, profile_age_2(input_senate_officials_objects))\n",
    "d3,d6 = profile_active_age(input_df, profile_age_2(input_officials_objects))\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_age_active_number\", (d1,d2,d3), [\"Age\", constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_age_active_size\", (d4,d5,d6), [\"Age\", constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oldest and Most Recent Dates (transaction and disclosure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_dates(group, type):\n",
    "    lowest_tdate = lowest_ddate = highest_tdate = highest_ddate = None\n",
    "    lowest_tdate_obj = lowest_ddate_obj = highest_tdate_obj = highest_ddate_obj = None\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        curr = t[constants.TDATE]            \n",
    "        if not lowest_tdate or curr < lowest_tdate:\n",
    "            lowest_tdate = curr \n",
    "            lowest_tdate_obj = t\n",
    "        if not highest_tdate or curr > highest_tdate:\n",
    "            highest_tdate = curr  \n",
    "            highest_tdate_obj = t\n",
    "\n",
    "        curr = t[constants.DDATE]\n",
    "        if not lowest_ddate or curr < lowest_ddate:\n",
    "            lowest_ddate = curr \n",
    "            lowest_ddate_obj = t\n",
    "        if not highest_ddate or curr > highest_ddate:\n",
    "            highest_ddate = curr \n",
    "            highest_ddate_obj = t\n",
    "\n",
    "    print(\"Oldest transaction_date for {}: {} \\n {}\".format(type, lowest_tdate, lowest_tdate_obj[constants.PTR_LINK]))\n",
    "    print(\"Most recent transaction_date for {}: {} \\n {} \".format(type, highest_tdate, highest_tdate_obj[constants.PTR_LINK]))\n",
    "    \n",
    "    print(\"Oldest disclosure_date for {}: {} \\n {}\".format(type, lowest_ddate, lowest_ddate_obj[constants.PTR_LINK]))\n",
    "    print(\"Most recent disclosure_date for {}: {} \\n {}\\n\".format(type, highest_ddate, highest_ddate_obj[constants.PTR_LINK]))\n",
    "    \n",
    "\n",
    "profile_dates(house_input_df, constants.HOUSE)\n",
    "profile_dates(senate_input_df, constants.SENATE)\n",
    "profile_dates(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_gender(group, normalized=None):\n",
    "    # d_prime = {'Female' : set(Officials), 'Male' : set(Officials), ...}\n",
    "    d_prime = {}\n",
    "\n",
    "    for link, name in group.items(): \n",
    "        gender = officials_gender[link]\n",
    "        d_prime = dict_utils.increment_set_in_dictionary(d_prime, gender, name)\n",
    "\n",
    "    # d = {'Female' : #_of_officials, 'Male' : #_of_officials, ...}\n",
    "    d = dict_utils.flatten_len(d_prime, inner_set=True)\n",
    "    \n",
    "    if normalized:\n",
    "        d = dict_utils.normalize(d, normalized, percent=True)\n",
    "        d = dict_utils.sort_dictionary_by_tuple(d)\n",
    "                 \n",
    "    return d\n",
    "\n",
    "# {link : canonical_name_input_based, ....}\n",
    "d1 = profile_gender(input_house_officials_link, profile_gender(house_officials))\n",
    "d2 = profile_gender(input_senate_officials_link, profile_gender(senate_officials))\n",
    "d3 = profile_gender(input_all_officials_link, profile_gender(all_officials))\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_gender\", (d1,d2,d3), [constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender (Which gender is the most active?) Active = No. of Trades &  Size of Transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_active_gender(group, normalized):\n",
    "    # {'gender' : 5_trades, ...}\n",
    "    d_number = {}\n",
    "    \n",
    "    # {gender : [gmean of amount, gmean of amount....] }\n",
    "    d_size = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "            name = official.get_name(t)\n",
    "            link = input_all_officials_name[name]\n",
    "            g = officials_gender[link]\n",
    "            \n",
    "            d_number =  dict_utils.increment_dictionary(d_number, g)\n",
    "            \n",
    "            mean =  ptr_utils.get_gmean(t[constants.AMOUNT])             \n",
    "            d_size = dict_utils.increment_list_in_dictionary(d_size, g, mean)\n",
    "\n",
    "    d_size = dict_utils.flatten_gmean(d_size)\n",
    "        \n",
    "    # Normalize\n",
    "    if normalized:\n",
    "        d_number = dict_utils.normalize(d_number, normalized, percent=True)\n",
    "        d_number = dict_utils.sort_dictionary_by_tuple(d_number)\n",
    "        \n",
    "        d_size = dict_utils.normalize(d_size, normalized, percent=True)\n",
    "        d_size = dict_utils.sort_dictionary_by_tuple(d_size)\n",
    "\n",
    "    return d_number, d_size\n",
    "\n",
    "\n",
    "d1,d4 = profile_active_gender(house_input_df, profile_gender(house_officials))\n",
    "d2,d5 = profile_active_gender(senate_input_df, profile_gender(senate_officials))\n",
    "d3,d6 = profile_active_gender(input_df, profile_gender(all_officials))\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_gender_number\", (d1,d2,d3), [constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_gender_size\", (d4,d5,d6), [constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_party(group, normalized=None):\n",
    "    # d_prime = {'Republican' : set(Officials), 'Democrat' : set(Officials), ...}\n",
    "    d_prime = {}\n",
    "    \n",
    "    for (_, off_obj) in group.values(): \n",
    "        d_prime = dict_utils.increment_set_in_dictionary(d_prime, off_obj.party, off_obj.name)\n",
    "        \n",
    "    # d = {'Republican' : #_of_officials, 'Democrat' : #_of_officials, ...}\n",
    "    d = dict_utils.flatten_len(d_prime, inner_set=True)\n",
    "    \n",
    "    if normalized: \n",
    "        d = dict_utils.normalize(d, normalized, percent=True)\n",
    "        d = dict_utils.sort_dictionary_by_tuple(d)\n",
    "\n",
    "    return d\n",
    "\n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "d1 = profile_party(input_house_officials_objects, house_officials_party)\n",
    "d2 = profile_party(input_senate_officials_objects, senate_officials_party)\n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "d3 = profile_party(input_officials_objects, all_officials_party)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_party\", (d1,d2,d3), [constants.PARTY, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Party (Which party is the most active?) Active = No. of Trades &  Size of Transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_active_party(group, normalized=None):\n",
    "    # {'party' : 5_trades, ...}\n",
    "    d_number = {}\n",
    "    \n",
    "    # {party : [gmean of amount, gmean of amount....] }\n",
    "    d_size = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "            obj = t_to_obj(t)\n",
    "            party = obj.party        \n",
    "            \n",
    "            d_number =  dict_utils.increment_dictionary(d_number, party)\n",
    "            \n",
    "            mean =  ptr_utils.get_gmean(t[constants.AMOUNT])             \n",
    "            d_size = dict_utils.increment_list_in_dictionary(d_size, party, mean)\n",
    "\n",
    "    d_size = dict_utils.flatten_gmean(d_size)\n",
    "        \n",
    "    # Normalize\n",
    "    if normalized:\n",
    "        d_number = dict_utils.normalize(d_number, normalized, percent=True)\n",
    "        d_number = dict_utils.sort_dictionary_by_tuple(d_number)\n",
    "        \n",
    "        d_size = dict_utils.normalize(d_size, normalized, percent=True)\n",
    "        d_size = dict_utils.sort_dictionary_by_tuple(d_size)\n",
    "    \n",
    "    return d_number, d_size\n",
    "\n",
    "d1,d4 = profile_active_party(house_input_df, house_officials_party)\n",
    "d2,d5 = profile_active_party(senate_input_df, senate_officials_party)\n",
    "d3,d6 = profile_active_party(input_df, all_officials_party)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_party_number\", (d1,d2,d3), [constants.PARTY, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_party_size\", (d4,d5,d6), [constants.PARTY, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_state(group, normalized=None):\n",
    "    # d_prime = {'Maryland' : set(Officials), 'California' : set(Officials), ...}\n",
    "    d_prime = {}\n",
    "    \n",
    "    # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for _, off_obj in group.values(): \n",
    "        d_prime = dict_utils.increment_set_in_dictionary(d_prime, off_obj.state, off_obj.name)\n",
    "\n",
    "    # d = {'Maryland' : #_of_officials, 'California' : #_of_officials, ...}\n",
    "    d = dict_utils.flatten_len(d_prime, inner_set=True)\n",
    "    \n",
    "    if normalized:\n",
    "        d = dict_utils.normalize(d, normalized, percent=True)\n",
    "        d = dict_utils.sort_dictionary_by_tuple(d)\n",
    "            \n",
    "    return d \n",
    "\n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "d1 = profile_state(input_house_officials_objects, house_officials_state_count)\n",
    "d2 = profile_state(input_senate_officials_objects, senate_officials_state_count)\n",
    "\n",
    "# {link : (canonical_name_input_based, official_object) ... }\n",
    "d3 = profile_state(input_officials_objects, all_officials_state_count)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_state\", (d1,d2,d3), [constants.STATE, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State (Which state is the most active?) Active = No. of Trades &  Size of Transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_active_state(group, normalized=None):\n",
    "    # {'state' : 5_trades, ...}\n",
    "    d_number = {}\n",
    "    \n",
    "    # {state : [gmean of amount, gmean of amount....] }\n",
    "    d_size = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "            obj =  t_to_obj(t)\n",
    "            \n",
    "            d_number =  dict_utils.increment_dictionary(d_number, obj.state)\n",
    "            \n",
    "            mean =  ptr_utils.get_gmean(t[constants.AMOUNT])             \n",
    "            d_size = dict_utils.increment_list_in_dictionary(d_size, obj.state, mean)\n",
    "\n",
    "    d_size = dict_utils.flatten_gmean(d_size)\n",
    "    \n",
    "    if normalized:\n",
    "        d_number = dict_utils.normalize(d_number, normalized, percent=True)\n",
    "        d_number = dict_utils.sort_dictionary_by_tuple(d_number)\n",
    "        \n",
    "        d_size = dict_utils.normalize(d_size, normalized, percent=True)\n",
    "        d_size = dict_utils.sort_dictionary_by_tuple(d_size)\n",
    "\n",
    "    return d_number, d_size\n",
    "\n",
    "d1,d4 = profile_active_state(house_input_df, house_officials_state_count)\n",
    "d2,d5 = profile_active_state(senate_input_df, senate_officials_state_count)\n",
    "d3,d6 = profile_active_state(input_df, all_officials_state_count)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_state_number\", (d1,d2,d3), [constants.STATE, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_state_size\", (d4,d5,d6), [constants.STATE, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seniority (Lowest, Highest, Average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_seniority(group):\n",
    "    # d = {x_years_in_congress, y_years_in_congres, ...}\n",
    "    l = []\n",
    "    \n",
    "    # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for _, (_, off_obj) in group.items(): \n",
    "        l.append(off_obj.get_seniority())\n",
    "    \n",
    "    l.sort()\n",
    "    \n",
    "    d = {}\n",
    "    d[\"0. Lowest\"] = l[0]\n",
    "    d[\"1. Average\"] = round((sum(l) / len(l)))\n",
    "    d[\"2. Highest\"] = l[len(l)-1]\n",
    "\n",
    "    return d \n",
    "\n",
    "d1 = profile_seniority(input_house_officials_objects)\n",
    "d2 = profile_seniority(input_senate_officials_objects)\n",
    "d3 = profile_seniority(input_officials_objects)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_seniority\", (d1,d2,d3), [constants.SENIORITY, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "def profile_seniority_2(group):\n",
    "    # d = {x_years_in_congress : #_of_people, }\n",
    "    d = {}\n",
    "    \n",
    "    # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for (_, off_obj) in group.values(): \n",
    "        d =  dict_utils.increment_dictionary(d, off_obj.get_seniority())\n",
    "    \n",
    "    return d \n",
    "\n",
    "d1 = profile_seniority_2(input_house_officials_objects)\n",
    "d2 = profile_seniority_2(input_senate_officials_objects)\n",
    "d3 = profile_seniority_2(input_officials_objects)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_seniority_2\", (d1,d2,d3), [constants.SENIORITY, constants.HOUSE, constants.SENATE, constants.INPUT])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seniority (Which seniority is most active?) Active = No. of Trades & Size of Transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_active_age(group):\n",
    "    # {'seniority' : 5_peeps_with_it, ...}\n",
    "    d_number = {}\n",
    "    \n",
    "    # {'seniority' :  [gmean of amount, gmean of amount....] }\n",
    "    d_size = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "            obj = t_to_obj(t)\n",
    "            seniority = obj.get_seniority()\n",
    "            \n",
    "            d_number =  dict_utils.increment_dictionary(d_number, seniority)\n",
    "            \n",
    "            mean =  ptr_utils.get_gmean(t[constants.AMOUNT])             \n",
    "            d_size = dict_utils.increment_list_in_dictionary(d_size, seniority, mean)\n",
    "    \n",
    "    d_size = dict_utils.flatten_gmean(d_size)\n",
    "\n",
    "    # Normalize\n",
    "    total = profile_seniority_2(input_officials_objects)\n",
    "    \n",
    "    for k,v in d_number.items():\n",
    "        d_number[k] = round(v/total[k], 0)\n",
    "    \n",
    "    for k,v in d_size.items():\n",
    "        d_size[k] = round(v/total[k], 0)\n",
    "\n",
    "    return d_number, d_size\n",
    "    \n",
    "d1,d4 = profile_active_age(house_input_df)\n",
    "d2,d5 = profile_active_age(senate_input_df)\n",
    "d3,d6 = profile_active_age(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_age_number\", (d1,d2,d3), [constants.AGE, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_active_age_size\", (d4,d5,d6), [constants.AGE, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get_Congress (Lowest, Highest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Degrees (Lowest, Highest, Average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_congress(group):\n",
    "    lowest = highest = None \n",
    "    \n",
    "    # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for (_, off_obj) in group.values():\n",
    "        res = off_obj.get_congress()\n",
    "        \n",
    "        if not lowest or res[0] < lowest:\n",
    "            lowest = res[0]\n",
    "    \n",
    "        if not highest or res[len(res) - 1] > highest:\n",
    "            highest = res[len(res) - 1]\n",
    "                    \n",
    "    d = {}\n",
    "    d[\"Lowest Congress\"] = lowest\n",
    "    d[\"Highest Congress\"] = highest\n",
    "\n",
    "    return d \n",
    "                        \n",
    "d1 = profile_congress(input_house_officials_objects)\n",
    "d2 = profile_congress(input_senate_officials_objects)\n",
    "d3 = profile_congress(input_officials_objects)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_congress\", (d1,d2,d3), [\"\", constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_degrees(group):    \n",
    "    # d = {x_degrees, y_degrees, ...}\n",
    "    l = []\n",
    "    \n",
    "    # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for (_, off_obj) in group.values(): \n",
    "        l.append(off_obj.get_num_of_degrees())\n",
    "    \n",
    "    l.sort()\n",
    "    \n",
    "    d = {}\n",
    "    d[\"0. Lowest\"] = l[0]\n",
    "    d[\"1. Average\"] = round((sum(l) / len(l)))\n",
    "    d[\"2. Highest\"] = l[len(l)-1]\n",
    "\n",
    "    return d \n",
    "    \n",
    "d1 = profile_degrees(input_house_officials_objects)\n",
    "d2 = profile_degrees(input_senate_officials_objects)\n",
    "d3 = profile_degrees(input_officials_objects)       \n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_degrees\", (d1,d2,d3), [\"No. of Degrees\", constants.HOUSE, constants.SENATE, constants.INPUT]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_JD(group):\n",
    "    # d = {x_degrees, y_degrees, ...}\n",
    "    yes = total = 0 \n",
    "    \n",
    "    # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for (_, off_obj) in group.values(): \n",
    "        if off_obj.has_JD():\n",
    "            yes += 1 \n",
    "        total += 1 \n",
    "        \n",
    "    d = {}\n",
    "    \n",
    "    d[\"(Raw, Percent)\"] = (yes, ptr_utils.make_percent(yes, total))\n",
    "    \n",
    "    return d \n",
    "    \n",
    "d1 = profile_JD(input_house_officials_objects)\n",
    "d2 = profile_JD(input_senate_officials_objects)\n",
    "d3 = profile_JD(input_officials_objects)        \n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"profile_JDs\", (d1,d2,d3), [\"\", constants.HOUSE, constants.SENATE, constants.INPUT]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transaction Date (transaction_date) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency of Differences between Transaction and Disclosure Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_differences(group):\n",
    "    d = {}\n",
    "    # match = {}\n",
    "    total = num = 0 \n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        # Negative, X days BEFORE\n",
    "        # Positive, Y dayas AFTER\n",
    "        diff = ptr_utils.difference_between_dates(t)      \n",
    "        total += 1 \n",
    "        num += diff   \n",
    "        \n",
    "        # match = {5 days: {'Tom' : 1313, 'X': 3 , ...}. ..}\n",
    "        # match =  dict_utils.increment_dictionary_in_dictionary(match, diff, official.get_name(t))\n",
    "            \n",
    "        d =  dict_utils.increment_dictionary(d, int(diff))\n",
    "    \n",
    "    d[\"Average\"] = ptr_utils.make_percent(num, total)\n",
    "    \n",
    "    return d \n",
    "    # return dict_utils.sort_dictionary_by_keys(d)\n",
    "\n",
    "d1 = frequency_of_differences(house_input_df)\n",
    "d2 = frequency_of_differences(senate_input_df)\n",
    "d3 = frequency_of_differences(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"frequency_of_differences\", (d1,d2,d3), [\"Difference\", constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each sector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_sector(group, diff):\n",
    "    # d_prime = {'sector' : {'date' : #_of_transactions, ....} , 'sector2' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            sector = dir_utils.search_mapping(sector_df, t[constants.TICKER], sector=True)            \n",
    "            d_prime =  dict_utils.increment_dictionary_in_dictionary(d_prime, sector, (t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    filename = \"transaction_date_wrt_sector\"  \n",
    "    if diff:\n",
    "        filename += \"_\" + diff \n",
    "    key_header = constants.SECTOR\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_sector(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_sector(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_sector(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each sector controlling for each official. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_sector_controlled(group, diff):    \n",
    "    # d_prime = { ('ticker' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime = dict_utils.increment_set_in_inner_dictionary(d_prime, t[constants.TICKER], t[constants.TDATE], official.get_name(t))\n",
    "       \n",
    "    \n",
    "    d_prime = dict_utils.flatten_len(d_prime)\n",
    "\n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    \n",
    "    filename = \"transaction_date_wrt_sector_controlled\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff \n",
    "     \n",
    "    key_header = constants.SECTOR\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_sector_controlled(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_sector_controlled(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_sector_controlled(input_df, constants.INPUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_industry(group, diff):    \n",
    "    # d_prime = {'industry' : {'date' : #_of_transactions, ....} , 'industry2' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            industry = dir_utils.search_mapping(industry_df, t[constants.TICKER], industry=True)\n",
    "\n",
    "            d_prime =  dict_utils.increment_dictionary_in_dictionary(d_prime, industry, (t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    filename = \"transaction_date_wrt_industry\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff  \n",
    "    key_header = constants.INDUSTRY\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_industry(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_industry(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_industry(input_df, constants.INPUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each industry controlling for official. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_industry_controlled(group, diff):\n",
    "    \n",
    "    # d_prime = { ('ticker' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            industry = dir_utils.search_mapping(industry_df, t[constants.TICKER], industry=True)\n",
    "            \n",
    "            d_prime = dict_utils.increment_set_in_inner_dictionary(d_prime, industry, t[constants.TDATE],  official.get_name(t))\n",
    "\n",
    "    d_prime = dict_utils.flatten_len(d_prime)\n",
    "    \n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "    \n",
    "    filename = \"transaction_date_wrt_industry_controlled\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff  \n",
    "    key_header = constants.INDUSTRY\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_industry_controlled(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_industry_controlled(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_industry_controlled(input_df, constants.INPUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each ticker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_ticker(group, diff):    \n",
    "    # d_prime = {'ticker' : {'date' : #_of_transactions, ....} , 'ticker2' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime =  dict_utils.increment_dictionary_in_dictionary(d_prime, t[constants.TICKER], (t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    filename = \"transaction_date_wrt_ticker\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "    key_header = constants.TICKER\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_ticker(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_ticker(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_ticker(input_df, constants.INPUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each ticker controlling for official."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_ticker_controlled(group, diff):    \n",
    "    # d_prime = { ('ticker' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():    \n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):    \n",
    "            name = official.get_name(t)\n",
    "            d_prime = dict_utils.increment_set_in_inner_dictionary(d_prime, t[constants.TICKER], t[constants.TDATE], name)\n",
    "       \n",
    "    d_prime = dict_utils.flatten_len_inner_set(d_prime)\n",
    "\n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    \n",
    "    filename = \"transaction_date_wrt_ticker_controlled\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff  \n",
    "        \n",
    "    key_header = constants.TICKER\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_ticker_controlled(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_ticker_controlled(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_ticker_controlled(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_type(group, diff):        \n",
    "    # d_prime = {'type' : {'date' : #_of_transactions, ....} , 'type2' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime =  dict_utils.increment_dictionary_in_dictionary(d_prime, ptr_utils.format_type(t[constants.TYPE]), (t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'type' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    filename = \"transaction_date_wrt_type\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff  \n",
    "    key_header = constants.TYPE\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df)\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_type(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_type(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_type(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for type controlling for official. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_type_controlled(group, diff):    \n",
    "    # d_prime = { ('type' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime = dict_utils.increment_set_in_inner_dictionary(d_prime, t[constants.TYPE], (t[constants.TDATE]), official.get_name(t))\n",
    "       \n",
    "\n",
    "    d_prime = dict_utils.flatten_len(d_prime)\n",
    "            \n",
    "    # d = {'type' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "    \n",
    "    \n",
    "    filename = \"transaction_date_wrt_type_controlled\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff  \n",
    "    key_header = constants.TYPE\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_type_controlled(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_type_controlled(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_type_controlled(input_df, constants.INPUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_amount(group, diff):\n",
    "    # d_prime = {'amount' : {'date' : #_of_transactions, ....} , 'amount1' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime =  dict_utils.increment_dictionary_in_dictionary(d_prime, t[constants.AMOUNT], (t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'type' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "    d = dict_utils.add_sort_key_for_amount(d)\n",
    "    d = dict_utils.sort_dictionary_by_sort_key(d)\n",
    "\n",
    "    filename = \"transaction_date_wrt_amount\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff  \n",
    "    key_header = constants.TYPE\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, key_header)\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_amount(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_amount(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_amount(input_df, constants.INPUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for amount controlling for official."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_amount_controlled(group, diff):\n",
    "    # d_prime = { ('amount' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "       d_prime = dict_utils.increment_set_in_inner_dictionary(d_prime, t[constants.AMOUNT], (t[constants.TDATE]), official.get_name(t))\n",
    "       \n",
    "\n",
    "    d_prime = dict_utils.flatten_len(d_prime)\n",
    "        \n",
    "    # d = {'amount' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "    d = dict_utils.add_sort_key_for_amount(d)\n",
    "    d = dict_utils.sort_dictionary_by_sort_key(d)\n",
    "    \n",
    "    \n",
    "    filename = \"transaction_date_wrt_amount_controlled\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff  \n",
    "    key_header = constants.AMOUNT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, key_header)\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "_ = transaction_date_wrt_amount_controlled(house_input_df, constants.HOUSE)\n",
    "_ = transaction_date_wrt_amount_controlled(senate_input_df, constants.SENATE)\n",
    "_ = transaction_date_wrt_amount_controlled(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each official."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_official(group, diff):\n",
    "    # d_prime = {'person1' : {'date' : #_of_transactions, ....} , 'person2' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime =  dict_utils.increment_dictionary_in_dictionary(d_prime, official.get_name(t), (t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'person' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    filename = \"transaction_date_wrt_official\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff \n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [constants.OFFICIAL, constants.TDATE, constants.NUMT])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "transaction_date_wrt_official_res = transaction_date_wrt_official(house_input_df, constants.HOUSE)\n",
    "transaction_date_wrt_official_res = transaction_date_wrt_official(senate_input_df, constants.SENATE)\n",
    "transaction_date_wrt_official_res = transaction_date_wrt_official(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_per_date(group):\n",
    "    d={}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        d =  dict_utils.increment_dictionary(d, (t[constants.TDATE]))\n",
    "\n",
    "    return d \n",
    "\n",
    "d1 = num_of_trans_per_date(house_input_df)\n",
    "d2 = num_of_trans_per_date(senate_input_df)\n",
    "d3 = num_of_trans_per_date(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_per_date\", (d1,d2,d3), [constants.TDATE, constants.HOUSE, constants.SENATE, constants.INPUT])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Transactions per Date Controlled\n",
    "_Number of transactions per date controlled by official. E.g. if Ted Baker made 40 transactions on 1/1/02 and Sam Wall made 2 transactions on 1/1/02, we conclude that there were two transactions on 1/1/02._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_per_date_controlled(group):    \n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        d =  dict_utils.increment_dictionary_in_dictionary(d, (t[constants.TDATE]), official.get_name(t))\n",
    "\n",
    "    return dict_utils.flatten_len(d, inner_set=True)\n",
    "    \n",
    "d1 = num_of_trans_per_date_controlled(house_input_df)\n",
    "d2 = num_of_trans_per_date_controlled(senate_input_df)\n",
    "d3 = num_of_trans_per_date_controlled(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_per_date_controlled\", (d1,d2,d3), [constants.TDATE, constants.HOUSE, constants.SENATE, constants.INPUT])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Transactions Within 2 Weeks Prior to Quarterly Tax Date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_within_tax_date(group):        \n",
    "        total = within = 0 \n",
    "        d = {}\n",
    "\n",
    "        for _,t in group.iterrows():  \n",
    "                total += 1 \n",
    "                if ptr_utils.within_tax_date(t[constants.TDATE]):\n",
    "                        within += 1 \n",
    "\n",
    "        d[\"(No. of transactions within 2 weeks of tax deadline, %)\"] = (within,  ptr_utils.make_percent(within, total))\n",
    "\n",
    "        return d \n",
    "\n",
    "d1 = num_of_trans_within_tax_date(house_input_df)\n",
    "d2 = num_of_trans_within_tax_date(senate_input_df)\n",
    "d3 = num_of_trans_within_tax_date(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_within_tax_date\", (d1,d2,d3), [\"\", constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Transactions Within 2 Weeks Prior to Quarterly Tax Date Semi-Controlled \n",
    "\n",
    "_Given dict='09/03/2021': {'Thomas H Tuberville': 1, 'Cynthia M Lummis': 1, 'A. Mitchell Mcconnell, Jr.': 1}...I only incremement the number of within (tax date) once per date per official. So, if an official does 100 transactions on a date within two weeks of a quarterly deadline, then I only count it as one transaction._\n",
    "\n",
    "_A Note: total === number of transactions per person per date (so not really all transactions) because someone could have potentially made 60 transactions on one date which we don't include in neither total or within, if applicable._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_within_tax_date_controlled(group):\n",
    "        total = within = 0 \n",
    "        people = set()\n",
    "        d = {}\n",
    "\n",
    "        for _, t in group.iterrows():\n",
    "                name = official.get_name(t)\n",
    "                if ptr_utils.within_tax_date(t[constants.TDATE]) and name not in people:\n",
    "                        people.add(name)\n",
    "                        within += 1 \n",
    "                total += 1         \n",
    "                \n",
    "        d[\"(No. of transactions within 2 weeks of tax deadline, %)\"] = (within,  ptr_utils.make_percent(within, total))\n",
    "\n",
    "        return d\n",
    "\n",
    "d1 = num_of_trans_within_tax_date_controlled(house_input_df)\n",
    "d2 = num_of_trans_within_tax_date_controlled(senate_input_df)\n",
    "d3 = num_of_trans_within_tax_date_controlled(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_within_tax_date_controlled\", (d1,d2,d3), [\"\", constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def people_and_within_tax_date(people):        \n",
    "#         # todo get number of senators. \n",
    "#         # todo is the monetary value of that equal!!!! \n",
    "#         d = {}\n",
    "#         for i in people:\n",
    "#                 d[i] = \"\"\n",
    "                \n",
    "#         d = dict_utils.sort_dictionary_by_keys(d)\n",
    "        \n",
    "#         dir = dir_utils.makesubdir(constants.path_csv, \"transaction_date/tax\")\n",
    "#         wd = csv_utils.make_csv(dir, \"people_and_within_tax_date_list\", d, [\"Officials\"])\n",
    "#         df = pd.read_csv(wd)\n",
    "#         print(\"People who posted transactions within two weeks of quarterly tax deadline:\\n {}\\n\".format(df.head(5)))\n",
    "\n",
    "#         print(\"Number of people who posted transactions within two weeks of quarterly tax deadline: {}\\n\".format(len(people)))\n",
    "        \n",
    "#         party = {}\n",
    "#         for p in people:\n",
    "#                 link = search.get_wiki_link(p)\n",
    "#                 _, obj = input_officials_objects[link]\n",
    "#                 party =  dict_utils.increment_dictionary(party, obj.party)\n",
    "                \n",
    "#         party = dict_utils.sort_dictionary_by_values(party)\n",
    "        \n",
    "#         wd = csv_utils.make_csv(dir, \"people_and_within_tax_date_list_w_aff\", party, [\"party\", \"number_of_filing_within_tax_date\"])\n",
    "#         df = pd.read_csv(wd)\n",
    "#         print(\"Party breakdown of people who posted transactions within two weeks of quarterly tax deadline:\\n {}\\n\".format(df.head(5)))\n",
    "\n",
    "# people_and_within_tax_date(num_of_trans_within_tax_date_controlled_res_house)\n",
    "# people_and_within_tax_date(num_of_trans_within_tax_date_controlled_res_senate)\n",
    "# people_and_within_tax_date(num_of_trans_within_tax_date_controlled_res_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def people_and_within_tax_date_how_often(people):\n",
    "\n",
    "#         d = {}\n",
    "#         d_controlled_by_dates = {}\n",
    "        \n",
    "#         for _,t in input_df.iterrows():\n",
    "#                 if official.get_canonical_name(t[title]) in people and ptr_utils.within_tax_date(t[constants.TDATE]):\n",
    "#                         d =  dict_utils.increment_dictionary(d, t[title])\n",
    "#                         d_controlled_by_dates =  dict_utils.increment_dictionary_in_dictionary(d_controlled_by_dates, t[constants.TDATE], t[title])\n",
    "\n",
    "#         d_controlled_by_dates_res  = {}\n",
    "#         for date in d_controlled_by_dates:\n",
    "#                 for person in d_controlled_by_dates[date]:\n",
    "#                         d_controlled_by_dates_res =  dict_utils.increment_dictionary(d_controlled_by_dates_res, person)\n",
    "\n",
    "#         d = dict_utils.sort_dictionary_by_values(d)\n",
    "#         d_controlled_by_dates_res = dict_utils.sort_dictionary_by_values(d_controlled_by_dates_res)\n",
    "\n",
    "#         dir = dir_utils.makesubdir(constants.path_csv, \"transaction_date/tax\")\n",
    "#         wd = csv_utils.make_csv(dir, \"people_and_within_tax_date_how_often\", d, [title, \"number_of_filing_within_tax_date\"])\n",
    "#         df = pd.read_csv(wd)\n",
    "#         print(\"People who posted transactions within two weeks of quarterly tax deadline and the number of transactions posted:\\n {}\\n\".format(df.head(5)))\n",
    "\n",
    "#         wd = csv_utils.make_csv(dir, \"people_and_within_tax_date_how_often_date_controlled\", d_controlled_by_dates_res, [title, \"number_of_filing_within_tax_date_date_controlled\"])\n",
    "#         df = pd.read_csv(wd)\n",
    "#         print(\"People who posted transactions within two weeks of quarterly tax deadline and the number of transactions posted controlled by date:\\n {}\\n\".format(df.head(5)))\n",
    "\n",
    "          \n",
    "# people_and_within_tax_date_how_often(num_of_trans_within_tax_date_controlled_res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Owner (owner) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Count of Owner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_count_of_owner(group):\n",
    "    # d = {'Joint' : 5}\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if constants.OWNER in t and ptr_utils.isvalid(t[constants.OWNER]) :\n",
    "            d =  dict_utils.increment_dictionary(d, t[constants.OWNER].capitalize())\n",
    "        \n",
    "    return dict_utils.sort_dictionary_by_values(d)\n",
    "    \n",
    "    \n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "d1 = freq_count_of_owner(house_input_df)\n",
    "d2 = freq_count_of_owner(senate_input_df)\n",
    "\n",
    "# {link : (canonical_name_input_based, official_object) ... }\n",
    "d3 = freq_count_of_owner(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.OWNER)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"freq_count_of_owner\", (d1,d2,d3), [\"Owner\", constants.HOUSE, constants.SENATE, constants.INPUT]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_count_by_spouse(group):\n",
    "    # d = {'x_spouse' : 5}\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if constants.OWNER in t and ptr_utils.isvalid(t[constants.OWNER]) and t[constants.OWNER].capitalize() == 'Spouse':\n",
    "            d =  dict_utils.increment_dictionary(d, official.get_name(t))\n",
    "        \n",
    "    return d\n",
    "    \n",
    "    \n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "d1 = freq_count_by_spouse(house_input_df)\n",
    "d2 = freq_count_by_spouse(senate_input_df)\n",
    "\n",
    "# {link : (canonical_name_input_based, official_object) ... }\n",
    "d3 = freq_count_by_spouse(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.OWNER)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"freq_count_by_spouse\", (d1,d2,d3), [\"Owner\", constants.HOUSE, constants.SENATE, constants.INPUT]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ticker (ticker) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_tickers(group):\n",
    "    # d = {'ticker' : #_of_times }\n",
    "    d = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d =  dict_utils.increment_dictionary(d, t[constants.TICKER])\n",
    "       \n",
    "\n",
    "    return dict_utils.sort_dictionary_by_values(d, reverse=True)\n",
    "\n",
    "d1 = num_of_tickers(house_input_df)\n",
    "d2 = num_of_tickers(senate_input_df)\n",
    "d3 = num_of_tickers(input_df)\n",
    "    \n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.TICKER)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_tickers\", (d1,d2,d3), [constants.TICKER, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Ticker per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_ticker_breakdown_year(group, diff):\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d = dict_utils.increment_dictionary_in_dictionary(d, t[constants.TICKER], ptr_utils.get_year(t[constants.TDATE]))\n",
    "            d = dict_utils.increment_dictionary_in_dictionary(d, t[constants.TICKER], \"Total\")\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_keys(d)\n",
    "    \n",
    "    filename = \"frequency_of_ticker_breakdown_year\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "    key_header = constants.TICKER\n",
    "    \n",
    "    \n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TICKER)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "\n",
    "frequency_of_ticker_breakdown_year(house_input_df, constants.HOUSE)\n",
    "frequency_of_ticker_breakdown_year(senate_input_df, constants.SENATE)\n",
    "frequency_of_ticker_breakdown_year(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Ticker per Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_ticker_by_date(group, diff):\n",
    "    # {ticker : {date : ___}}\n",
    "    d = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d = dict_utils.increment_dictionary_in_dictionary(d, t[constants.TICKER], t[constants.TDATE])\n",
    "\n",
    "    \n",
    "    d = dict_utils.flatten_best(d)\n",
    "    \n",
    "\n",
    "    filename = \"frequency_of_ticker_by_date\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "    \n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TICKER)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, constants.TICKER)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "\n",
    "d1 = frequency_of_ticker_by_date(house_input_df, constants.HOUSE)\n",
    "d2 = frequency_of_ticker_by_date(senate_input_df, constants.SENATE)\n",
    "d3 = frequency_of_ticker_by_date(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Industry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Transactions per Industry\n",
    "_Not controlled in any way._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_transactions_per_indusry(group):        \n",
    "    d = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            industry = dir_utils.search_mapping(industry_df, t[constants.TICKER], industry=True)\n",
    "            d = dict_utils.increment_dictionary(d, industry)\n",
    "\n",
    "    return dict_utils.sort_dictionary_by_values(d)\n",
    "    \n",
    "\n",
    "d1 = number_of_transactions_per_indusry(house_input_df)\n",
    "d2 = number_of_transactions_per_indusry(senate_input_df)\n",
    "d3 = number_of_transactions_per_indusry(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.INDUSTRY)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"number_of_transactions_per_indusry\", (d1,d2,d3), [constants.INDUSTRY, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Industry Breakdown per Official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_industry_breakdown_official(group, diff):\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            industry = dir_utils.search_mapping(industry_df, t[constants.TICKER], industry=True)\n",
    "            d = dict_utils.increment_dictionary_in_dictionary(d, official.get_name(t), industry)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_keys(d)\n",
    "    \n",
    "    filename = \"frequency_of_industry_breakdown_official\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.INDUSTRY)\n",
    "\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, constants.OFFICIAL)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "    \n",
    "    return d \n",
    "\n",
    "d1 = frequency_of_industry_breakdown_official(house_input_df, constants.HOUSE)\n",
    "d2 = frequency_of_industry_breakdown_official(senate_input_df, constants.SENATE)\n",
    "d3 = frequency_of_industry_breakdown_official(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency of Industry per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_industry_breakdown(group, diff):\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():     \n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            industry = dir_utils.search_mapping(industry_df, t[constants.TICKER], industry=True)  \n",
    "            d = dict_utils.increment_dictionary_in_dictionary(d, industry, ptr_utils.get_year(t[constants.TDATE]))\n",
    "            d = dict_utils.increment_dictionary_in_dictionary(d, industry, constants.TOTAL)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_keys(d)\n",
    "    \n",
    "    filename = \"frequency_of_industry_breakdown\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff \n",
    "    key_header = \"industry\"\n",
    "    \n",
    "    \n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.INDUSTRY)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "    return d \n",
    "\n",
    "d1 = frequency_of_industry_breakdown(house_input_df, constants.HOUSE)\n",
    "d2 = frequency_of_industry_breakdown(senate_input_df, constants.SENATE)\n",
    "d3 = frequency_of_industry_breakdown(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asset Description (asset_description) and Comment (comment) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_options(group):\n",
    "    count = total = 0 \n",
    "    d = {}\n",
    "    # [this_person_placed_an_option, ...]\n",
    "    people = set()\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if constants.ASSET_DESCRIPTION in t and ptr_utils.isvalid(t[constants.ASSET_DESCRIPTION]) and (\"Option\" in t[constants.ASSET_DESCRIPTION] or \"option\" in t[constants.ASSET_DESCRIPTION]): \n",
    "            count += 1 \n",
    "            people.add(official.get_name(t))\n",
    "        total += 1 \n",
    "\n",
    "    d[\"(No. of Options, %)\"] = (count, ptr_utils.make_percent(count, total))\n",
    "\n",
    "    return d \n",
    "            \n",
    "d1 = number_of_options(house_input_df)\n",
    "d2 = number_of_options(senate_input_df)\n",
    "d3 = number_of_options(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.COMMENT)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"number_of_options\", (d1,d2,d3), [\"\", constants.HOUSE, constants.SENATE, constants.INPUT])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Scanned PDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_scanned_pdfs(group):\n",
    "    count = total = 0 \n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if t[constants.ASSET_DESCRIPTION] == constants.DISCLOSED:\n",
    "            count += 1 \n",
    "        total += 1 \n",
    "            \n",
    "    d[\"(No. of Scanned PDFS, %)\"] = (count, ptr_utils.make_percent(count, total))\n",
    "\n",
    "    return d \n",
    "            \n",
    "d1 = number_of_scanned_pdfs(house_input_df)\n",
    "d2 = number_of_scanned_pdfs(senate_input_df)\n",
    "d3 = number_of_scanned_pdfs(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.COMMENT)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"number_of_scanned_pdfs\", (d1,d2,d3), [\"\", constants.HOUSE, constants.SENATE, constants.INPUT])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asset Type (asset_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Asset Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_asset_type(group):\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if constants.ATYPE in t and ptr_utils.isvalid(t[constants.ATYPE]):\n",
    "            d = dict_utils.increment_dictionary(d, t[constants.ATYPE])\n",
    "      \n",
    "    return dict_utils.sort_dictionary_by_values(d)\n",
    "\n",
    "d1 = frequency_of_asset_type(house_input_df)\n",
    "d2 = frequency_of_asset_type(senate_input_df)\n",
    "d3 = frequency_of_asset_type(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.ATYPE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"frequency_of_asset_type\", (d1,d2,d3), [constants.ATYPE, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amount "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Amount by Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_amount_by_persom(group, diff):\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        d = dict_utils.increment_dictionary_in_dictionary(d, official.get_name(t), t[constants.AMOUNT])\n",
    "    \n",
    "    d = dict_utils.sort_dictionary_by_keys(d)\n",
    "    \n",
    "    filename = \"frequency_of_amount_by_persom\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff \n",
    "        \n",
    "    key_header = constants.AMOUNT\n",
    "    \n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.AMOUNT)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "    \n",
    "    return d \n",
    "   \n",
    "    \n",
    "d1 = frequency_of_amount_by_persom(house_input_df, constants.HOUSE)\n",
    "d2 = frequency_of_amount_by_persom(senate_input_df, constants.SENATE)\n",
    "# d3 = frequency_of_amount_by_persom(input_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Transactions by Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_amount_total(group):\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        d = dict_utils.increment_dictionary(d, t[constants.AMOUNT])\n",
    "\n",
    "    # d = dict_utils.add_sort_key_for_amount(d, normal_header=\"num_of_transactions\", normal=True)\n",
    "    # d = dict_utils.sort_dictionary_by_sort_key(d)\n",
    "\n",
    "    return d \n",
    "    \n",
    "d1 = frequency_of_amount_total(house_input_df)\n",
    "d2 = frequency_of_amount_total(senate_input_df)\n",
    "d3 = frequency_of_amount_total(input_df)\n",
    "\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.AMOUNT)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"frequency_of_amount_total\", (d1,d2,d3), [constants.AMOUNT, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Amount by Gender "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_amount_by_gender(group, diff):\n",
    "    d = {}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        name = official.get_name(t)\n",
    "        link = input_all_officials_name[name]\n",
    "        d = dict_utils.increment_dictionary_in_dictionary(d, t[constants.AMOUNT], officials_gender[link])\n",
    "\n",
    "    d = dict_utils.add_sort_key_for_amount(d)\n",
    "    d = dict_utils.sort_dictionary_by_sort_key(d)\n",
    "    \n",
    "        \n",
    "    filename = \"frequency_of_amount_by_gender\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "    \n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.AMOUNT)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, constants.AMOUNT)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "    return d \n",
    "   \n",
    "    \n",
    "d1 = frequency_of_amount_by_gender(house_input_df, constants.HOUSE)\n",
    "d2 = frequency_of_amount_by_gender(senate_input_df, constants.SENATE)\n",
    "# d3 = frequency_of_amount_by_gender(input_df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Transactions by Political Affiliation and Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_amount_by_aff(group, diff):\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        obj = t_to_obj(t)\n",
    "        d = dict_utils.increment_dictionary_in_dictionary(d, t[constants.AMOUNT], obj.party)\n",
    "\n",
    "\n",
    "    d = dict_utils.add_sort_key_for_amount(d)\n",
    "    d = dict_utils.sort_dictionary_by_sort_key(d)\n",
    "    \n",
    "        \n",
    "    filename = \"frequency_of_amount_by_aff\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "    \n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.AMOUNT)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, constants.AMOUNT)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "    \n",
    "    return d \n",
    "   \n",
    "    \n",
    "d1 = frequency_of_amount_by_aff(house_input_df, constants.HOUSE)\n",
    "d2 = frequency_of_amount_by_aff(senate_input_df, constants.SENATE)\n",
    "# d3 = frequency_of_amount_by_aff(input_df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average For Buys and Sells per Official "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_per_person(group, diff):\n",
    "    d={}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.AMOUNT]) and (t[constants.TYPE] == constants.PURCHASE or t[constants.TYPE] == constants.SALE):\n",
    "                        \n",
    "            mean = ptr_utils.get_gmean(t[constants.AMOUNT])\n",
    "\n",
    "            # if t[constants.TYPE] == constants.PURCHASE: \n",
    "            #     mean = -mean \n",
    "\n",
    "            d = dict_utils.increment_list_in_dictionary(d, official.get_name(t), mean)\n",
    "\n",
    "\n",
    "    d = dict_utils.flatten_gmean(d)        \n",
    "            \n",
    "    filename = \"average_per_person\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "\n",
    "    key_header = constants.OFFICIAL \n",
    "    value_header = \"average_size_of_transactions\"\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_values(d)\n",
    "    d = dict_utils.commify(d)\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.AMOUNT)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "\n",
    "    return d \n",
    "\n",
    "d1 = average_per_person(house_input_df, constants.HOUSE)\n",
    "d2 = average_per_person(senate_input_df, constants.SENATE)\n",
    "d3 = average_per_person(input_df, constants.INPUT) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_activity(group, diff):\n",
    "    d={}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "                        \n",
    "            mean = ptr_utils.get_gmean(t[constants.AMOUNT])\n",
    "\n",
    "            d = dict_utils.increment_list_in_dictionary(d, official.get_name(t), mean)\n",
    "\n",
    "\n",
    "    d = dict_utils.flatten_gmean(d)        \n",
    "            \n",
    "    filename = \"average_activity\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "\n",
    "    key_header = constants.OFFICIAL \n",
    "    value_header = \"average_size_of_transactions\"\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_values(d)\n",
    "    d = dict_utils.commify(d)\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.AMOUNT)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "\n",
    "    return d \n",
    "\n",
    "d1 = average_activity(house_input_df, constants.HOUSE)\n",
    "d2 = average_activity(senate_input_df, constants.SENATE)\n",
    "d3 = average_activity(input_df, constants.INPUT) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types (type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Actions Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_act(group):\n",
    "    d = {}\n",
    "\n",
    "    for _,t in group.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TYPE]): \n",
    "            d = dict_utils.increment_dictionary(d, t[constants.TYPE])\n",
    "    \n",
    "    return dict_utils.sort_dictionary_by_values(d)\n",
    "    \n",
    "     \n",
    "d1 = frequency_of_act(house_input_df)\n",
    "d2 = frequency_of_act(senate_input_df)\n",
    "d3 = frequency_of_act(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.TYPE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"frequency_of_act\", (d1,d2,d3), [constants.TYPE, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Transactions per Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def types_of_transactions_per_person(group, diff):\n",
    "    d={}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        d = dict_utils.increment_dictionary_in_dictionary(d, official.get_name(t), t[constants.TYPE])\n",
    "        d = dict_utils.increment_dictionary_in_dictionary(d, official.get_name(t), constants.TOTAL)\n",
    "\n",
    "\n",
    "    filename = \"types_of_transactions_per_person\"\n",
    "    if diff:\n",
    "        filename += \"_\" + diff\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_keys(d)\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TYPE)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, constants.OFFICIAL)\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "\n",
    "    return d \n",
    "\n",
    "d1 = types_of_transactions_per_person(house_input_df, constants.HOUSE)\n",
    "d2 = types_of_transactions_per_person(senate_input_df, constants.SENATE)\n",
    "d3 = types_of_transactions_per_person(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_per_year(group, normalized):\n",
    "    d={}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        d =  dict_utils.increment_dictionary(d, ptr_utils.get_year(t[constants.TDATE]))\n",
    "\n",
    "    d2 = dict_utils.normalize(d, normalized, percent=True)\n",
    "        \n",
    "    return dict_utils.sort_dictionary_by_values(d), dict_utils.sort_dictionary_by_values(d2)\n",
    "\n",
    "d1, d4 = num_of_trans_per_year(house_input_df, len(input_house_officials_objects))\n",
    "d2, d5 = num_of_trans_per_year(senate_input_df, len(input_senate_officials_objects))\n",
    "d3, d6 = num_of_trans_per_year(input_df, len(input_officials_objects))\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.FREQ)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_per_year\", (d1,d2,d3), [constants.YEAR constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_per_year_normalized\", (d4,d5,d6), [constants.YEAR constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Person \n",
    "_Not controlling for number of years in position or size of transaction._ For each official, we want their total number of transactions.  {'Sam': 5, 'Alex': 2424, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_per_person(group):\n",
    "    d={}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        d = dict_utils.increment_dictionary(d, official.get_name(t))\n",
    "\n",
    "    return dict_utils.sort_dictionary_by_values(d)\n",
    "    \n",
    "d1 = num_of_trans_per_person(house_input_df)\n",
    "d2 = num_of_trans_per_person(senate_input_df)    \n",
    "d3 = num_of_trans_per_person(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_per_person\", (d1,d2,d3), [constants.OFFICIAL, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Person Controlled\n",
    "_Divide number of transactions by number of years in official position.  Not controlling for size of transaction._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_per_person_controlled(group):    \n",
    "    d={}\n",
    "    \n",
    "    for _,t in group.iterrows():\n",
    "        d = dict_utils.increment_dictionary(d, official.get_name(t))\n",
    "        \n",
    "    for k,v in d.items():\n",
    "        obj = t_to_obj(t)\n",
    "        d[k] = int(v/obj.get_seniority()) if int(v/obj.get_seniority()) != 0 else 1 \n",
    "\n",
    "    return dict_utils.sort_dictionary_by_values(d)\n",
    "\n",
    "\n",
    "d1 = num_of_trans_per_person_controlled(house_input_df)\n",
    "d2 = num_of_trans_per_person_controlled(senate_input_df)\n",
    "d3 = num_of_trans_per_person_controlled(input_df)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, constants.FREQ)\n",
    "\n",
    "csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_per_person_controlled\", (d1, d2, d3), [constants.OFFICIAL, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e534e48711db4d1e1c48977d0d14ff85b1f16d41bcc4fdfd88268a329b3c9d66"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
