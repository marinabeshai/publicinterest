{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.csv_utils as csv_utils \n",
    "import utils.dir_utils as dir_utils\n",
    "import utils.dict_utils as dict_utils \n",
    "import utils.ptr_utils as ptr_utils\n",
    "import utils.constants as constants \n",
    "import helpers.official_u as official\n",
    "import helpers.search_u as search\n",
    "import pandas as pd \n",
    "from scipy.stats.mstats import gmean\n",
    "\n",
    "title, input_df = dir_utils.get_data(senate=True)\n",
    "sector_df = dir_utils.get_mapping(sector=True)\n",
    "industry_df = dir_utils.get_mapping(industry=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transaction Date (transaction_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each sector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   sector transaction_date  number_of_transactions\n",
      "0      Financial Services       2020/04/14                      27\n",
      "1                    Fund       2020/04/02                      26\n",
      "2                     NaN       2015/02/13                      19\n",
      "3  Communication Services       2020/04/14                      18\n",
      "4              Technology       2020/04/14                      18\n"
     ]
    }
   ],
   "source": [
    "def transaction_date_wrt_sector():\n",
    "\n",
    "    # d_prime = {'sector' : {'date' : #_of_transactions, ....} , 'sector2' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in input_df.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            sector = dir_utils.search_mapping(sector_df, t[constants.TICKER], sector=True)\n",
    "            \n",
    "            d_prime = dict_utils.increment_dictionary_in_dictionary(d_prime, sector, ptr_utils.format_date(t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten(d_prime)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    filename = \"most_popular_td_fe_sector\"\n",
    "    key_header = constants.SECTOR\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "transaction_date_wrt_sector_res = transaction_date_wrt_sector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each sector controlling for each official."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_sector_controlled():\n",
    "\n",
    "    # d_prime = { ('ticker' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "    d_prime = {}\n",
    "\n",
    "    \n",
    "    for _,t in input_df.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            industry = dir_utils.search_mapping(sector_df, t[constants.TICKER], sector=True)\n",
    "            \n",
    "            d_prime = dict_utils.increment_set_in_dictionary(d_prime, industry, ptr_utils.format_date(t[constants.TDATE]), official.get_canonical_name(t[title]))\n",
    "       \n",
    "\n",
    "    for ticker in d_prime:\n",
    "        for date in d_prime[ticker]:\n",
    "            d_prime[ticker][date] = len(d_prime[ticker][date])\n",
    "            \n",
    "    \n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten(d_prime)\n",
    "\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "   \n",
    "    \n",
    "    filename = \"most_popular_td_fe_sector_controlled\"\n",
    "    key_header = constants.SECTOR\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "transaction_date_wrt_sector_controlled_res = transaction_date_wrt_sector_controlled()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_industry():\n",
    "    \n",
    "    # d_prime = {'industry' : {'date' : #_of_transactions, ....} , 'industry2' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in input_df.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            industry = dir_utils.search_mapping(industry_df, t[constants.TICKER])\n",
    "            \n",
    "            d_prime = dict_utils.increment_dictionary_in_dictionary(d_prime, industry, ptr_utils.format_date(t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten(d_prime)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    filename = \"most_popular_td_fe_industry\"\n",
    "    key_header = constants.INDUSTRY\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "transaction_date_wrt_industry_res = transaction_date_wrt_industry()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each industry controlling for official."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_industry_controlled():\n",
    "    \n",
    "    # d_prime = { ('ticker' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "    d_prime = {}\n",
    "\n",
    "    \n",
    "    for _,t in input_df.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            industry = dir_utils.search_mapping(industry_df, t[constants.TICKER])\n",
    "            \n",
    "            d_prime = dict_utils.increment_set_in_dictionary(d_prime, industry, ptr_utils.format_date(t[constants.TDATE]), official.get_canonical_name(t[title]))\n",
    "       \n",
    "\n",
    "    for ticker in d_prime:\n",
    "        for date in d_prime[ticker]:\n",
    "            d_prime[ticker][date] = len(d_prime[ticker][date])\n",
    "            \n",
    "    \n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten(d_prime)\n",
    "\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "    \n",
    "    \n",
    "    filename = \"most_popular_td_fe_industry_controlled\"\n",
    "    key_header = constants.INDUSTRY\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "transaction_date_wrt_industry_controlled_res = transaction_date_wrt_industry_controlled()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each ticker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_ticker():\n",
    "        \n",
    "    # d_prime = {'ticker' : {'date' : #_of_transactions, ....} , 'ticker2' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in input_df.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime = dict_utils.increment_dictionary_in_dictionary(d_prime, t[constants.TICKER], ptr_utils.format_date(t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten(d_prime)\n",
    "\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    filename = \"most_popular_td_fe_ticker\"\n",
    "    key_header = constants.TICKER\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "transaction_date_wrt_ticker_res = transaction_date_wrt_ticker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each ticker controlling for official."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_ticker_controlled():\n",
    "    # d_prime = { ('ticker' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "    d_prime = {}\n",
    "\n",
    "    \n",
    "    for _,t in input_df.iterrows():\n",
    "       d_prime = dict_utils.increment_set_in_dictionary(d_prime, t[constants.TICKER], ptr_utils.format_date(t[constants.TDATE]), official.get_canonical_name(t[title]))\n",
    "       \n",
    "\n",
    "    for ticker in d_prime:\n",
    "        for date in d_prime[ticker]:\n",
    "            d_prime[ticker][date] = len(d_prime[ticker][date])\n",
    "            \n",
    "    \n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten(d_prime)\n",
    "\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    \n",
    "    filename = \"most_popular_td_fe_ticker_controlled\"\n",
    "    key_header = constants.TICKER\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "transaction_date_wrt_ticker_controlled_res = transaction_date_wrt_ticker_controlled()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_type():\n",
    "        \n",
    "    # d_prime = {'type' : {'date' : #_of_transactions, ....} , 'type2' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in input_df.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime = dict_utils.increment_dictionary_in_dictionary(d_prime, t[constants.TYPE], ptr_utils.format_date(t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'type' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten(d_prime)\n",
    "\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    filename = \"most_popuar_td_for_type\"\n",
    "    key_header = constants.TYPE\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "transaction_date_wrt_type_res = transaction_date_wrt_type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for type controlling for official. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_type_controlled():\n",
    "    \n",
    "    # d_prime = { ('type' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "    d_prime = {}\n",
    "\n",
    "    \n",
    "    for _,t in input_df.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime = dict_utils.increment_set_in_dictionary(d_prime, t[constants.TYPE], ptr_utils.format_date(t[constants.TDATE]), official.get_canonical_name(t[title]))\n",
    "       \n",
    "\n",
    "    for ticker in d_prime:\n",
    "        for date in d_prime[ticker]:\n",
    "            d_prime[ticker][date] = len(d_prime[ticker][date])\n",
    "            \n",
    "    \n",
    "    # d = {'type' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten(d_prime)\n",
    "\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "    \n",
    "    \n",
    "    filename = \"most_popular_td_fe_type_controlled\"\n",
    "    key_header = constants.TYPE\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "transaction_date_wrt_type_controlled_res = transaction_date_wrt_type_controlled()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_amount():\n",
    "    # d_prime = {'amount' : {'date' : #_of_transactions, ....} , 'amount1' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in input_df.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime = dict_utils.increment_dictionary_in_dictionary(d_prime, t[constants.AMOUNT], ptr_utils.format_date(t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'type' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten(d_prime)\n",
    "\n",
    "    d = dict_utils.add_sort_key_for_amount(d)\n",
    "    d = dict_utils.sort_dictionary_by_sort_key(d)\n",
    "\n",
    "    filename = \"most_popuar_td_for_amount\"\n",
    "    key_header = constants.TYPE\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, key_header)\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "transaction_date_wrt_amount_res = transaction_date_wrt_amount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for amount controlling for official."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_amount_controlled():\n",
    "\n",
    "    # d_prime = { ('amount' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "    d_prime = {}\n",
    "\n",
    "    \n",
    "    for _,t in rows:\n",
    "       d_prime = dict_utils.increment_set_in_dictionary(d_prime, t[constants.AMOUNT], ptr_utils.format_date(t[constants.TDATE]), official.get_canonical_name(t[title]))\n",
    "       \n",
    "\n",
    "    for ticker in d_prime:\n",
    "        for date in d_prime[ticker]:\n",
    "            d_prime[ticker][date] = len(d_prime[ticker][date])\n",
    "            \n",
    "    \n",
    "    # d = {'amount' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten(d_prime)\n",
    "\n",
    "    d = dict_utils.add_sort_key_for_amount(d)\n",
    "    d = dict_utils.sort_dictionary_by_sort_key(d)\n",
    "    \n",
    "    \n",
    "    filename = \"most_popular_td_fe_amount_controlled\"\n",
    "    key_header = constants.AMOUNT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, key_header                                                                                                                                                                                                                                      )\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "transaction_date_wrt_amount_controlled_res = transaction_date_wrt_amount_controlled()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each official."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_official():\n",
    "\n",
    "    # d_prime = {'person1' : {'date' : #_of_transactions, ....} , 'person2' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in input_df.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime = dict_utils.increment_dictionary_in_dictionary(d_prime, official.get_canonical_name(t[title]), ptr_utils.format_date(t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'person' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten(d_prime)\n",
    "\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    filename = \"most_popular_td_fe_official\"\n",
    "    key_header = title\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "transaction_date_wrt_official_res = transaction_date_wrt_official()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The average amount size of transactions (i.e., activity) for each transaction_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dates_and_size_of_amount():\n",
    "\n",
    "    d={}\n",
    "    \n",
    "    for _, t in input_df.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "            \n",
    "            # if 'Purchase' in transaction['type']:\n",
    "                \n",
    "            # if 'Sale' in transaction['type']:\n",
    "            d = dict_utils.increment_dictionary_in_dictionary(d, ptr_utils.format_date(t[constants.TDATE]), ptr_utils.average_amount(t[constants.AMOUNT]))\n",
    "\n",
    "\n",
    "    d2 = {}\n",
    "    for date in d:\n",
    "        l = []\n",
    "        for amount in d[date]:   \n",
    "            l.append(d[date][amount]*amount)\n",
    "            \n",
    "        d2[date] = l \n",
    "        \n",
    "        \n",
    "    for date in d2:\n",
    "        d2[date] = int(gmean(d2[date]))\n",
    "    \n",
    "    filename = \"dates_and_size_of_amount\"\n",
    "    key_header = \"date\" \n",
    "    value_header = \"average_size_of_transactions\"\n",
    "\n",
    "    d2 = dict_utils.sort_dictionary_by_values(d2)\n",
    "    d2 = dict_utils.commify(d2)\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d2, [key_header, value_header])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "\n",
    "    return d2 \n",
    "\n",
    "dates_and_size_of_amount_res = dates_and_size_of_amount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Person by Date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_per_person_per_date():    \n",
    "\n",
    "    d={}\n",
    "\n",
    "    for _, t in input_df.iterrows():\n",
    "        d = dict_utils.increment_dictionary_in_dictionary(d, official.get_canonical_name(t[title]), ptr_utils.format_date(t[constants.TDATE]))\n",
    "\n",
    "    filename = \"num_of_trans_per_person_per_date\"\n",
    "    \n",
    "    \n",
    "    # some sort of error \n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, title)\n",
    "    print(pd.read_csv(wd).head(5))\n",
    "\n",
    "num_of_trans_per_person_per_date()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_per_person_per_date():\n",
    "\n",
    "    d={}\n",
    "\n",
    "    for _, t in input_df.iterrows():\n",
    "        d = dict_utils.increment_dictionary(d, ptr_utils.format_date(t[constants.TDATE]))\n",
    "        \n",
    "\n",
    "    filename = \"num_of_trans_per_person_per_date\"\n",
    "    key_header = \"date\"\n",
    "    value_header = \"number_of_transactions\"\n",
    "    \n",
    "    d = dict_utils.sort_dictionary_by_values(d)\n",
    "    \n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header])\n",
    "    # fig = graph_csv(dir, path_html, filename, key_header, value_header)\n",
    "    # fig.show()\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "trans_per_person_per_date_res = num_of_trans_per_person_per_date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Transactions per Date Controlled\n",
    "_Number of transactions per date controlled by official. E.g. if Ted Baker made 40 transactions on 1/1/02 and Sam Wall made 2 transactions on 1/1/02, we conclude that there were two transactions on 1/1/02._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_per_date_controlled():\n",
    "\n",
    "    d = {}\n",
    "\n",
    "    for _, t in input_df.iterrows():\n",
    "        d = dict_utils.increment_dictionary_in_dictionary(d, ptr_utils.format_date(t[constants.TDATE]), official.get_canonical_name(t[title]))\n",
    "    \n",
    "    d2 = {}\n",
    "    for date in d:\n",
    "        d2[date] =  len(d[date])\n",
    "        \n",
    "    d2 = dict_utils.sort_dictionary_by_values(d2)\n",
    "        \n",
    "    filename = \"num_of_trans_per_date_controlled\"\n",
    "    key_header = \"date\"\n",
    "    value_header = \"number_of_transactions_unique\"\n",
    "\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, \"transaction_date\")\n",
    "    wd = csv_utils.make_csv(dir, filename, d2, [key_header, value_header])\n",
    "    # fig = graph_csv(dir, path_html, filename, key_header, value_header, scatter=True)\n",
    "    # fig.show()\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "    \n",
    "num_of_trans_per_date_controlled_res = num_of_trans_per_date_controlled()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tax (not touched.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Transactions Within 2 Weeks Prior to Quarterly Tax Date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i should like type of transactions @TODO. \n",
    "\n",
    "def num_of_trans_within_tax_date(rows):\n",
    "        total = within = 0 \n",
    "        \n",
    "        for k,v in rows.items():  \n",
    "                total += 1 \n",
    "                if ptr_utils.within_tax_date(k):\n",
    "                        within += v \n",
    "\n",
    "        print(\"Percent of transactions posted within two weeks of quarterly tax deadline: {percent}%\".format(percent=str((within/total)*100)[:5]))\n",
    "        return (within/total)*100\n",
    "\n",
    "frac = num_of_trans_within_tax_date(trans_per_person_per_date_res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Transactions Within 2 Weeks Prior to Quarterly Tax Date Semi-Controlled \n",
    "\n",
    "_Given dict='09/03/2021': {'Thomas H Tuberville': 1, 'Cynthia M Lummis': 1, 'A. Mitchell Mcconnell, Jr.': 1}...I only incremement the number of within (tax date) once per date per official. So, if an official does 100 transactions on a date within two weeks of a quarterly deadline, then I only count it as one transaction._\n",
    "\n",
    "_A Note: total === number of transactions per person per date (so not really all transactions) because someone could have potentially made 60 transactions on one date which we don't include in neither total or within, if applicable._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_within_tax_date_controlled(rows):\n",
    "        total = within = 0 \n",
    "        people = set()\n",
    "\n",
    "        for date, inner_dict in rows.items():\n",
    "                if ptr_utils.within_tax_date(date):\n",
    "                    for person in inner_dict:\n",
    "                                people.add(person)\n",
    "                                within += 1 \n",
    "                                total += 1 \n",
    "                else:\n",
    "                        for person in inner_dict:\n",
    "                                total += 1 \n",
    "     \n",
    "     \n",
    "        print(\"Percent of transactions posted within two weeks of quarterly tax deadline: {percent}%\".format(percent=str((within/total)*100)[:5]))\n",
    "        return people\n",
    "\n",
    "num_of_trans_within_tax_date_controlled_res = num_of_trans_within_tax_date_controlled(num_of_trans_per_date_controlled_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import sort_dictionary_by_keys\n",
    "\n",
    "def people_and_within_tax_date(people):        \n",
    "        # todo get number of senators. \n",
    "        # todo is the monetary value of that equal!!!! \n",
    "        d = {}\n",
    "        for i in people:\n",
    "                d[i] = \"\"\n",
    "                \n",
    "        d = dict_utils.sort_dictionary_by_keys(d)\n",
    "        \n",
    "        dir = dir_utils.makesubdir(path_csv, \"transaction_date/tax\")\n",
    "        wd = csv_utils.make_csv(dir, \"people_and_within_tax_date_list\", d, [\"Officials\"])\n",
    "        df = pd.read_csv(wd)\n",
    "        print(\"People who posted transactions within two weeks of quarterly tax deadline:\\n {}\\n\".format(df.head(5)))\n",
    "\n",
    "        print(\"Number of people who posted transactions within two weeks of quarterly tax deadline: {}\\n\".format(len(people)))\n",
    "        \n",
    "        party = {}\n",
    "        for p in people:\n",
    "                party = dict_utils.increment_dictionary(party, search.wiki_search(p).get_party())\n",
    "                \n",
    "        party = dict_utils.sort_dictionary_by_values(party)\n",
    "        \n",
    "        wd = csv_utils.make_csv(dir, \"people_and_within_tax_date_list_w_aff\", party, [\"party\", \"number_of_filing_within_tax_date\"])\n",
    "        df = pd.read_csv(wd)\n",
    "        print(\"Party breakdown of people who posted transactions within two weeks of quarterly tax deadline:\\n {}\\n\".format(df.head(5)))\n",
    "\n",
    "people_and_within_tax_date(num_of_trans_within_tax_date_controlled_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def people_and_within_tax_date_how_often(people):\n",
    "\n",
    "        d = {}\n",
    "        d_controlled_by_dates = {}\n",
    "        \n",
    "        for _, t in input_df.iterrows():\n",
    "                if official.get_canonical_name(t[title]) in people and ptr_utils.within_tax_date(t[constants.TDATE]):\n",
    "                        d = dict_utils.increment_dictionary(d, t[title])\n",
    "                        d_controlled_by_dates = dict_utils.increment_dictionary_in_dictionary(d_controlled_by_dates, t[constants.TDATE], t[title])\n",
    "\n",
    "        d_controlled_by_dates_res  = {}\n",
    "        for date in d_controlled_by_dates:\n",
    "                for person in d_controlled_by_dates[date]:\n",
    "                        d_controlled_by_dates_res = dict_utils.increment_dictionary(d_controlled_by_dates_res, person)\n",
    "\n",
    "        d = dict_utils.sort_dictionary_by_values(d)\n",
    "        d_controlled_by_dates_res = dict_utils.sort_dictionary_by_values(d_controlled_by_dates_res)\n",
    "\n",
    "        dir = dir_utils.makesubdir(constants.path_csv, \"transaction_date/tax\")\n",
    "        wd = csv_utils.make_csv(dir, \"people_and_within_tax_date_how_often\", d, [title, \"number_of_filing_within_tax_date\"])\n",
    "        df = pd.read_csv(wd)\n",
    "        print(\"People who posted transactions within two weeks of quarterly tax deadline and the number of transactions posted:\\n {}\\n\".format(df.head(5)))\n",
    "\n",
    "        wd = csv_utils.make_csv(dir, \"people_and_within_tax_date_how_often_date_controlled\", d_controlled_by_dates_res, [title, \"number_of_filing_within_tax_date_date_controlled\"])\n",
    "        df = pd.read_csv(wd)\n",
    "        print(\"People who posted transactions within two weeks of quarterly tax deadline and the number of transactions posted controlled by date:\\n {}\\n\".format(df.head(5)))\n",
    "\n",
    "          \n",
    "people_and_within_tax_date_how_often(num_of_trans_within_tax_date_controlled_res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Owner (owner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ticker (ticker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Ticker per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_ticker_breakdown_ticker():\n",
    "    d = {}\n",
    "\n",
    "\n",
    "    for _, transaction in input_df.iterrows():\n",
    "        if isvalid(transaction['ticker']):\n",
    "            d = increment_dictionary_in_dictionary(d, transaction['ticker'], get_year(transaction['transaction_date']))\n",
    "            d = increment_dictionary_in_dictionary(d, transaction['ticker'], \"Total\")\n",
    "\n",
    "    d = sort_dictionary_by_keys(d)\n",
    "    \n",
    "    filename = \"trans_per_year_breakdown\"\n",
    "    key_header = \"ticker\"\n",
    "    \n",
    "    \n",
    "    dir = makesubdir(path_csv, \"ticker\")\n",
    "    wd = make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "\n",
    "frequency_of_ticker_breakdown_ticker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Ticker per Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_year, increment_dictionary_in_dictionary, path_csv\n",
    "from csv_utils import make_csv_breakdown\n",
    "\n",
    "def frequency_of_ticker_by_date():\n",
    "    d = {}\n",
    "\n",
    "    \n",
    "    for _, transaction in rows:\n",
    "        if isvalid(transaction['ticker']):\n",
    "            d = increment_dictionary_in_dictionary(d, transaction['ticker'], transaction['transaction_date'])\n",
    "\n",
    "    filename = \"frequency_of_ticker_by_date\"\n",
    "    key_header = \"ticker\"\n",
    "    \n",
    "    dir = makesubdir(path_csv, \"ticker\")\n",
    "    wd = make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "\n",
    "frequency_of_ticker_by_date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Industry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Transactions per Industry\n",
    "_Not controlled in any way._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_transactions_per_indusry():        \n",
    "    d = {}\n",
    "\n",
    "    df = get_mapping()\n",
    "    \n",
    "    for _, transaction in rows:\n",
    "        ticker = transaction['ticker']\n",
    "        industry = search_mapping(df, ticker)\n",
    "        if industry: \n",
    "            d = increment_dictionary(d, industry)\n",
    "\n",
    "    filename = \"number_of_transactions_per_indusry\"\n",
    "    key_header = \"industry\"\n",
    "    value_header = \"number_of_transactions\"\n",
    "\n",
    "    d = sort_dictionary_by_values(d)\n",
    "    \n",
    "    dir = makesubdir(path_csv, \"ticker/industry\")\n",
    "    wd = make_csv(dir, filename, d, [key_header, value_header])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))    \n",
    "    \n",
    "    return d \n",
    "\n",
    "number_of_transactions_per_indusry_res = number_of_transactions_per_indusry()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Industry Breakdown per Official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_industry_breakdown_official():\n",
    "    d = {}\n",
    "\n",
    "    df = get_mapping()\n",
    "\n",
    "    for _, transaction in rows:\n",
    "        industry = search_mapping(df, transaction['ticker'])\n",
    "        if industry: \n",
    "            d = increment_dictionary_in_dictionary(d, get_canonical_name(transaction[title]), industry)\n",
    "\n",
    "    d = sort_dictionary_by_keys(d)\n",
    "    \n",
    "    filename = \"frequency_of_industry_per_official\"\n",
    "    dir = makesubdir(path_csv, \"ticker/industry\")\n",
    "\n",
    "    wd = make_csv_breakdown(dir, filename, d, title)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "\n",
    "frequency_of_industry_breakdown_official()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency of Industry per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_industry_breakdown():\n",
    "    \n",
    "    d = {}\n",
    "    df = get_mapping()\n",
    "\n",
    "    for _, transaction in rows:\n",
    "        ticker = transaction['ticker']\n",
    "        \n",
    "        if isvalid(ticker):\n",
    "            industry = search_mapping(df, ticker)\n",
    "            if industry: \n",
    "                d = increment_dictionary_in_dictionary(d, industry, get_year(transaction['transaction_date']))\n",
    "\n",
    "    d = sort_dictionary_by_keys(d)\n",
    "    \n",
    "    filename = \"frequency_of_industry_breakdown\"\n",
    "    key_header = \"industry\"\n",
    "    \n",
    "    \n",
    "    dir = makesubdir(path_csv, \"ticker/industry\")\n",
    "    wd = make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "\n",
    "frequency_of_industry_breakdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asset Description (asset_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asset Type (asset_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Asset Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_asset_type():\n",
    "    d = {}\n",
    "\n",
    "\n",
    "    for _, transaction in rows:\n",
    "        if isvalid(transaction['asset_type']):\n",
    "            d = increment_dictionary(d, transaction['asset_type'])\n",
    "      \n",
    "    d = sort_dictionary_by_values(d)\n",
    "  \n",
    "    filename = \"frequency_of_asset_type\"\n",
    "    key_header = \"asset_type\"\n",
    "    value_header = \"number_of_transactions\"\n",
    "    \n",
    "    dir = makesubdir(path_csv, \"asset_type\")\n",
    "    wd = make_csv(dir, filename, d, [key_header, value_header])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "\n",
    "\n",
    "frequency_of_asset_type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Amount by Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_amount_by_persom():\n",
    "    d = {}\n",
    "\n",
    "\n",
    "    for _, transaction in rows:\n",
    "        d = increment_dictionary_in_dictionary(d, get_canonical_name(transaction[title]), transaction['amount'])\n",
    "\n",
    "    \n",
    "    d = sort_dictionary_by_keys(d)\n",
    "    \n",
    "    filename = \"frequency_of_amount_by_persom\"\n",
    "    key_header = \"amount\"\n",
    "    \n",
    "    dir = makesubdir(path_csv, \"amount\")\n",
    "    wd = make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "   \n",
    "    \n",
    "frequency_of_amount_by_persom()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Transactions by Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_amount_total():\n",
    "    d = {}\n",
    "\n",
    "\n",
    "    for _, transaction in rows:\n",
    "        d = increment_dictionary(d, transaction['amount'])\n",
    "\n",
    "    d = add_sort_key_for_amount(d, normal_header=\"num_of_transactions\", normal=True)\n",
    "    d = sort_dictionary_by_sort_key(d)\n",
    "\n",
    "    filename = \"frequency_of_amount_total\"\n",
    "    key_header = \"amount\"\n",
    "\n",
    "\n",
    "    dir = makesubdir(path_csv, \"amount\")\n",
    "    wd = make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "   \n",
    "    \n",
    "frequency_of_amount_total()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Amount by Gender "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_amount_by_gender():\n",
    "    d = {}\n",
    "\n",
    "\n",
    "    gender = {}\n",
    "    for _, transaction in rows:\n",
    "        person = transaction[title]\n",
    "        \n",
    "        if person not in gender: \n",
    "            rep = wiki_search(person) \n",
    "            gender.update({person : rep.get_gender()})\n",
    "            \n",
    "        d = increment_dictionary_in_dictionary(d, transaction['amount'], gender[person])\n",
    "        \n",
    "\n",
    "    d = add_sort_key_for_amount(d)\n",
    "    d = sort_dictionary_by_sort_key(d)\n",
    "    \n",
    "        \n",
    "    filename = \"frequency_of_amount_by_gender\"\n",
    "    key_header = \"amount\"\n",
    "    \n",
    "    \n",
    "    dir = makesubdir(path_csv, \"amount\")\n",
    "    wd = make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "   \n",
    "    \n",
    "frequency_of_amount_by_gender()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Transactions by Political Affiliation and Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def frequency_of_amount_by_aff():\n",
    "    d = {}\n",
    "\n",
    "\n",
    "    affiliations = {}\n",
    "    for _, transaction in rows:\n",
    "        person = transaction[title]\n",
    "        \n",
    "        if person not in affiliations: \n",
    "            rep = wiki_search(person) \n",
    "            affiliations.update({person : rep.party})\n",
    "            \n",
    "        d = increment_dictionary_in_dictionary(d, transaction['amount'], affiliations[person])\n",
    "\n",
    "\n",
    "    d = add_sort_key_for_amount(d)\n",
    "    d = sort_dictionary_by_sort_key(d)\n",
    "    \n",
    "        \n",
    "    filename = \"frequency_of_amount_by_aff\"\n",
    "    key_header = \"amount\"\n",
    "    \n",
    "    \n",
    "    dir = makesubdir(path_csv, \"amount\")\n",
    "    wd = make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "   \n",
    "    \n",
    "frequency_of_amount_by_aff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average For Buys and Sells per Official "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_per_person():\n",
    "\n",
    "    d={}\n",
    "    \n",
    "    for _, transaction in rows:\n",
    "        if isvalid(transaction['amount']):\n",
    "            \n",
    "            # if 'Purchase' in transaction['type']:\n",
    "                \n",
    "            # if 'Sale' in transaction['type']:\n",
    "            d = increment_dictionary_in_dictionary(d, get_canonical_name(transaction[title]), average_amount(transaction['amount']))\n",
    "\n",
    "\n",
    "    d2 = {}\n",
    "    for person in d:\n",
    "        l = []\n",
    "        for amount in d[person]:   \n",
    "            l.append(d[person][amount]*amount)\n",
    "            \n",
    "        d2[person] = l \n",
    "        \n",
    "        \n",
    "    for person in d2:\n",
    "        d2[person] = int(gmean(d2[person]))\n",
    "    \n",
    "    filename = \"average_per_person\"\n",
    "    key_header = title \n",
    "    value_header = \"average_size_of_transactions\"\n",
    "\n",
    "    d2 = sort_dictionary_by_values(d2)\n",
    "    d2 = commify(d2)\n",
    "\n",
    "    dir = makesubdir(path_csv, \"amount\")\n",
    "    wd = make_csv(dir, filename, d2, [key_header, value_header])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "\n",
    "    return d2 \n",
    "\n",
    "average_per_person_res = average_per_person()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types (type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Actions Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_act():\n",
    "    d = {}\n",
    "\n",
    "    for _, transaction in rows:\n",
    "        if isvalid(transaction['type']): \n",
    "            d = increment_dictionary(d, transaction['type'])\n",
    "    \n",
    "    d = sort_dictionary_by_values(d)\n",
    "    \n",
    "    filename = \"frequency_of_act\"\n",
    "    key_header = \"type\"\n",
    "    value_header = \"number_of_transactions\"\n",
    "    \n",
    "    dir = makesubdir(path_csv, \"type\")\n",
    "    wd = make_csv(dir, filename, d, [key_header, value_header])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "\n",
    "     \n",
    "frequency_of_act()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Transactions per Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import increment_dictionary_in_dictionary, sort_dictionary_by_keys, get_data, path_csv,makesubdir\n",
    "from csv_utils import make_csv_breakdown\n",
    "import pandas as pd \n",
    "from official import get_canonical_name\n",
    "\n",
    "\n",
    "def types_of_transactions_per_person():\n",
    "\n",
    "    d={}\n",
    "    \n",
    "    for _, transaction in rows:\n",
    "        d = increment_dictionary_in_dictionary(d, get_canonical_name(transaction[title]), transaction['type'])\n",
    "\n",
    "\n",
    "    filename = \"types_of_transactions_per_person\"\n",
    "\n",
    "    d = sort_dictionary_by_keys(d)\n",
    "\n",
    "    dir = makesubdir(path_csv, \"type\")\n",
    "    wd = make_csv_breakdown(dir, filename, d, title)\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "\n",
    "    return d \n",
    "\n",
    "types_of_transactions_per_person_res = types_of_transactions_per_person()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment (comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def num_of_trans_per_year():\n",
    "    d={}\n",
    "    \n",
    "    for _, transaction in rows:\n",
    "        d = increment_dictionary(d, get_year(transaction['transaction_date']))\n",
    "\n",
    "    filename = \"num_of_trans_per_year\"\n",
    "    key_header = \"year\"\n",
    "    value_header = \"number_of_transactions\"\n",
    "\n",
    "    d = sort_dictionary_by_values(d)\n",
    "    \n",
    "    dir = makesubdir(path_csv, \"frequency\")\n",
    "    wd = make_csv(dir, filename, d, [key_header, value_header])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "\n",
    "    return d \n",
    "\n",
    "num_of_trans_per_year_res = num_of_trans_per_year()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Person \n",
    "_Not controlling for number of years in position or size of transaction._ For each official, we want their total number of transactions.  {'Sam': 5, 'Alex': 2424, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def num_of_trans_per_person():\n",
    "\n",
    "    d={}\n",
    "    \n",
    "    for _, transaction in rows:\n",
    "        d = increment_dictionary(d, get_canonical_name(transaction[title]))\n",
    "\n",
    "    filename = \"num_of_trans_per_person\"\n",
    "    key_header = title\n",
    "    value_header = \"number_of_transactions\"\n",
    "\n",
    "    d = sort_dictionary_by_values(d)\n",
    "    \n",
    "    dir = makesubdir(path_csv, \"frequency\")\n",
    "    wd = make_csv(dir, filename, d, [key_header, value_header])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "\n",
    "    return d \n",
    "\n",
    "trans_per_person_res = num_of_trans_per_person()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Person Controlled\n",
    "_Divide number of transactions by number of years in official position.  Not controlling for size of transaction._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_per_person_controlled(rows):    \n",
    "\n",
    "    d={}\n",
    "\n",
    "    for person, num_of_trans in rows.items():\n",
    "        official = wiki_search(person)    \n",
    "        years_in_office = official.get_num_of_years()\n",
    "        d[person] = math.ceil(num_of_trans/years_in_office) \n",
    "\n",
    "    filename = \"num_of_trans_per_person_controlled\"\n",
    "    value_header = \"avg_number_of_transactions\"\n",
    "\n",
    "    d = sort_dictionary_by_values(d)\n",
    "   \n",
    "    dir = makesubdir(path_csv, \"frequency\")\n",
    "    wd = make_csv(dir, filename, d, [title, value_header])\n",
    "    print(pd.read_csv(wd).head(5))\n",
    "    \n",
    "    return d \n",
    "\n",
    "num_of_trans_per_person_controlled_res = num_of_trans_per_person_controlled(trans_per_person_res)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Person Controlled w/Number of Years in Congress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_per_person_controlled_w_seniority(rows):    \n",
    "\n",
    "    d={}\n",
    "\n",
    "    for person, num_of_trans in rows.items():\n",
    "        official = wiki_search(person)    \n",
    "        years_in_office = official.get_num_of_years()\n",
    "        d[person] = math.ceil(num_of_trans/years_in_office), official.get_num_of_years()\n",
    "\n",
    "    filename = \"num_of_trans_per_person_controlled_w_seniority\"\n",
    "    value_header = \"avg_number_of_transactions\"\n",
    "\n",
    "    d = sort_dictionary_by_values(d)\n",
    "   \n",
    "    dir = makesubdir(path_csv, \"frequency\")\n",
    "    wd = make_csv(dir, filename, d, [title, value_header, \"seniority\"])\n",
    "    print(pd.read_csv(wd).head(5))\n",
    "    \n",
    "    return d \n",
    "\n",
    "num_of_trans_per_person_controlled_w_seniority_res = num_of_trans_per_person_controlled_w_seniority(trans_per_person_res)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Person Controlled w/Degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_per_person_controlled_w_degrees(rows):    \n",
    "\n",
    "\n",
    "    d={}\n",
    "\n",
    "    for person, num_of_trans in rows.items():\n",
    "        official = wiki_search(person)    \n",
    "        years_in_office = official.get_num_of_years()\n",
    "        d[person] = math.ceil(num_of_trans/years_in_office), official.get_num_of_degrees()\n",
    "\n",
    "    filename = \"num_of_trans_per_person_controlled_w_degrees\"\n",
    "    value_header = \"avg_number_of_transactions\"\n",
    "\n",
    "    d = sort_dictionary_by_values(d)\n",
    "   \n",
    "    dir = makesubdir(path_csv, \"frequency\")\n",
    "    wd = make_csv(dir, filename, d, [title, value_header, \"num_of_degrees\"])\n",
    "    print(pd.read_csv(wd).head(5))\n",
    "    \n",
    "    return d \n",
    "\n",
    "num_of_trans_per_person_controlled_w_degrees_res = num_of_trans_per_person_controlled_w_degrees(trans_per_person_res)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Person Controlled w/Affiliation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def num_of_trans_per_person_controlled_w_aff(rows):\n",
    "\n",
    "    d={}\n",
    "    \n",
    "    for person, val in rows.items():\n",
    "        official = wiki_search(person)     \n",
    "        d[person] = val, official.get_party()\n",
    "\n",
    "    filename = \"num_of_trans_per_person_controlled_w_aff\"\n",
    "    value_header = \"avg_number_of_transactions\"\n",
    "\n",
    "    d = sort_dictionary_by_values(d)\n",
    "        \n",
    "    dir = makesubdir(path_csv, \"frequency\")\n",
    "    wd = make_csv(dir, filename, d, [title, value_header, \"party\"])\n",
    "    print(pd.read_csv(wd).head(5))\n",
    "    \n",
    "    return d, pd.read_csv(wd).head(10)\n",
    "\n",
    "num_of_trans_per_person_controlled_w_aff_res, top_10 = num_of_trans_per_person_controlled_w_aff(num_of_trans_per_person_controlled_res)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transaction Date (transaction_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency of Differences between Transaction and Disclosure Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_differences():\n",
    "    d = {}\n",
    "    match = {}\n",
    "    total = num = 0 \n",
    "\n",
    "    for _, transaction in rows:\n",
    "        transaction_date = transaction['transaction_date']\n",
    "        disclosure_date = transaction['disclosure_date']\n",
    "\n",
    "        # Negative, X days BEFORE\n",
    "        # Positive, Y dayas AFTER\n",
    "        diff = difference_between_dates(disclosure_date, transaction_date)      \n",
    "        total += 1 \n",
    "        num += diff   \n",
    "        \n",
    "        # match = {5 days: {'Tom' : 1313, 'X': 3 , ...}. ..}\n",
    "        match = increment_dictionary_in_dictionary(match, diff, transaction[title])\n",
    "            \n",
    "            \n",
    "        d = increment_dictionary(d, int(diff))\n",
    "    \n",
    "    d = sort_dictionary_by_keys(d)\n",
    "        \n",
    "    filename = \"frequency_of_differences\"\n",
    "    key_header = \"difference_in_days\"\n",
    "    value_header = \"#_of_transactions_with_that_diff\"\n",
    "    \n",
    "    \n",
    "    dir = makesubdir(path_csv, \"disclosure_date/transaction_date\")\n",
    "    make_csv(dir, filename, d, [key_header, value_header])\n",
    "    # fig = graph_csv(dir, path_html, filename, key_header, value_header)\n",
    "    # fig.show()\n",
    "    \n",
    "    print(\"Average difference in days: {}\".format(num//total))\n",
    "\n",
    "frequency_of_differences()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e534e48711db4d1e1c48977d0d14ff85b1f16d41bcc4fdfd88268a329b3c9d66"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
