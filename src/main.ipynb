{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.csv_utils_u as csv_utils \n",
    "import utils.dir_utils_u as dir_utils\n",
    "import utils.dict_utils_u as dict_utils \n",
    "import utils.ptr_utils_u as ptr_utils\n",
    "import utils.constants_u as constants \n",
    "import helpers.official_u as official\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transaction Date (transaction_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each ticker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ticker transaction_date  number_of_transactions\n",
      "0   ECOM       2021/02/10                       8\n",
      "1      X       2021/05/06                       6\n",
      "2    OXY       2021/02/16                       6\n",
      "3    CLF       2021/07/21                       5\n",
      "4     AA       2021/01/06                       5\n"
     ]
    }
   ],
   "source": [
    "def transaction_date_wrt_ticker():\n",
    "    \n",
    "    _, rows = dir_utils.get_data()\n",
    "    \n",
    "    # d_prime = {'ticker' : {'date' : #_of_transactions, ....} , 'ticker2' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in rows:\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime = dict_utils.increment_dictionary_in_dictionary(d_prime, t[constants.TICKER], ptr_utils.format_date(t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten(d_prime)\n",
    "\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d)\n",
    "    d = dict_utils.reversedict(d)\n",
    "\n",
    "    filename = \"most_popular_td_fe_ticker\"\n",
    "    key_header = constants.TICKER\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "transaction_date_wrt_ticker_res = transaction_date_wrt_ticker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each ticker controlling for official."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ticker transaction_date  number_of_transactions\n",
      "0   BSTZ       2019/06/26                       2\n",
      "1   ALLE       2021/09/30                       1\n",
      "2    BKE       2021/09/30                       1\n",
      "3   CABO       2021/09/30                       1\n",
      "4   CTAS       2021/09/30                       1\n"
     ]
    }
   ],
   "source": [
    "def transaction_date_wrt_ticker_controlled():\n",
    "    \n",
    "    title, rows = dir_utils.get_data()\n",
    "    \n",
    "    # d_prime = { ('ticker' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "    d_prime = {}\n",
    "\n",
    "    \n",
    "    for _,t in rows:\n",
    "       d_prime = dict_utils.increment_set_in_dictionary(d_prime, t[constants.TICKER], ptr_utils.format_date(t[constants.TDATE]), official.get_canonical_name(t[title]))\n",
    "       \n",
    "\n",
    "    for ticker in d_prime:\n",
    "        for date in d_prime[ticker]:\n",
    "            d_prime[ticker][date] = len(d_prime[ticker][date])\n",
    "            \n",
    "    \n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten(d_prime)\n",
    "\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d)\n",
    "    d = dict_utils.reversedict(d)\n",
    "    \n",
    "    \n",
    "    filename = \"most_popular_td_fe_ticker_controlled\"\n",
    "    key_header = constants.TICKER\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "transaction_date_wrt_ticker_controlled_res = transaction_date_wrt_ticker_controlled()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             type transaction_date  number_of_transactions\n",
      "0     Sale (Full)       2020/04/14                     116\n",
      "1        Purchase       2017/03/16                      78\n",
      "2  Sale (Partial)       2020/04/14                      26\n",
      "3        Exchange       2017/09/01                       5\n"
     ]
    }
   ],
   "source": [
    "def transaction_date_wrt_type():\n",
    "    \n",
    "    _, rows = dir_utils.get_data()\n",
    "    \n",
    "    # d_prime = {'type' : {'date' : #_of_transactions, ....} , 'type2' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in rows:\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime = dict_utils.increment_dictionary_in_dictionary(d_prime, t[constants.TYPE], ptr_utils.format_date(t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'type' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten(d_prime)\n",
    "\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d)\n",
    "    d = dict_utils.reversedict(d)\n",
    "\n",
    "    filename = \"most_popuar_td_for_type\"\n",
    "    key_header = constants.TYPE\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "transaction_date_wrt_type_res = transaction_date_wrt_type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ['type']  2015/02/13  2015/02/20  2020/03/11  2020/04/07  \\\n",
      "0     $1,001 - $15,000        96.0         NaN         NaN         NaN   \n",
      "1    $15,001 - $50,000         NaN         NaN         NaN         NaN   \n",
      "2   $50,001 - $100,000         NaN         NaN         NaN         NaN   \n",
      "3  $100,001 - $250,000         NaN         NaN         NaN        43.0   \n",
      "4  $250,001 - $500,000         NaN         NaN         NaN         8.0   \n",
      "\n",
      "   2020/04/14  2020/04/15  2020/05/20  sort_key  \n",
      "0         NaN         NaN         NaN     15000  \n",
      "1        69.0         NaN         NaN     50000  \n",
      "2        23.0         NaN         NaN    100000  \n",
      "3         NaN         NaN         NaN    250000  \n",
      "4         NaN         NaN         NaN    500000  \n"
     ]
    }
   ],
   "source": [
    "def transaction_date_wrt_amount():\n",
    "    \n",
    "    _, rows = dir_utils.get_data()\n",
    "    \n",
    "    # d_prime = {'amount' : {'date' : #_of_transactions, ....} , 'amount1' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in rows:\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime = dict_utils.increment_dictionary_in_dictionary(d_prime, t[constants.AMOUNT], ptr_utils.format_date(t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'type' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten(d_prime)\n",
    "\n",
    "    d = dict_utils.add_sort_key_for_amount(d)\n",
    "    d = dict_utils.sort_dictionary_by_sort_key(d)\n",
    "\n",
    "    filename = \"most_popuar_td_for_amount\"\n",
    "    key_header = constants.TYPE\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, [key_header])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "transaction_date_wrt_amount_res = transaction_date_wrt_amount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import increment_dictionary_in_dictionary, sort_dictionary_by_values, path_csv, get_data, get_year, average_amount, isvalid, increment_dictionary, makesubdir, commify\n",
    "from csv_utils import make_csv\n",
    "import pandas as pd \n",
    "from scipy.stats.mstats import gmean\n",
    "from official import get_canonical_name\n",
    "\n",
    "def dates_and_size_of_amount():\n",
    "    _, rows = get_data()\n",
    "    d={}\n",
    "    \n",
    "    for _, transaction in rows:\n",
    "        if isvalid(transaction['amount']):\n",
    "            \n",
    "            # if 'Purchase' in transaction['type']:\n",
    "                \n",
    "            # if 'Sale' in transaction['type']:\n",
    "            d = increment_dictionary_in_dictionary(d, transaction['transaction_date'], average_amount(transaction['amount']))\n",
    "\n",
    "\n",
    "    d2 = {}\n",
    "    for date in d:\n",
    "        l = []\n",
    "        for amount in d[date]:   \n",
    "            l.append(d[date][amount]*amount)\n",
    "            \n",
    "        d2[date] = l \n",
    "        \n",
    "        \n",
    "    for date in d2:\n",
    "        d2[date] = int(gmean(d2[date]))\n",
    "    \n",
    "    filename = \"dates_and_size_of_amount\"\n",
    "    key_header = \"date\" \n",
    "    value_header = \"average_size_of_transactions\"\n",
    "\n",
    "    d2 = sort_dictionary_by_values(d2)\n",
    "    d2 = commify(d2)\n",
    "\n",
    "    dir = makesubdir(path_csv, \"transaction_date\")\n",
    "    wd = make_csv(dir, filename, d2, [key_header, value_header])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "\n",
    "    return d2 \n",
    "\n",
    "dates_and_size_of_amount_res = dates_and_size_of_amount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Person by Date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import increment_dictionary_in_dictionary, path_csv\n",
    "from csv_utils import make_csv_breakdown\n",
    "\n",
    "def num_of_trans_per_person_per_date():    \n",
    "    title, rows = get_data()\n",
    "    d={}\n",
    "\n",
    "    for _, transaction in rows:\n",
    "        date = transaction['transaction_date']\n",
    "        d = increment_dictionary_in_dictionary(d, get_canonical_name(transaction[title]), date)\n",
    "\n",
    "    filename = \"num_of_trans_per_person_per_date\"\n",
    "    \n",
    "    \n",
    "    # some sort of error \n",
    "    dir = makesubdir(path_csv, \"transaction_date\")\n",
    "    wd = make_csv_breakdown(dir, filename, d, title)\n",
    "    print(pd.read_csv(wd).head(5))\n",
    "\n",
    "num_of_trans_per_person_per_date()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_utils import graph_csv \n",
    "from csv_utils import make_csv\n",
    "from utils import path_html, increment_dictionary, path_csv, reversedict\n",
    "import plotly.express as px\n",
    "\n",
    "def num_of_trans_per_person_per_date():\n",
    "    _, rows = get_data()\n",
    "    d={}\n",
    "\n",
    "    for _, transaction in rows:\n",
    "        date = transaction['transaction_date']\n",
    "        d = increment_dictionary(d, date)\n",
    "\n",
    "    filename = \"num_of_trans_per_person_per_date\"\n",
    "    key_header = \"date\"\n",
    "    value_header = \"number_of_transactions\"\n",
    "    \n",
    "    d = reversedict(d)\n",
    "    \n",
    "    dir = makesubdir(path_csv, \"transaction_date\")\n",
    "    make_csv(dir, filename, d, [key_header, value_header])\n",
    "    # fig = graph_csv(dir, path_html, filename, key_header, value_header)\n",
    "    # fig.show()\n",
    "    return d \n",
    "\n",
    "trans_per_person_per_date_res = num_of_trans_per_person_per_date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Transactions per Date Controlled\n",
    "_Number of transactions per date controlled by official. E.g. if Ted Baker made 40 transactions on 1/1/02 and Sam Wall made 2 transactions on 1/1/02, we conclude that there were two transactions on 1/1/02._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import increment_dictionary_in_dictionary, path_csv, path_html, reversedict, get_data\n",
    "from csv_utils import make_csv\n",
    "from graph_utils import graph_csv\n",
    "\n",
    "def num_of_trans_per_date_controlled():\n",
    "    title, rows = get_data()\n",
    "    d = {}\n",
    "\n",
    "    for _, transaction in rows:\n",
    "        date = transaction['transaction_date']\n",
    "        d = increment_dictionary_in_dictionary(d, date, get_canonical_name(transaction[title]))\n",
    "    \n",
    "    d2 = {}\n",
    "    for date in d:\n",
    "        d2[date] =  len(d[date])\n",
    "        \n",
    "    d2 = reversedict(d2)\n",
    "        \n",
    "    filename = \"num_of_trans_per_date_controlled\"\n",
    "    key_header = \"date\"\n",
    "    value_header = \"number_of_transactions_unique\"\n",
    "\n",
    "\n",
    "    dir = makesubdir(path_csv, \"transaction_date\")\n",
    "    make_csv(dir, filename, d2, [key_header, value_header])\n",
    "    # fig = graph_csv(dir, path_html, filename, key_header, value_header, scatter=True)\n",
    "    # fig.show()\n",
    "    return d \n",
    "    \n",
    "num_of_trans_per_date_controlled_res = num_of_trans_per_date_controlled()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Transactions Within 2 Weeks Prior to Quarterly Tax Date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import within_tax_date, increment_dictionary\n",
    "from search import wiki_search\n",
    "\n",
    "# i should like type of transactions @TODO. \n",
    "\n",
    "def num_of_trans_within_tax_date(rows):\n",
    "        total = within = 0 \n",
    "        \n",
    "        for k,v in rows.items():  \n",
    "                total += 1 \n",
    "                if within_tax_date(k):\n",
    "                        within += v \n",
    "\n",
    "        print(\"Percent of transactions posted within two weeks of quarterly tax deadline: {percent}%\".format(percent=str((within/total)*100)[:5]))\n",
    "        return (within/total)*100\n",
    "\n",
    "frac = num_of_trans_within_tax_date(trans_per_person_per_date_res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Transactions Within 2 Weeks Prior to Quarterly Tax Date Semi-Controlled \n",
    "\n",
    "_Given dict='09/03/2021': {'Thomas H Tuberville': 1, 'Cynthia M Lummis': 1, 'A. Mitchell Mcconnell, Jr.': 1}...I only incremement the number of within (tax date) once per date per official. So, if an official does 100 transactions on a date within two weeks of a quarterly deadline, then I only count it as one transaction._\n",
    "\n",
    "_A Note: total === number of transactions per person per date (so not really all transactions) because someone could have potentially made 60 transactions on one date which we don't include in neither total or within, if applicable._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_within_tax_date_controlled(rows):\n",
    "        total = within = 0 \n",
    "        people = set()\n",
    "\n",
    "        for date, inner_dict in rows.items():\n",
    "                if within_tax_date(date):\n",
    "                    for person in inner_dict:\n",
    "                                people.add(person)\n",
    "                                within += 1 \n",
    "                                total += 1 \n",
    "                else:\n",
    "                        for person in inner_dict:\n",
    "                                total += 1 \n",
    "     \n",
    "     \n",
    "        print(\"Percent of transactions posted within two weeks of quarterly tax deadline: {percent}%\".format(percent=str((within/total)*100)[:5]))\n",
    "        return people\n",
    "\n",
    "num_of_trans_within_tax_date_controlled_res = num_of_trans_within_tax_date_controlled(num_of_trans_per_date_controlled_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import sort_dictionary_by_keys\n",
    "\n",
    "def people_and_within_tax_date(people):        \n",
    "        # todo get number of senators. \n",
    "        # todo is the monetary value of that equal!!!! \n",
    "        d = {}\n",
    "        for i in people:\n",
    "                d[i] = \"\"\n",
    "                \n",
    "        d = sort_dictionary_by_keys(d)\n",
    "        \n",
    "        dir = makesubdir(path_csv, \"transaction_date/tax\")\n",
    "        wd = make_csv(dir, \"people_and_within_tax_date_list\", d, [\"Officials\"])\n",
    "        df = pd.read_csv(wd)\n",
    "        print(\"People who posted transactions within two weeks of quarterly tax deadline:\\n {}\\n\".format(df.head(5)))\n",
    "\n",
    "        print(\"Number of people who posted transactions within two weeks of quarterly tax deadline: {}\\n\".format(len(people)))\n",
    "        \n",
    "        party = {}\n",
    "        for p in people:\n",
    "                party = increment_dictionary(party, wiki_search(p).get_party())\n",
    "                \n",
    "        party = sort_dictionary_by_values(party)\n",
    "        \n",
    "        wd = make_csv(dir, \"people_and_within_tax_date_list_w_aff\", party, [\"party\", \"number_of_filing_within_tax_date\"])\n",
    "        df = pd.read_csv(wd)\n",
    "        print(\"Party breakdown of people who posted transactions within two weeks of quarterly tax deadline:\\n {}\\n\".format(df.head(5)))\n",
    "\n",
    "people_and_within_tax_date(num_of_trans_within_tax_date_controlled_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def people_and_within_tax_date_how_often(people):\n",
    "        title, rows = get_data()\n",
    "        d = {}\n",
    "        d_controlled_by_dates = {}\n",
    "        \n",
    "        for _, transaction in rows:\n",
    "                if get_canonical_name(transaction[title]) in people and within_tax_date(transaction['transaction_date']):\n",
    "                        d = increment_dictionary(d, transaction[title])\n",
    "                        d_controlled_by_dates = increment_dictionary_in_dictionary(d_controlled_by_dates, transaction['transaction_date'], transaction[title])\n",
    "\n",
    "        d_controlled_by_dates_res  = {}\n",
    "        for date in d_controlled_by_dates:\n",
    "                for person in d_controlled_by_dates[date]:\n",
    "                        d_controlled_by_dates_res = increment_dictionary(d_controlled_by_dates_res, person)\n",
    "\n",
    "        d = sort_dictionary_by_values(d)\n",
    "        d_controlled_by_dates_res = sort_dictionary_by_values(d_controlled_by_dates_res)\n",
    "\n",
    "        dir = makesubdir(path_csv, \"transaction_date/tax\")\n",
    "        wd = make_csv(dir, \"people_and_within_tax_date_how_often\", d, [title, \"number_of_filing_within_tax_date\"])\n",
    "        df = pd.read_csv(wd)\n",
    "        print(\"People who posted transactions within two weeks of quarterly tax deadline and the number of transactions posted:\\n {}\\n\".format(df.head(5)))\n",
    "\n",
    "        wd = make_csv(dir, \"people_and_within_tax_date_how_often_date_controlled\", d_controlled_by_dates_res, [title, \"number_of_filing_within_tax_date_date_controlled\"])\n",
    "        df = pd.read_csv(wd)\n",
    "        print(\"People who posted transactions within two weeks of quarterly tax deadline and the number of transactions posted controlled by date:\\n {}\\n\".format(df.head(5)))\n",
    "\n",
    "          \n",
    "people_and_within_tax_date_how_often(num_of_trans_within_tax_date_controlled_res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Owner (owner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ticker (ticker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Ticker per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import isvalid, get_data, sort_dictionary_by_keys, get_year, increment_dictionary_in_dictionary, path_csv\n",
    "from csv_utils import make_csv_breakdown\n",
    "import pandas as pd \n",
    "\n",
    "def frequency_of_ticker_breakdown_ticker():\n",
    "    d = {}\n",
    "    _, rows = get_data()\n",
    "\n",
    "    for _, transaction in rows:\n",
    "        if isvalid(transaction['ticker']):\n",
    "            d = increment_dictionary_in_dictionary(d, transaction['ticker'], get_year(transaction['transaction_date']))\n",
    "            d = increment_dictionary_in_dictionary(d, transaction['ticker'], \"Total\")\n",
    "\n",
    "    d = sort_dictionary_by_keys(d)\n",
    "    \n",
    "    filename = \"trans_per_year_breakdown\"\n",
    "    key_header = \"ticker\"\n",
    "    \n",
    "    \n",
    "    dir = makesubdir(path_csv, \"ticker\")\n",
    "    wd = make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "\n",
    "frequency_of_ticker_breakdown_ticker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Ticker per Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_year, increment_dictionary_in_dictionary, path_csv\n",
    "from csv_utils import make_csv_breakdown\n",
    "\n",
    "def frequency_of_ticker_by_date():\n",
    "    d = {}\n",
    "    _, rows = get_data()\n",
    "    \n",
    "    for _, transaction in rows:\n",
    "        if isvalid(transaction['ticker']):\n",
    "            d = increment_dictionary_in_dictionary(d, transaction['ticker'], transaction['transaction_date'])\n",
    "\n",
    "    filename = \"frequency_of_ticker_by_date\"\n",
    "    key_header = \"ticker\"\n",
    "    \n",
    "    dir = makesubdir(path_csv, \"ticker\")\n",
    "    wd = make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "\n",
    "frequency_of_ticker_by_date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Industry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Transactions per Industry\n",
    "_Not controlled in any way._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import increment_dictionary, sort_dictionary_by_values, path_csv, get_data, isvalid, get_mapping, search_mapping\n",
    "from csv_utils import make_csv\n",
    "import pandas as pd \n",
    "\n",
    "def number_of_transactions_per_indusry():        \n",
    "    d = {}\n",
    "    _, rows = get_data()\n",
    "    df = get_mapping()\n",
    "    \n",
    "    for _, transaction in rows:\n",
    "        ticker = transaction['ticker']\n",
    "        industry = search_mapping(df, ticker)\n",
    "        if industry: \n",
    "            d = increment_dictionary(d, industry)\n",
    "\n",
    "    filename = \"number_of_transactions_per_indusry\"\n",
    "    key_header = \"industry\"\n",
    "    value_header = \"number_of_transactions\"\n",
    "\n",
    "    d = sort_dictionary_by_values(d)\n",
    "    \n",
    "    dir = makesubdir(path_csv, \"ticker/industry\")\n",
    "    wd = make_csv(dir, filename, d, [key_header, value_header])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))    \n",
    "    \n",
    "    return d \n",
    "\n",
    "number_of_transactions_per_indusry_res = number_of_transactions_per_indusry()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Industry Breakdown per Official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_year, increment_dictionary_in_dictionary, path_csv, get_mapping, search_mapping, makesubdir\n",
    "from csv_utils import make_csv_breakdown\n",
    "\n",
    "def frequency_of_industry_breakdown_official():\n",
    "    d = {}\n",
    "    title, rows = get_data()\n",
    "    df = get_mapping()\n",
    "\n",
    "    for _, transaction in rows:\n",
    "        industry = search_mapping(df, transaction['ticker'])\n",
    "        if industry: \n",
    "            d = increment_dictionary_in_dictionary(d, get_canonical_name(transaction[title]), industry)\n",
    "\n",
    "    d = sort_dictionary_by_keys(d)\n",
    "    \n",
    "    filename = \"frequency_of_industry_per_official\"\n",
    "    dir = makesubdir(path_csv, \"ticker/industry\")\n",
    "\n",
    "    wd = make_csv_breakdown(dir, filename, d, title)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "\n",
    "frequency_of_industry_breakdown_official()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency of Industry per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import isvalid, get_data, sort_dictionary_by_keys, get_year, increment_dictionary_in_dictionary, path_csv, get_mapping, search_mapping\n",
    "from csv_utils import make_csv_breakdown\n",
    "import pandas as pd \n",
    "\n",
    "def frequency_of_industry_breakdown():\n",
    "    d = {}\n",
    "    _, rows = get_data()\n",
    "    df = get_mapping()\n",
    "\n",
    "    for _, transaction in rows:\n",
    "        ticker = transaction['ticker']\n",
    "        \n",
    "        if isvalid(ticker):\n",
    "            industry = search_mapping(df, ticker)\n",
    "            if industry: \n",
    "                d = increment_dictionary_in_dictionary(d, industry, get_year(transaction['transaction_date']))\n",
    "\n",
    "    d = sort_dictionary_by_keys(d)\n",
    "    \n",
    "    filename = \"frequency_of_industry_breakdown\"\n",
    "    key_header = \"industry\"\n",
    "    \n",
    "    \n",
    "    dir = makesubdir(path_csv, \"ticker/industry\")\n",
    "    wd = make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "\n",
    "frequency_of_industry_breakdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asset Description (asset_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asset Type (asset_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Asset Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_asset_type():\n",
    "    d = {}\n",
    "    _, rows = get_data()\n",
    "\n",
    "    for _, transaction in rows:\n",
    "        if isvalid(transaction['asset_type']):\n",
    "            d = increment_dictionary(d, transaction['asset_type'])\n",
    "      \n",
    "    d = sort_dictionary_by_values(d)\n",
    "  \n",
    "    filename = \"frequency_of_asset_type\"\n",
    "    key_header = \"asset_type\"\n",
    "    value_header = \"number_of_transactions\"\n",
    "    \n",
    "    dir = makesubdir(path_csv, \"asset_type\")\n",
    "    wd = make_csv(dir, filename, d, [key_header, value_header])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "\n",
    "\n",
    "frequency_of_asset_type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Amount by Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search import wiki_search\n",
    "from utils import increment_dictionary_in_dictionary, sort_dictionary_by_keys, get_data, sort_dictionary_by_sort_key, path_csv \n",
    "from csv_utils import make_csv_breakdown\n",
    "import pandas as pd \n",
    "\n",
    "def frequency_of_amount_by_persom():\n",
    "    d = {}\n",
    "    title, rows = get_data()\n",
    "\n",
    "    for _, transaction in rows:\n",
    "        d = increment_dictionary_in_dictionary(d, get_canonical_name(transaction[title]), transaction['amount'])\n",
    "\n",
    "    \n",
    "    d = sort_dictionary_by_keys(d)\n",
    "    \n",
    "    filename = \"frequency_of_amount_by_persom\"\n",
    "    key_header = \"amount\"\n",
    "    \n",
    "    dir = makesubdir(path_csv, \"amount\")\n",
    "    wd = make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "   \n",
    "    \n",
    "frequency_of_amount_by_persom()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Transactions by Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search import wiki_search\n",
    "from utils import increment_dictionary, sort_dictionary_by_keys, get_data, sort_dictionary_by_sort_key, path_csv, add_sort_key_for_amount\n",
    "from csv_utils import make_csv_breakdown\n",
    "import pandas as pd \n",
    "\n",
    "def frequency_of_amount_total():\n",
    "    d = {}\n",
    "    _, rows = get_data()\n",
    "\n",
    "    for _, transaction in rows:\n",
    "        d = increment_dictionary(d, transaction['amount'])\n",
    "\n",
    "    d = add_sort_key_for_amount(d, normal_header=\"num_of_transactions\", normal=True)\n",
    "    d = sort_dictionary_by_sort_key(d)\n",
    "\n",
    "    filename = \"frequency_of_amount_total\"\n",
    "    key_header = \"amount\"\n",
    "\n",
    "\n",
    "    dir = makesubdir(path_csv, \"amount\")\n",
    "    wd = make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "   \n",
    "    \n",
    "frequency_of_amount_total()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Amount by Gender "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search import wiki_search\n",
    "from utils import increment_dictionary_in_dictionary, add_sort_key_for_amount, get_data, sort_dictionary_by_sort_key, path_csv, makesubdir \n",
    "from csv_utils import make_csv_breakdown\n",
    "import pandas as pd \n",
    "\n",
    "def frequency_of_amount_by_gender():\n",
    "    d = {}\n",
    "    title, rows = get_data()\n",
    "\n",
    "    gender = {}\n",
    "    for _, transaction in rows:\n",
    "        person = transaction[title]\n",
    "        \n",
    "        if person not in gender: \n",
    "            rep = wiki_search(person) \n",
    "            gender.update({person : rep.get_gender()})\n",
    "            \n",
    "        d = increment_dictionary_in_dictionary(d, transaction['amount'], gender[person])\n",
    "        \n",
    "\n",
    "    d = add_sort_key_for_amount(d)\n",
    "    d = sort_dictionary_by_sort_key(d)\n",
    "    \n",
    "        \n",
    "    filename = \"frequency_of_amount_by_gender\"\n",
    "    key_header = \"amount\"\n",
    "    \n",
    "    \n",
    "    dir = makesubdir(path_csv, \"amount\")\n",
    "    wd = make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "   \n",
    "    \n",
    "frequency_of_amount_by_gender()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Transactions by Political Affiliation and Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search import wiki_search\n",
    "from utils import increment_dictionary_in_dictionary, add_sort_key_for_amount, get_data, sort_dictionary_by_sort_key, path_csv \n",
    "from csv_utils import make_csv_breakdown\n",
    "import pandas as pd \n",
    "\n",
    "def frequency_of_amount_by_aff():\n",
    "    d = {}\n",
    "    title, rows = get_data()\n",
    "\n",
    "    affiliations = {}\n",
    "    for _, transaction in rows:\n",
    "        person = transaction[title]\n",
    "        \n",
    "        if person not in affiliations: \n",
    "            rep = wiki_search(person) \n",
    "            affiliations.update({person : rep.party})\n",
    "            \n",
    "        d = increment_dictionary_in_dictionary(d, transaction['amount'], affiliations[person])\n",
    "\n",
    "\n",
    "    d = add_sort_key_for_amount(d)\n",
    "    d = sort_dictionary_by_sort_key(d)\n",
    "    \n",
    "        \n",
    "    filename = \"frequency_of_amount_by_aff\"\n",
    "    key_header = \"amount\"\n",
    "    \n",
    "    \n",
    "    dir = makesubdir(path_csv, \"amount\")\n",
    "    wd = make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "   \n",
    "    \n",
    "frequency_of_amount_by_aff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average For Buys and Sells per Official "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import increment_dictionary_in_dictionary, sort_dictionary_by_values, path_csv, get_data, get_year, average_amount, isvalid, increment_dictionary, makesubdir, commify\n",
    "from csv_utils import make_csv\n",
    "import pandas as pd \n",
    "from scipy.stats.mstats import gmean\n",
    "from official import get_canonical_name\n",
    "\n",
    "def average_per_person():\n",
    "    title, rows = get_data()\n",
    "    d={}\n",
    "    \n",
    "    for _, transaction in rows:\n",
    "        if isvalid(transaction['amount']):\n",
    "            \n",
    "            # if 'Purchase' in transaction['type']:\n",
    "                \n",
    "            # if 'Sale' in transaction['type']:\n",
    "            d = increment_dictionary_in_dictionary(d, get_canonical_name(transaction[title]), average_amount(transaction['amount']))\n",
    "\n",
    "\n",
    "    d2 = {}\n",
    "    for person in d:\n",
    "        l = []\n",
    "        for amount in d[person]:   \n",
    "            l.append(d[person][amount]*amount)\n",
    "            \n",
    "        d2[person] = l \n",
    "        \n",
    "        \n",
    "    for person in d2:\n",
    "        d2[person] = int(gmean(d2[person]))\n",
    "    \n",
    "    filename = \"average_per_person\"\n",
    "    key_header = title \n",
    "    value_header = \"average_size_of_transactions\"\n",
    "\n",
    "    d2 = sort_dictionary_by_values(d2)\n",
    "    d2 = commify(d2)\n",
    "\n",
    "    dir = makesubdir(path_csv, \"amount\")\n",
    "    wd = make_csv(dir, filename, d2, [key_header, value_header])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "\n",
    "    return d2 \n",
    "\n",
    "average_per_person_res = average_per_person()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types (type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Actions Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_data, isvalid\n",
    "\n",
    "def frequency_of_act():\n",
    "    d = {}\n",
    "    _, rows = get_data()\n",
    "\n",
    "    for _, transaction in rows:\n",
    "        if isvalid(transaction['type']): \n",
    "            d = increment_dictionary(d, transaction['type'])\n",
    "    \n",
    "    d = sort_dictionary_by_values(d)\n",
    "    \n",
    "    filename = \"frequency_of_act\"\n",
    "    key_header = \"type\"\n",
    "    value_header = \"number_of_transactions\"\n",
    "    \n",
    "    dir = makesubdir(path_csv, \"type\")\n",
    "    wd = make_csv(dir, filename, d, [key_header, value_header])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "\n",
    "     \n",
    "frequency_of_act()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Transactions per Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import increment_dictionary_in_dictionary, sort_dictionary_by_keys, get_data, path_csv,makesubdir\n",
    "from csv_utils import make_csv_breakdown\n",
    "import pandas as pd \n",
    "from official import get_canonical_name\n",
    "\n",
    "\n",
    "def types_of_transactions_per_person():\n",
    "    title, rows = get_data()\n",
    "    d={}\n",
    "    \n",
    "    for _, transaction in rows:\n",
    "        d = increment_dictionary_in_dictionary(d, get_canonical_name(transaction[title]), transaction['type'])\n",
    "\n",
    "\n",
    "    filename = \"types_of_transactions_per_person\"\n",
    "\n",
    "    d = sort_dictionary_by_keys(d)\n",
    "\n",
    "    dir = makesubdir(path_csv, \"type\")\n",
    "    wd = make_csv_breakdown(dir, filename, d, title)\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "\n",
    "    return d \n",
    "\n",
    "types_of_transactions_per_person_res = types_of_transactions_per_person()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment (comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import increment_dictionary, sort_dictionary_by_values, path_csv, get_data, get_year, makesubdir\n",
    "from csv_utils import make_csv\n",
    "import pandas as pd \n",
    "\n",
    "def num_of_trans_per_year():\n",
    "    _, rows = get_data()\n",
    "    d={}\n",
    "    \n",
    "    for _, transaction in rows:\n",
    "        d = increment_dictionary(d, get_year(transaction['transaction_date']))\n",
    "\n",
    "    filename = \"num_of_trans_per_year\"\n",
    "    key_header = \"year\"\n",
    "    value_header = \"number_of_transactions\"\n",
    "\n",
    "    d = sort_dictionary_by_values(d)\n",
    "    \n",
    "    dir = makesubdir(path_csv, \"frequency\")\n",
    "    wd = make_csv(dir, filename, d, [key_header, value_header])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "\n",
    "    return d \n",
    "\n",
    "num_of_trans_per_year_res = num_of_trans_per_year()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Person \n",
    "_Not controlling for number of years in position or size of transaction._ For each official, we want their total number of transactions.  {'Sam': 5, 'Alex': 2424, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import increment_dictionary, sort_dictionary_by_values, path_csv, get_data\n",
    "from official import get_canonical_name\n",
    "from csv_utils import make_csv\n",
    "import pandas as pd \n",
    "\n",
    "def num_of_trans_per_person():\n",
    "    title, rows = get_data()\n",
    "    d={}\n",
    "    \n",
    "    for _, transaction in rows:\n",
    "        d = increment_dictionary(d, get_canonical_name(transaction[title]))\n",
    "\n",
    "    filename = \"num_of_trans_per_person\"\n",
    "    key_header = title\n",
    "    value_header = \"number_of_transactions\"\n",
    "\n",
    "    d = sort_dictionary_by_values(d)\n",
    "    \n",
    "    dir = makesubdir(path_csv, \"frequency\")\n",
    "    wd = make_csv(dir, filename, d, [key_header, value_header])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "\n",
    "    return d \n",
    "\n",
    "trans_per_person_res = num_of_trans_per_person()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Person Controlled\n",
    "_Divide number of transactions by number of years in official position.  Not controlling for size of transaction._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search import wiki_search\n",
    "from utils import get_data\n",
    "import math \n",
    "\n",
    "def num_of_trans_per_person_controlled(rows):    \n",
    "    title, _ = get_data()\n",
    "    d={}\n",
    "\n",
    "    for person, num_of_trans in rows.items():\n",
    "        official = wiki_search(person)    \n",
    "        years_in_office = official.get_num_of_years()\n",
    "        d[person] = math.ceil(num_of_trans/years_in_office) \n",
    "\n",
    "    filename = \"num_of_trans_per_person_controlled\"\n",
    "    value_header = \"avg_number_of_transactions\"\n",
    "\n",
    "    d = sort_dictionary_by_values(d)\n",
    "   \n",
    "    dir = makesubdir(path_csv, \"frequency\")\n",
    "    wd = make_csv(dir, filename, d, [title, value_header])\n",
    "    print(pd.read_csv(wd).head(5))\n",
    "    \n",
    "    return d \n",
    "\n",
    "num_of_trans_per_person_controlled_res = num_of_trans_per_person_controlled(trans_per_person_res)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Person Controlled w/Number of Years in Congress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search import wiki_search\n",
    "from utils import get_data\n",
    "import math \n",
    "\n",
    "def num_of_trans_per_person_controlled_w_seniority(rows):    \n",
    "    title, _ = get_data()\n",
    "\n",
    "    d={}\n",
    "\n",
    "    for person, num_of_trans in rows.items():\n",
    "        official = wiki_search(person)    \n",
    "        years_in_office = official.get_num_of_years()\n",
    "        d[person] = math.ceil(num_of_trans/years_in_office), official.get_num_of_years()\n",
    "\n",
    "    filename = \"num_of_trans_per_person_controlled_w_seniority\"\n",
    "    value_header = \"avg_number_of_transactions\"\n",
    "\n",
    "    d = sort_dictionary_by_values(d)\n",
    "   \n",
    "    dir = makesubdir(path_csv, \"frequency\")\n",
    "    wd = make_csv(dir, filename, d, [title, value_header, \"seniority\"])\n",
    "    print(pd.read_csv(wd).head(5))\n",
    "    \n",
    "    return d \n",
    "\n",
    "num_of_trans_per_person_controlled_w_seniority_res = num_of_trans_per_person_controlled_w_seniority(trans_per_person_res)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Person Controlled w/Degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search import wiki_search\n",
    "from utils import get_data\n",
    "import math \n",
    "\n",
    "def num_of_trans_per_person_controlled_w_degrees(rows):    \n",
    "    title, _ = get_data()\n",
    "\n",
    "    d={}\n",
    "\n",
    "    for person, num_of_trans in rows.items():\n",
    "        official = wiki_search(person)    \n",
    "        years_in_office = official.get_num_of_years()\n",
    "        d[person] = math.ceil(num_of_trans/years_in_office), official.get_num_of_degrees()\n",
    "\n",
    "    filename = \"num_of_trans_per_person_controlled_w_degrees\"\n",
    "    value_header = \"avg_number_of_transactions\"\n",
    "\n",
    "    d = sort_dictionary_by_values(d)\n",
    "   \n",
    "    dir = makesubdir(path_csv, \"frequency\")\n",
    "    wd = make_csv(dir, filename, d, [title, value_header, \"num_of_degrees\"])\n",
    "    print(pd.read_csv(wd).head(5))\n",
    "    \n",
    "    return d \n",
    "\n",
    "num_of_trans_per_person_controlled_w_degrees_res = num_of_trans_per_person_controlled_w_degrees(trans_per_person_res)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Person Controlled w/Affiliation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search import wiki_search\n",
    "import math \n",
    "\n",
    "def num_of_trans_per_person_controlled_w_aff(rows):\n",
    "    title, _ = get_data()\n",
    "    d={}\n",
    "    \n",
    "    for person, val in rows.items():\n",
    "        official = wiki_search(person)     \n",
    "        d[person] = val, official.get_party()\n",
    "\n",
    "    filename = \"num_of_trans_per_person_controlled_w_aff\"\n",
    "    value_header = \"avg_number_of_transactions\"\n",
    "\n",
    "    d = sort_dictionary_by_values(d)\n",
    "        \n",
    "    dir = makesubdir(path_csv, \"frequency\")\n",
    "    wd = make_csv(dir, filename, d, [title, value_header, \"party\"])\n",
    "    print(pd.read_csv(wd).head(5))\n",
    "    \n",
    "    return d, pd.read_csv(wd).head(10)\n",
    "\n",
    "num_of_trans_per_person_controlled_w_aff_res, top_10 = num_of_trans_per_person_controlled_w_aff(num_of_trans_per_person_controlled_res)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transaction Date (transaction_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency of Differences between Transaction and Disclosure Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import difference_between_dates, increment_dictionary, sort_dictionary_by_keys, path_csv, path_html\n",
    "from graph_utils import graph_csv\n",
    "from csv_utils import make_csv\n",
    "\n",
    "# todo, check if outlier exists (manually check it).\n",
    "# potential for automating it? ---> policy issue?\n",
    "\n",
    "def frequency_of_differences():\n",
    "    d = {}\n",
    "    match = {}\n",
    "    title, rows = get_data()\n",
    "    total = num = 0 \n",
    "\n",
    "    for _, transaction in rows:\n",
    "        transaction_date = transaction['transaction_date']\n",
    "        disclosure_date = transaction['disclosure_date']\n",
    "\n",
    "        # Negative, X days BEFORE\n",
    "        # Positive, Y dayas AFTER\n",
    "        diff = difference_between_dates(disclosure_date, transaction_date)      \n",
    "        total += 1 \n",
    "        num += diff   \n",
    "        \n",
    "        # match = {5 days: {'Tom' : 1313, 'X': 3 , ...}. ..}\n",
    "        match = increment_dictionary_in_dictionary(match, diff, transaction[title])\n",
    "            \n",
    "            \n",
    "        d = increment_dictionary(d, int(diff))\n",
    "    \n",
    "    d = sort_dictionary_by_keys(d)\n",
    "        \n",
    "    filename = \"frequency_of_differences\"\n",
    "    key_header = \"difference_in_days\"\n",
    "    value_header = \"#_of_transactions_with_that_diff\"\n",
    "    \n",
    "    \n",
    "    dir = makesubdir(path_csv, \"disclosure_date/transaction_date\")\n",
    "    make_csv(dir, filename, d, [key_header, value_header])\n",
    "    # fig = graph_csv(dir, path_html, filename, key_header, value_header)\n",
    "    # fig.show()\n",
    "    \n",
    "    print(\"Average difference in days: {}\".format(num//total))\n",
    "\n",
    "frequency_of_differences()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e534e48711db4d1e1c48977d0d14ff85b1f16d41bcc4fdfd88268a329b3c9d66"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
