{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.csv_utils as csv_utils \n",
    "import utils.dir_utils as dir_utils\n",
    "import utils.dict_utils as dict_utils \n",
    "import utils.ptr_utils as ptr_utils\n",
    "import utils.constants as constants \n",
    "import helpers.official as official\n",
    "import helpers.search_u as search\n",
    "import helpers.congress as congress\n",
    "import pandas as pd \n",
    "from scipy.stats.mstats import gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, input_df = dir_utils.get_data(combined=True)\n",
    "\n",
    "# donald payne + son\n",
    "# house_officials.add(\"Payne Jr., Donald\")\n",
    "# house_officials.add(\"Payne, Donald M.\")\n",
    "\n",
    "\n",
    "# house_officials.add(\"Rogers, Michael J.\")\n",
    "# house_officials.add(\"Rogers, Michael D.\")\n",
    "# house_officials.remove(\"Rogers, Mike\")\n",
    "\n",
    "# house_officials.add(\"Hall, Kwanza\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Bill_Flores\n",
      "/Bruce_Poliquin\n",
      "/Dusty_Johnson\n",
      "/Dan_Donovan_(politician)\n",
      "/Pete_Olson\n",
      "/Xavier_Becerra\n",
      "/Bonnie_Watson_Coleman\n",
      "/Pete_Aguilar\n",
      "/Maxine_Waters\n",
      "/Dick_Durbin\n",
      "/Jason_Crow\n",
      "/Bill_Young\n",
      "/Antonio_Delgado_(politician)\n",
      "/Tim_Huelskamp\n",
      "/Charlie_Dent\n",
      "/Charles_Boustany\n",
      "/Howard_Coble\n",
      "/John_Barrow_(American_politician)\n",
      "/Rick_Nolan\n",
      "/John_Rutherford_(Florida_politician)\n",
      "/Jos%C3%A9_E._Serrano\n",
      "/Ron_Johnson_(Wisconsin_politician)\n",
      "/Gloria_Negrete_McLeod\n",
      "/Jim_Hagedorn\n",
      "/Mia_Love\n",
      "/Conor_Lamb\n",
      "/Joe_Lieberman\n",
      "/Lynn_Westmoreland\n",
      "/Eric_Cantor\n",
      "/Bob_Menendez\n",
      "/Bob_Good\n",
      "/Lisa_McClain\n",
      "/Hank_Johnson\n",
      "/Bob_Brady\n",
      "/Roy_Blunt\n",
      "/Marie_Newman\n",
      "/Colleen_Hanabusa\n",
      "/Donna_Shalala\n",
      "/Rob_Andrews\n",
      "/Todd_Akin\n",
      "/Rich_Nugent\n",
      "/Veronica_Escobar\n",
      "/Justin_Amash\n",
      "/Jim_Clyburn\n",
      "/Elise_Stefanik\n",
      "/Carolyn_Maloney\n",
      "/Troy_Nehls\n",
      "/Dan_Coats\n",
      "/Jim_Bridenstine\n",
      "/Brenda_Jones_(politician)\n",
      "/Eric_Swalwell\n",
      "/Sylvia_Garcia\n",
      "/Carlos_Curbelo\n",
      "/David_Wu\n",
      "/Tom_Graves\n",
      "/James_Lankford\n",
      "/Mike_Bost\n",
      "/Devin_Nunes\n",
      "/Mike_Simpson\n",
      "/Jim_DeMint\n",
      "/Peter_Roskam\n",
      "/Tony_C%C3%A1rdenas\n",
      "/Melanie_Stansbury\n",
      "/Susan_Collins\n",
      "/Cori_Bush\n",
      "/John_F._Tierney\n",
      "/Joe_Manchin\n",
      "/John_Conyers\n",
      "/Doris_Matsui\n",
      "/Doug_Lamborn\n",
      "/Chris_Stewart_(politician)\n",
      "/Heath_Shuler\n",
      "/Jim_McDermott\n",
      "/Dianne_Feinstein\n",
      "/Corrine_Brown\n",
      "/Norma_Torres\n",
      "/Elaine_Luria\n",
      "/Anna_Eshoo\n",
      "/Jon_Tester\n",
      "/Donald_McEachin\n",
      "/Marcy_Kaptur\n",
      "/Mark_Sanford\n",
      "/Elijah_Cummings\n",
      "/John_Dingell\n",
      "/Fred_Keller_(politician)\n",
      "/Patrick_McHenry\n",
      "/Virginia_Foxx\n",
      "/Ron_Barber\n",
      "/Dale_Kildee\n",
      "/Mike_Fitzpatrick\n",
      "/Sam_Farr\n",
      "/Matt_Cartwright\n",
      "/David_Valadao\n",
      "/Paul_Tonko\n",
      "/Max_Baucus\n",
      "/Chip_Roy\n",
      "/Ron_Wright_(politician)\n",
      "/Warren_Davidson\n",
      "/Tim_Griffin\n",
      "/Jack_Kingston\n",
      "/Tim_Johnson_(Illinois_politician)\n",
      "/Jo_Ann_Emerson\n",
      "/Tim_Ryan_(Ohio_politician)\n",
      "/Eni_Faleomavaega\n",
      "/Michael_Cloud\n",
      "/Doug_Jones_(politician)\n",
      "/Cindy_Hyde-Smith\n",
      "/Jerry_Lewis_(California_politician)\n",
      "/Nancy_Mace\n",
      "/Lois_Frankel\n",
      "/Ronny_Jackson\n",
      "/John_Walsh_(Montana_politician)\n",
      "/Adam_Kinzinger\n",
      "/Frank_Wolf_(politician)\n",
      "/Cory_Gardner\n",
      "/Kim_Schrier\n",
      "/John_Kennedy_(Louisiana_politician)\n",
      "/Kat_Cammack\n",
      "/Lloyd_Smucker\n",
      "/Mike_Lee_(American_politician)\n",
      "/Gil_Cisneros\n",
      "/Janice_Hahn\n",
      "/Donald_M._Payne\n",
      "/Jeff_Merkley\n",
      "/Chris_Murphy\n",
      "/Donald_Payne_Jr.\n",
      "/Ralph_Hall\n",
      "/Jason_Chaffetz\n",
      "/Bob_Goodlatte\n",
      "/Gregg_Harper\n",
      "/Ra%C3%BAl_Labrador\n",
      "/Thad_Cochran\n",
      "/Jean_Schmidt\n",
      "/David_McKinley\n",
      "/Tina_Smith\n",
      "/Tony_Gonzales\n",
      "/Al_Green_(politician)\n",
      "/Jo_Bonner\n",
      "/Randy_Neugebauer\n",
      "/Tim_Burchett\n",
      "/Bobby_Rush\n",
      "/Pat_Meehan\n",
      "/Spencer_Bachus\n",
      "/Ken_Buck\n",
      "/Lamar_Alexander\n",
      "/Scott_Tipton\n",
      "/Kay_Hagan\n",
      "/Alan_Grayson\n",
      "/Lou_Correa\n",
      "/Dan_Kildee\n",
      "/Susie_Lee\n",
      "/Jim_Gerlach\n",
      "/Joe_Garcia\n",
      "/Jerry_Carl\n",
      "/French_Hill_(politician)\n",
      "/Angus_King\n",
      "/Jason_Smith_(politician)\n",
      "/Roger_Marshall_(politician)\n",
      "/Tom_Reed_(politician)\n",
      "/Bob_Corker\n",
      "/John_Barrasso\n",
      "/Joaquin_Castro\n",
      "/Katie_Porter\n",
      "/Trent_Franks\n",
      "/Stephen_F._Lynch\n",
      "/Brian_Schatz\n",
      "/John_Ratcliffe_(American_politician)\n",
      "/Henry_Waxman\n",
      "/John_Mica\n",
      "/John_Lewis\n",
      "/Mike_Garcia_(politician)\n",
      "/Todd_Rokita\n",
      "/Frank_Guinta\n",
      "/Jon_Kyl\n",
      "/Lisa_Murkowski\n",
      "/Debbie_Lesko\n",
      "/Mary_Gay_Scanlon\n",
      "/Anthony_Gonzalez_(politician)\n",
      "/Allyson_Schwartz\n",
      "/Maria_Cantwell\n",
      "/Tom_Cotton\n",
      "/Chris_Coons\n",
      "/Vicente_Gonzalez_(politician)\n",
      "/Joe_Wilson_(American_politician)\n",
      "/Frank_LoBiondo\n",
      "/Jaime_Herrera_Beutler\n",
      "/John_Sarbanes\n",
      "/Geoff_Davis\n",
      "/Maggie_Hassan\n",
      "/Joe_Cunningham_(American_politician)\n",
      "/Cliff_Stearns\n",
      "/Raphael_Warnock\n",
      "/Chip_Cravaack\n",
      "/Walter_B._Jones_Jr.\n",
      "/Johnny_Isakson\n",
      "/Tom_Coburn\n",
      "/Guy_Reschenthaler\n",
      "/Betty_Sutton\n",
      "/Lacy_Clay\n",
      "/Emanuel_Cleaver\n",
      "/Harry_Reid\n",
      "/Tom_O%27Halleran\n",
      "/Fred_Upton\n",
      "/Deb_Haaland\n",
      "/Darrell_Issa\n",
      "/Randy_Feenstra\n",
      "/Debbie_Wasserman_Schultz\n",
      "/Mike_Ross_(politician)\n",
      "/Sam_Graves\n",
      "/Debbie_Stabenow\n",
      "/Jim_Inhofe\n",
      "/Tammy_Duckworth\n",
      "/Mark_Takai\n",
      "/Kevin_McCarthy_(California_politician)\n",
      "/Tom_Marino\n",
      "/Steve_LaTourette\n",
      "/Marlin_Stutzman\n",
      "/James_Comer_(politician)\n",
      "/Jimmy_Gomez\n",
      "/Dave_Camp\n",
      "/Marcia_Fudge\n",
      "/Eliot_Engel\n",
      "/Mike_Honda\n",
      "/Chuck_Grassley\n",
      "/Tim_Bishop\n",
      "/Mike_Conaway\n",
      "/Mike_Coffman\n",
      "/Rob_Wittman\n",
      "/Marco_Rubio\n",
      "/Ritchie_Torres\n",
      "/Brett_Guthrie\n",
      "/Victoria_Spartz\n",
      "/Nita_Lowey\n",
      "/Doc_Hastings\n",
      "/Barney_Frank\n",
      "/Mark_Kirk\n",
      "/Cheri_Bustos\n",
      "/Brian_Fitzpatrick_(American_politician)\n",
      "/Mark_Pryor\n",
      "/Raul_Ruiz_(politician)\n",
      "/Jimmy_Duncan_(politician)\n",
      "/Gary_Peters\n",
      "/Charlie_Gonzalez\n",
      "/Rod_Blum\n",
      "/Bill_Huizenga\n",
      "/John_Culberson\n",
      "/Lucy_McBath\n",
      "/John_Moolenaar\n",
      "/Ben_Cline\n",
      "/Blaine_Luetkemeyer\n",
      "/Brian_Higgins\n",
      "/Mark_Warner\n",
      "/Peter_T._King\n",
      "/Max_Rose\n",
      "/Betty_McCollum\n",
      "/Gene_Green\n",
      "/Tim_Murphy_(American_politician)\n",
      "/Henry_Cuellar\n",
      "/Paul_Broun\n",
      "/Bennie_Thompson\n",
      "/Bob_Dold\n",
      "/Ed_Whitfield\n",
      "/Kurt_Schrader\n",
      "/Alexandria_Ocasio-Cortez\n",
      "/Ralph_Abraham_(politician)\n",
      "/Mondaire_Jones\n",
      "/Joe_Heck\n",
      "/Kevin_Yoder\n",
      "/Barbara_Comstock\n",
      "/Steve_Southerland_(Florida_politician)\n",
      "/Reid_Ribble\n",
      "/Dan_Lipinski\n",
      "/Allen_West_(politician)\n",
      "/Ilhan_Omar\n",
      "/Keith_Ellison\n",
      "/Jeff_Fortenberry\n",
      "/Chris_Smith_(New_Jersey_politician)\n",
      "/John_Katko\n",
      "/Jay_Inslee\n",
      "/Scott_Franklin_(politician)\n",
      "/Tom_Carper\n",
      "/Jake_Ellzey\n",
      "/Debbie_Dingell\n",
      "/Jim_Webb\n",
      "/Jim_McGovern_(American_politician)\n",
      "/Patrick_Murphy_(Florida_politician)\n",
      "/Ruben_Gallego\n",
      "/Mike_Levin\n",
      "/Josh_Harder\n",
      "/Cedric_Richmond\n",
      "/Trey_Gowdy\n",
      "/Tim_Scott\n",
      "/Jerry_McNerney\n",
      "/Chris_Lee_(New_York_politician)\n",
      "/Cory_Booker\n",
      "/Sean_Duffy\n",
      "/Jared_Golden\n",
      "/Renee_Ellmers\n",
      "/Denny_Heck\n",
      "/Andy_Kim_(politician)\n",
      "/Seth_Moulton\n",
      "/Patty_Murray\n",
      "/Bryan_Steil\n",
      "/Chaka_Fattah\n",
      "/Trey_Radel\n",
      "/Elton_Gallegly\n",
      "/Shelley_Moore_Capito\n",
      "/Tom_Udall\n",
      "/Derek_Kilmer\n",
      "/Claudia_Tenney\n",
      "/Carolyn_Bourdeaux\n",
      "/Lori_Trahan\n",
      "/Gregory_Meeks\n",
      "/Dave_Trott_(politician)\n",
      "/Clay_Higgins\n",
      "/Dutch_Ruppersberger\n",
      "/Ron_Estes\n",
      "/Marsha_Blackburn\n",
      "/Dennis_Ross_(politician)\n",
      "/Dina_Titus\n",
      "/Andy_Harris_(politician)\n",
      "/Mark_Meadows\n",
      "/Alcee_Hastings\n",
      "/Larry_Kissell\n",
      "/Ralph_Norman\n",
      "/Thomas_Suozzi\n",
      "/Jeb_Hensarling\n",
      "/Scott_Perry_(politician)\n",
      "/Ron_Wyden\n",
      "/Tim_Walberg\n",
      "/Michael_Bennet\n",
      "/Teresa_Leger_Fernandez\n",
      "/Bruce_Westerman\n",
      "/Ra%C3%BAl_Grijalva\n",
      "/Sandy_Adams\n",
      "/Joe_Barton\n",
      "/Peter_Meijer\n",
      "/Alex_Padilla\n",
      "/Steve_Israel\n",
      "/Lynn_Woolsey\n",
      "/Charles_Bass\n",
      "/Mike_Thompson_(California_politician)\n",
      "/Chris_Van_Hollen\n",
      "/William_Enyart\n",
      "/Bill_Johnson_(Ohio_politician)\n",
      "/Edolphus_Towns\n",
      "/Pat_Roberts\n",
      "/Leonard_Lance\n",
      "/Garret_Graves\n",
      "/Bruce_Braley\n",
      "/Austin_Scott_(politician)\n",
      "/Dave_Reichert\n",
      "/Richard_Lugar\n",
      "/Luther_Strange\n",
      "/Lynn_Jenkins\n",
      "/Vance_McAllister\n",
      "/Jeff_Van_Drew\n",
      "/Pramila_Jayapal\n",
      "/Bob_Turner_(American_politician)\n",
      "/Kathy_Manning\n",
      "/Diana_DeGette\n",
      "/Martha_McSally\n",
      "/Juan_Vargas\n",
      "/Kathy_Hochul\n",
      "/Kelly_Ayotte\n",
      "/Cresent_Hardy\n",
      "/Saxby_Chambliss\n",
      "/John_Hoeven\n",
      "/John_Cornyn\n",
      "/Ron_DeSantis\n",
      "/George_Holding\n",
      "/Joe_Baca\n",
      "/John_Curtis_(Utah_politician)\n",
      "/Francis_Rooney\n",
      "/Joe_Courtney_(politician)\n",
      "/Steve_Rothman\n",
      "/Scott_Rigell\n",
      "/Bobby_Scott_(politician)\n",
      "/Gary_Miller_(politician)\n",
      "/Richard_Blumenthal\n",
      "/Steve_Chabot\n",
      "/Tommy_Tuberville\n",
      "/Adam_Schiff\n",
      "/Charles_Rangel\n",
      "/Robert_Hurt_(politician)\n",
      "/John_Fleming_(American_politician)\n",
      "/David_Rivera\n",
      "/David_Cicilline\n",
      "/Drew_Ferguson_(politician)\n",
      "/Ben_Quayle\n",
      "/David_Scott_(Georgia_politician)\n",
      "/Al_Franken\n",
      "/Diana_Harshbarger\n",
      "/Jason_Altmire\n",
      "/Rodney_Frelinghuysen\n",
      "/Sander_Levin\n",
      "/Gary_Ackerman\n",
      "/Russ_Carnahan\n",
      "/Tim_Kaine\n",
      "/Bill_Foster_(politician)\n",
      "/Keith_Rothfus\n",
      "/Tom_Malinowski\n",
      "/Patrick_Leahy\n",
      "/Deborah_K._Ross\n",
      "/Claire_McCaskill\n",
      "/Andy_Barr_(American_politician)\n",
      "/Rick_Berg\n",
      "/Hal_Rogers\n",
      "/Blake_Farenthold\n",
      "/Chuck_Fleischmann\n",
      "/Troy_Carter_(politician)\n",
      "/Ted_Poe\n",
      "/Tammy_Baldwin\n",
      "/Ben_Ray_Luj%C3%A1n\n",
      "/Bill_Cassidy\n",
      "/Marc_Veasey\n",
      "/Grace_Meng\n",
      "/Ryan_Costello\n",
      "/Beth_Van_Duyne\n",
      "/Candice_Miller\n",
      "/Steve_Stivers\n",
      "/Abby_Finkenauer\n",
      "/Tom_Tiffany\n",
      "/Jon_Runyan_Sr.\n",
      "/Jerry_Moran\n",
      "/Joseph_Morelle\n",
      "/Andy_Biggs\n",
      "/Tom_Rooney_(Florida_politician)\n",
      "/Michelle_Lujan_Grisham\n",
      "/Mo_Cowan\n",
      "/Mary_Miller_(politician)\n",
      "/Bob_Gibbs\n",
      "/Kyrsten_Sinema\n",
      "/Dean_Heller\n",
      "/Ben_Cardin\n",
      "/Rush_Holt_Jr.\n",
      "/Dwight_Evans_(politician)\n",
      "/Jamaal_Bowman\n",
      "/Tom_Price_(American_politician)\n",
      "/Dan_Crenshaw\n",
      "/Michele_Bachmann\n",
      "/Scott_Peters_(politician)\n",
      "/Daniel_Webster_(Florida_politician)\n",
      "/Maurice_Hinchey\n",
      "/Scott_DesJarlais\n",
      "/Sean_Casten\n",
      "/Kendra_Horn\n",
      "/Michael_San_Nicolas\n",
      "/Jacky_Rosen\n",
      "/Andrew_Garbarino\n",
      "/Paul_Mitchell_(politician)\n",
      "/Pedro_Pierluisi\n",
      "/Jake_Auchincloss\n",
      "/Denny_Rehberg\n",
      "/Dan_Maffei\n",
      "/Pat_Tiberi\n",
      "/Tom_Rice\n",
      "/Michael_C._Burgess\n",
      "/Ben_Sasse\n",
      "/Rosa_DeLauro\n",
      "/Jim_Moran\n",
      "/Trent_Kelly\n",
      "/Salud_Carbajal\n",
      "/Judy_Biggert\n",
      "/Thaddeus_McCotter\n",
      "/Mimi_Walters\n",
      "/Bobby_Schilling\n",
      "/Mike_Rounds\n",
      "/Ed_Case\n",
      "/Elizabeth_Warren\n",
      "/Lou_Barletta\n",
      "/Adam_Smith_(Washington_politician)\n",
      "/Gary_Palmer_(politician)\n",
      "/Daniel_Akaka\n",
      "/Steve_Cohen_(politician)\n",
      "/David_Curson\n",
      "/Bill_Owens_(New_York_politician)\n",
      "/Gwen_Graham\n",
      "/Haley_Stevens\n",
      "/Van_Taylor\n",
      "/Lance_Gooden\n",
      "/Jon_Ossoff\n",
      "/Steny_Hoyer\n",
      "/George_Miller_(California_politician)\n",
      "/Todd_Young\n",
      "/Lauren_Underwood\n",
      "/Luis_Guti%C3%A9rrez\n",
      "/Kenny_Marchant\n",
      "/Louise_Slaughter\n",
      "/Martha_Roby\n",
      "/Randy_Hultgren\n",
      "/Morgan_Griffith\n",
      "/Kirsten_Gillibrand\n",
      "/Tom_Latham_(politician)\n",
      "/Lamar_Smith\n",
      "/Sharice_Davids\n",
      "/Don_Bacon\n",
      "/Cynthia_Lummis\n",
      "/Jack_Reed_(Rhode_Island_politician)\n",
      "/Suzan_DelBene\n",
      "/Anthony_Weiner\n",
      "/John_Ensign\n",
      "/Brian_Mast\n",
      "/Jim_Banks\n",
      "/Jes%C3%BAs_%22Chuy%22_Garc%C3%ADa\n",
      "/Ayanna_Pressley\n",
      "/Erik_Paulsen\n",
      "/David_Joyce_(politician)\n",
      "/Duncan_D._Hunter\n",
      "/Steve_Knight_(politician)\n",
      "/Judy_Chu\n",
      "/Eddie_Bernice_Johnson\n",
      "/Jeff_Landry\n",
      "/Shontel_Brown\n",
      "/Jackie_Walorski\n",
      "/Kathy_Castor\n",
      "/Roscoe_Bartlett\n",
      "/Andrew_Clyde\n",
      "/Alan_Nunnelee\n",
      "/Cliff_Bentz\n",
      "/Frank_Lautenberg\n",
      "/Mike_Carey_(politician)\n",
      "/Dennis_Cardoza\n",
      "/Mikie_Sherrill\n",
      "/Jahana_Hayes\n",
      "/Kevin_Brady\n",
      "/Mario_D%C3%ADaz-Balart\n",
      "/David_Vitter\n",
      "/Josh_Gottheimer\n",
      "/Don_Young\n",
      "/Mike_Capuano\n",
      "/Niki_Tsongas\n",
      "/Mike_Crapo\n",
      "/Mike_Bishop_(politician)\n",
      "/Terri_Sewell\n",
      "/Vicky_Hartzler\n",
      "/Jeanne_Shaheen\n",
      "/Harley_Rouda\n",
      "/Mike_Enzi\n",
      "/Mike_Pompeo\n",
      "/Kathleen_Rice\n",
      "/Mike_Braun\n",
      "/Grace_Napolitano\n",
      "/Jared_Polis\n",
      "/Colin_Allred\n",
      "/Brenda_Lawrence\n",
      "/Jennifer_Wexton\n",
      "/Kristi_Noem\n",
      "/Pete_Stauber\n",
      "/Barry_Loudermilk\n",
      "/Raja_Krishnamoorthi\n",
      "/David_Rouzer\n",
      "/John_Shimkus\n",
      "/Howard_Berman\n",
      "/Peter_Welch\n",
      "/Sheila_Jackson_Lee\n",
      "/Annie_Kuster\n",
      "/Carol_Miller_(politician)\n",
      "/Scott_L._Fitzgerald\n",
      "/Gwen_Moore\n",
      "/Troy_Balderson\n",
      "/Pete_Stark\n",
      "/Marilyn_Strickland\n",
      "/Rob_Woodall\n",
      "/Mac_Thornberry\n",
      "/Jesse_Jackson_Jr.\n",
      "/Jeff_Bingaman\n",
      "/Pete_Gallego\n",
      "/Barry_Moore_(Alabama_politician)\n",
      "/Norm_Dicks\n",
      "/David_Trone\n",
      "/Dean_Phillips\n",
      "/Chellie_Pingree\n",
      "/Steve_King\n",
      "/Joe_Pitts_(Pennsylvania_politician)\n",
      "/Jim_Matheson\n",
      "/Dan_Sullivan_(U.S._senator)\n",
      "/Chrissy_Houlahan\n",
      "/Kai_Kahele\n",
      "/Elissa_Slotkin\n",
      "/Mike_Kelly_(Pennsylvania_politician)\n",
      "/Tracey_Mann\n",
      "/Will_Hurd\n",
      "/Mazie_Hirono\n",
      "/John_Thune\n",
      "/Darin_LaHood\n",
      "/Ruben_Kihuen\n",
      "/Scott_Brown_(politician)\n",
      "/Abigail_Spanberger\n",
      "/Aaron_Schock\n",
      "/John_Garamendi\n",
      "/Mark_DeSaulnier\n",
      "/John_Carney_(politician)\n",
      "/Collin_Peterson\n",
      "/Kwanza_Hall\n",
      "/Hansen_Clarke\n",
      "/Rodney_Davis_(politician)\n",
      "/Markwayne_Mullin\n",
      "/Byron_Donalds\n",
      "/Paul_Ryan\n",
      "/Catherine_Cortez_Masto\n",
      "/Michael_McCaul\n",
      "/Tom_Emmer\n",
      "/Ed_Perlmutter\n",
      "/Joe_Crowley\n",
      "/Kevin_Cramer\n",
      "/Randy_Weber\n",
      "/Ed_Markey\n",
      "/Heidi_Heitkamp\n",
      "/Paul_Gosar\n",
      "/John_Yarmuth\n",
      "/Thomas_Massie\n",
      "/Brian_Bilbray\n",
      "/Peter_DeFazio\n",
      "/Cindy_Axne\n",
      "/John_B._Larson\n",
      "/Bill_Hagerty\n",
      "/Donald_Norcross\n",
      "/Robert_Pittenger\n",
      "/Matt_Rosendale\n",
      "/Joe_Kennedy_III\n",
      "/Eleanor_Holmes_Norton\n",
      "/Herb_Kohl\n",
      "/Kent_Conrad\n",
      "/Bradley_Byrne\n",
      "/Kweisi_Mfume\n",
      "/Filemon_Vela_Jr.\n",
      "/Madison_Cawthorn\n",
      "/Laura_Richardson\n",
      "/Jim_Costa\n",
      "/Barbara_Lee\n",
      "/Steve_Stockman\n",
      "/Louie_Gohmert\n",
      "/Stephanie_Bice\n",
      "/Bill_Keating_(politician)\n",
      "/Greg_Steube\n",
      "/Thom_Tillis\n",
      "/Ann_Kirkpatrick\n",
      "/Jackie_Speier\n",
      "/Nan_Hayworth\n",
      "/Brad_Wenstrup\n",
      "/Al_Lawson\n",
      "/Ben_Nelson\n",
      "/Amata_Coleman_Radewagen\n",
      "/Neal_Dunn\n",
      "/Carlos_A._Gim%C3%A9nez\n",
      "/Madeleine_Bordallo\n",
      "/Ander_Crenshaw\n",
      "/Mike_McIntyre\n",
      "/Mike_Johanns\n",
      "/Xochitl_Torres_Small\n",
      "/Adriano_Espaillat\n",
      "/Brad_Schneider\n",
      "/Steve_Scalise\n",
      "/Jimmy_Panetta\n",
      "/Young_Kim\n",
      "/Don_Manzullo\n",
      "/Jim_Himes\n",
      "/Lee_Zeldin\n",
      "/Sara_Jacobs\n",
      "/Bill_Nelson\n",
      "/Richard_Neal\n",
      "/Barbara_Mikulski\n",
      "/David_Jolly\n",
      "/Zoe_Lofgren\n",
      "/Jim_Renacci\n",
      "/David_Schweikert\n",
      "/Mel_Watt\n",
      "/Ted_Deutch\n",
      "/Pete_Sessions\n",
      "/Elizabeth_Esty\n",
      "/Rick_Larsen\n",
      "/Mark_E._Green\n",
      "/Sue_Myrick\n",
      "/Ken_Calvert\n",
      "/Jack_Bergman\n",
      "/Wally_Herger\n",
      "/Rob_Bishop\n",
      "/Jason_Lewis_(Minnesota_politician)\n",
      "/Lindsey_Graham\n",
      "/Mike_Rogers_(Michigan_politician)\n",
      "/Buddy_Carter\n",
      "/Charlie_Crist\n",
      "/Leonard_Boswell\n",
      "/Ryan_Zinke\n",
      "/Susan_Brooks\n",
      "/Karen_Handel\n",
      "/Chris_Gibson_(New_York_politician)\n",
      "/Carol_Shea-Porter\n",
      "/Ted_Cruz\n",
      "/Mike_Quigley_(politician)\n",
      "/Daniel_Inouye\n",
      "/Lizzie_Fletcher\n",
      "/Mark_Takano\n",
      "/Bob_Filner\n",
      "/Greg_Walden\n",
      "/Jim_Cooper\n",
      "/Curt_Clawson\n",
      "/John_B._T._Campbell_III\n",
      "/G._K._Butterfield\n",
      "/Richard_Shelby\n",
      "/Gus_Bilirakis\n",
      "/Mark_Pocan\n",
      "/Ted_Budd\n",
      "/Jim_Baird_(politician)\n",
      "/Martin_Heinrich\n",
      "/Julia_Letlow\n",
      "/Greg_Stanton\n",
      "/Dana_Rohrabacher\n",
      "/Lucille_Roybal-Allard\n",
      "/Dave_Loebsack\n",
      "/Yvette_Clarke\n",
      "/Debbie_Mucarsel-Powell\n",
      "/Michael_Guest_(politician)\n",
      "/Matt_Salmon\n",
      "/Bill_Shuster\n",
      "/Joni_Ernst\n",
      "/John_Delaney_(Maryland_politician)\n",
      "/Roger_Wicker\n",
      "/Jan_Schakowsky\n",
      "/Anthony_G._Brown\n",
      "/Ben_McAdams\n",
      "/Stephanie_Murphy\n",
      "/Ann_Marie_Buerkle\n",
      "/Ron_Kind\n",
      "/John_McCain\n",
      "/Connie_Mack_IV\n",
      "/Darren_Soto\n",
      "/Chris_Jacobs_(politician)\n",
      "/Andy_Levin\n",
      "/Kelly_Loeffler\n",
      "/Ed_Pastor\n",
      "/John_Joyce_(American_politician)\n",
      "/Jenniffer_Gonz%C3%A1lez\n",
      "/Tom_MacArthur\n",
      "/Suzanne_Bonamici\n",
      "/Richard_Hudson_(American_politician)\n",
      "/Mick_Mulvaney\n",
      "/Jerry_Nadler\n",
      "/Loretta_Sanchez\n",
      "/Ron_Paul\n",
      "/Andr%C3%A9_Carson\n",
      "/Jim_Sensenbrenner\n",
      "/Evan_Jenkins_(politician)\n",
      "/Frank_Lucas_(Oklahoma_politician)\n",
      "/Sheldon_Whitehouse\n",
      "/Mike_Johnson_(Louisiana_politician)\n",
      "/Yvette_Herrell\n",
      "/Dan_Bishop\n",
      "/Dan_Lungren\n",
      "/Mary_Bono\n",
      "/Jody_Hice\n",
      "/Rick_Crawford_(politician)\n",
      "/Susan_Davis_(politician)\n",
      "/Phil_Roe_(politician)\n",
      "/Tim_Holden\n",
      "/Bernie_Sanders\n",
      "/Rub%C3%A9n_Hinojosa\n",
      "/Lee_Terry\n",
      "/Diane_Black\n",
      "/John_Kline_(politician)\n",
      "/Denver_Riggleman\n",
      "/Jamie_Raskin\n",
      "/Brian_Babin\n",
      "/Robin_Kelly\n",
      "/Jodey_Arrington\n",
      "/Sam_Johnson\n",
      "/Robert_Aderholt\n",
      "/Steve_Womack\n",
      "/Jay_Rockefeller\n",
      "/Amy_Klobuchar\n",
      "/Joe_Walsh_(Illinois_politician)\n",
      "/Mark_Begich\n",
      "/Doug_LaMalfa\n",
      "/Joe_Donnelly\n",
      "/Jay_Obernolte\n",
      "/John_Carter_(Texas_politician)\n",
      "/Brad_Ashford\n",
      "/Ann_Wagner\n",
      "/Dan_Meuser\n",
      "/Olympia_Snowe\n",
      "/Michelle_Steel\n",
      "/Nicole_Malliotakis\n",
      "/Randy_Forbes\n",
      "/Adrian_Smith_(politician)\n",
      "/Chuck_Schumer\n",
      "/David_Kustoff\n",
      "/Jeff_Flake\n",
      "/David_Perdue\n",
      "/Kamala_Harris\n",
      "/Greg_Gianforte\n",
      "/Rick_W._Allen\n",
      "/Sanford_Bishop\n",
      "/Mitch_McConnell\n",
      "/Anthony_Brindisi\n",
      "/Michael_Grimm_(politician)\n",
      "/Steve_Pearce_(politician)\n",
      "/Frederica_Wilson\n",
      "/Quico_Canseco\n",
      "/Alma_Adams\n",
      "/Kay_Bailey_Hutchison\n",
      "/Steven_Horsford\n",
      "/David_Dreier\n",
      "/Bill_Posey\n",
      "/Hakeem_Jeffries\n",
      "/Stacey_Plaskett\n",
      "/David_Price_(American_politician)\n",
      "/Nick_Rahall\n",
      "/Frank_Pallone\n",
      "/Jerry_Costello\n",
      "/Rand_Paul\n",
      "/Steven_Palazzo\n",
      "/Lauren_Boebert\n",
      "/Dan_Boren\n",
      "/TJ_Cox\n",
      "/Mary_Landrieu\n",
      "/Mike_Michaud\n",
      "/Chris_Pappas_(politician)\n",
      "/Nancy_Pelosi\n",
      "/Jeff_Miller_(Florida_politician)\n",
      "/Earl_Blumenauer\n",
      "/Beto_O%27Rourke\n",
      "/Pete_Visclosky\n",
      "/Pat_Toomey\n",
      "/Glenn_Grothman\n",
      "/Ross_Spano\n",
      "/Don_Beyer\n",
      "/William_Timmons\n",
      "/Jeff_Denham\n",
      "/Buck_McKeon\n",
      "/James_Langevin\n",
      "/Michelle_Fischbach\n",
      "/John_Kerry\n",
      "/Mark_Udall\n",
      "/Luke_Messer\n",
      "/Kelly_Armstrong\n",
      "/Madeleine_Dean\n",
      "/Bob_Latta\n",
      "/Jake_LaTurner\n",
      "/Alan_Lowenthal\n",
      "/Gerry_Connolly\n",
      "/John_Boozman\n",
      "/Pat_Fallon\n",
      "/Barbara_Boxer\n",
      "/Ben_Chandler\n",
      "/Vern_Buchanan\n",
      "/Mark_Kelly\n",
      "/Tom_Cole\n",
      "/Ed_Royce\n",
      "/Ted_Yoho\n",
      "/Kevin_Hern\n",
      "/Carl_Levin\n",
      "/Rashida_Tlaib\n",
      "/Greg_Murphy_(politician)\n",
      "/Val_Demings\n",
      "/Trey_Hollingsworth\n",
      "/Mike_Doyle_(American_politician)\n",
      "/John_A._Sullivan_(Oklahoma_politician)\n",
      "/Alex_Mooney\n",
      "/Jared_Huffman\n",
      "/Richard_L._Hanna\n",
      "/Susan_Wild\n",
      "/Katie_Hill_(politician)\n",
      "/Brad_Sherman\n",
      "/Chris_Collins_(New_York_politician)\n",
      "/Ashley_Hinson\n",
      "/Steve_Austria\n",
      "/Stephen_Fincher\n",
      "/Steve_Daines\n",
      "/Mark_Critz\n",
      "/John_Boehner\n",
      "/Albio_Sires\n",
      "/Paul_Cook_(politician)\n",
      "/Tom_McClintock\n",
      "/Dan_Burton\n",
      "/Dan_Benishek\n",
      "/Lloyd_Doggett\n",
      "/Mariannette_Miller-Meeks\n",
      "/Mar%C3%ADa_Elvira_Salazar\n",
      "/Ileana_Ros-Lehtinen\n",
      "/Gregorio_Sablan\n",
      "/Brendan_Boyle\n",
      "/Ted_Lieu\n",
      "/Dennis_Kucinich\n",
      "/Tim_Johnson_(South_Dakota_politician)\n",
      "/Dan_Newhouse\n",
      "/Blake_Moore\n",
      "/Mike_Turner\n",
      "/Linda_S%C3%A1nchez\n",
      "/Tom_Garrett_(Virginia_politician)\n",
      "/Katherine_Clark\n",
      "/Todd_Russell_Platts\n",
      "/Liz_Cheney\n",
      "/Jeff_Duncan_(politician)\n",
      "/Scott_Garrett\n",
      "/Billy_Long\n",
      "/Jeffrey_Chiesa\n",
      "/Mike_Rogers_(Alabama_politician)\n",
      "/Phil_Gingrey\n",
      "/David_Young_(Iowa_politician)\n",
      "/Bob_Casey_Jr.\n",
      "/Joe_Neguse\n",
      "/Rick_Scott\n",
      "/John_Olver\n",
      "/Mitt_Romney\n",
      "/Jane_Harman\n",
      "/Gabby_Giffords\n",
      "/John_Hickenlooper\n",
      "/Scott_Taylor_(politician)\n",
      "/Lisa_Blunt_Rochester\n",
      "/Karen_Bass\n",
      "/Glenn_Thompson_(politician)\n",
      "/Dave_Brat\n",
      "/John_Rose_(Tennessee_politician)\n",
      "/Sean_Patrick_Maloney\n",
      "/Danny_K._Davis\n",
      "/Marjorie_Taylor_Greene\n",
      "/Burgess_Owens\n",
      "/Mike_Pence\n",
      "/Ami_Bera\n",
      "/Rodney_Alexander\n",
      "/Russ_Fulcher\n",
      "/Nikema_Williams\n",
      "/Mark_Walker_(North_Carolina_politician)\n",
      "/Orrin_Hatch\n",
      "/Tulsi_Gabbard\n",
      "/Mike_Gallagher_(American_politician)\n",
      "/Sherrod_Brown\n",
      "/Tom_Petri\n",
      "/Joyce_Beatty\n",
      "/Michael_Waltz\n",
      "/John_Faso\n",
      "/Angie_Craig\n",
      "/August_Pfluger\n",
      "/Nanette_Barrag%C3%A1n\n",
      "/Steve_Russell_(politician)\n",
      "/Steve_Watkins\n",
      "/Frank_J._Mrvan\n",
      "/Julia_Brownley\n",
      "/Mo_Brooks\n",
      "/Larry_Bucshon\n",
      "/Donna_Christian-Christensen\n",
      "/Lois_Capps\n",
      "/Ro_Khanna\n",
      "/Cathy_McMorris_Rodgers\n",
      "/Richard_Burr\n",
      "/Deb_Fischer\n",
      "/Mark_Amodei\n",
      "/Jeff_Sessions\n",
      "/Brad_Miller_(politician)\n",
      "/Jim_Risch\n",
      "/Kerry_Bentivolio\n",
      "/Roger_Williams_(American_politician)\n",
      "/Tim_Walz\n",
      "/Nydia_Vel%C3%A1zquez\n",
      "/Matt_Gaetz\n",
      "/Silvestre_Reyes\n",
      "/Shelley_Berkley\n",
      "/Tom_Harkin\n",
      "/Doug_Collins_(politician)\n",
      "/Bill_Pascrell\n",
      "/Greg_Pence\n",
      "/Josh_Hawley\n",
      "/Kay_Granger\n",
      "/Rob_Portman\n",
      "/Carolyn_McCarthy\n",
      "/Jim_Jordan_(American_politician)\n",
      "/Donna_Edwards\n"
     ]
    }
   ],
   "source": [
    "for i in (congress.get_all_officials()): print(i)\n",
    "# c = search.get_congress(l[0])\n",
    "# for i in c.get_everyone():\n",
    "#     print(i)\n",
    "#     print()\n",
    "\n",
    "# souther constants.CANONICAL_NAME_TO_WIKIPEIDA_PROBLEMATIC_CONVERSATIONS\n",
    "\n",
    "# print(c.get_house_party())\n",
    "\n",
    "# print(c.get_senate_party())\n",
    "\n",
    "# {'Republican': 242, 'Democratic': 205, 'Libertarian': 1, '': 3}\n",
    "# {'Republican': 49, 'Democratic': 52, '': 1, 'Independent': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, input_df = dir_utils.get_data(combined=True)\n",
    "\n",
    "# These are names. \n",
    "input_all_officials = set()\n",
    "input_house_officials = set()\n",
    "input_senate_officials = set()\n",
    "\n",
    "for _,t in input_df.iterrows():        \n",
    "    name = official.get_canonical_name(t[constants.SENATOR]) if ptr_utils.isvalid(t[constants.SENATOR]) else official.get_canonical_name(t[constants.REPRESENTATIVE])\n",
    "    input_house_officials.add(name) if ptr_utils.isvalid(t[constants.REPRESENTATIVE]) else input_senate_officials.add(name)\n",
    "    input_all_officials.add(name)\n",
    "    \n",
    "print(\"Number of officials in input dataset: {}\".format(len(input_all_officials)))\n",
    "print(\"Number of representatives in input dataset: {}\".format(len(input_house_officials)))\n",
    "print(\"Number of senators in input dataset: {}\".format(len(input_senate_officials)))\n",
    "\n",
    "input_house_officials_objects = []\n",
    "for person in input_house_officials: \n",
    "    off = search.wiki_search(person)        \n",
    "    input_house_officials_objects.append(off)\n",
    "    \n",
    "input_senate_officials_objects = []\n",
    "for person in input_senate_officials:\n",
    "    off = search.wiki_search(person)        \n",
    "    input_senate_officials_objects.append(off)\n",
    "\n",
    "input_all_officials_objects = input_house_officials_objects + input_senate_officials_objects\n",
    "\n",
    "l = list(range(112, 118))\n",
    "all_officials = set()\n",
    "house_officials = set()\n",
    "senate_officials = set()\n",
    "\n",
    "all_officials = congress.get_all_officials()\n",
    "house_officials = congress.get_house_officials()\n",
    "senate_officials = congress.get_senate_officials()\n",
    "\n",
    "congress_objects = []\n",
    "for i in l:\n",
    "    c = search.get_congress(i)\n",
    "    congress_objects.append(c)\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "# print(\"Number of officials in total (from 112-117th congress): {}\".format(len(all_officials)))\n",
    "# print(\"Number of officials in input dataset/Number of officials in total (from 112-117th congress): {}\".format(ptr_utils.make_percent(len(input_all_officials), len(all_officials))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oldest Dates (transaction and disclosure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_dates():\n",
    "    lowest_tdate = lowest_ddate = None \n",
    "    highest_tdate = highest_ddate = None \n",
    "    \n",
    "    for _,t in input_df.iterrows():\n",
    "        curr = ptr_utils.format_date(t[constants.TDATE])            \n",
    "        if not lowest_tdate or curr < lowest_tdate:\n",
    "            lowest_tdate = curr \n",
    "        if not highest_tdate or curr > highest_tdate:\n",
    "            highest_tdate = curr  \n",
    "\n",
    "        curr = ptr_utils.format_date(t[constants.DDATE])\n",
    "        if not lowest_ddate or curr < lowest_ddate:\n",
    "            lowest_ddate = curr \n",
    "        if not highest_ddate or curr > highest_ddate:\n",
    "            highest_ddate = curr \n",
    "            \n",
    "\n",
    "    print(\"Oldest transaction_date: {}\".format(lowest_tdate))\n",
    "    print(\"Most recent transaction_date: {}\".format(highest_tdate))\n",
    "    \n",
    "    print(\"Oldest disclosure_date: {}\".format(lowest_ddate))\n",
    "    print(\"Most recent disclosure_date: {}\".format(highest_ddate))\n",
    "    \n",
    "\n",
    "profile_dates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gender(group, filename):\n",
    "    # d_prime = {'Female' : set(Officials), 'Male' : set(Officials), ...}\n",
    "    d_prime = {}\n",
    "\n",
    "    for o in group: \n",
    "        gender = official.get_gender(o)\n",
    "            \n",
    "        # there is a bug here, bc total should be enough to cover input,senate,house but it isnt\n",
    "            \n",
    "        d_prime = dict_utils.increment_set_in_dictionary(d_prime, gender, o)\n",
    "\n",
    "    # d = {'Female' : #_of_officials, 'Male' : #_of_officials, ...}\n",
    "    d = dict_utils.flatten_len(d_prime, inner_set=True)\n",
    "    \n",
    "    d = dict_utils.sort_dictionary_by_values(d)\n",
    "    \n",
    "    key_header = constants.GENDER\n",
    "    value_header = \"number_of_officials\"\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "    csv_utils.make_csv(dir, filename, d, [key_header, value_header])\n",
    "    return \n",
    "\n",
    "get_gender(all_officials, \"num_of_off_per_gender_TOTAL\")\n",
    "get_gender(input_all_officials, \"num_of_off_per_gender_INPUT\")\n",
    "get_gender(input_senate_officials, \"num_of_off_per_gender_senate\")\n",
    "get_gender(input_house_officials, \"num_of_off_per_gender_house\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_party(group, filename):\n",
    "    # d_prime = {'Republican' : set(Officials), 'Democrat' : set(Officials), ...}\n",
    "        d_prime = {}\n",
    "        \n",
    "        for off_obj in group: \n",
    "            d_prime = dict_utils.increment_set_in_dictionary(d_prime, off_obj.party, off_obj.name)\n",
    "            \n",
    "        # d = {'Republican' : #_of_officials, 'Democrat' : #_of_officials, ...}\n",
    "        d = dict_utils.flatten_len(d_prime, inner_set=True)\n",
    "                \n",
    "        d = dict_utils.sort_dictionary_by_values(d)\n",
    "        \n",
    "        key_header = constants.PARTY\n",
    "        value_header = \"number_of_officials\"\n",
    "\n",
    "        dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "        csv_utils.make_csv(dir, filename, d, [key_header, value_header])\n",
    "\n",
    "        return \n",
    "\n",
    "profile_party(input_all_officials_objects, \"num_of_off_per_party_INPUT\")\n",
    "profile_party(input_senate_officials_objects, \"num_of_off_per_party_SENATE\")\n",
    "profile_party(input_house_officials_objects, \"num_of_off_per_party_HOUSE\")\n",
    "\n",
    "def profile_party_total():\n",
    "   \n",
    "    # d = {'Republican' : #_of_officials, 'Democrat' : #_of_officials, ...}\n",
    "    d = {}\n",
    "    for c in congress_objects:\n",
    "        for k,v in c.senate_party.items():\n",
    "            d = dict_utils.increment_dictionary(d, k, v)\n",
    "        for k,v in c.house_party.items():\n",
    "            d = dict_utils.increment_dictionary(d, k, v)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_values(d)\n",
    "    \n",
    "    key_header = constants.PARTY\n",
    "    value_header = \"number_of_officials\"\n",
    "    filename = \"num_of_off_per_party_TOTAL\"\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "    csv_utils.make_csv(dir, filename, d, [key_header, value_header])\n",
    "\n",
    "    return \n",
    "\n",
    "profile_party_total()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for o in officials:\n",
    "#     name = o \n",
    "#     if o not in all_officials:\n",
    "#         CANONICAL_TO_WIKIPEDIA_PROBLEMATIC_CONVERSIONS = {'Mcconnell Jr., A. M.' : 'McConnell, Mitch', 'Casey Jr., Robert P.' : 'Casey Jr., Bob', 'Gallagher, Michael J.' : 'Gallagher, Mike'}\n",
    "        \n",
    "#         if o not in CANONICAL_TO_WIKIPEDIA_PROBLEMATIC_CONVERSIONS:\n",
    "#             s = search.get_wiki_page(o)\n",
    "#             s = s[s.find(\"name \") + 4  : ]\n",
    "#             s = s[ : s.find(\"|\")].replace(\"=\", \"\").strip()\n",
    "\n",
    "#             if \" or \" in s: \n",
    "#                 s = s.split(\" or \")[1]\n",
    "                \n",
    "#             wikified = official.get_canonical_name(s)\n",
    "#             if wikified not in all_officials:\n",
    "#                 if name[len(name)-1] == \".\":\n",
    "#                     without_initial = name[:len(name)-3].strip()\n",
    "#                     if without_initial not in all_officials:\n",
    "#                         print(o)\n",
    "#                         # break \n",
    "#         else:\n",
    "#             o = CANONICAL_TO_WIKIPEDIA_PROBLEMATIC_CONVERSIONS[o]\n",
    "#             if o not in all_officials:\n",
    "#                 print(o)\n",
    "                \n",
    "# # i need a set difference\n",
    "\n",
    "\n",
    "# # have all the unique officials \n",
    "# # need to somehow use canonical n\n",
    "    \n",
    "\n",
    "\n",
    "# x = (sorted(all_officials))\n",
    "# for i in x: print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_state():\n",
    "    \n",
    "    # d_prime = {'Maryland' : set(Officials), 'California' : set(Officials), ...}\n",
    "    d_prime = {}\n",
    "    \n",
    "    for off_obj in input_all_officials_objects: \n",
    "        d_prime = dict_utils.increment_set_in_dictionary(d_prime, off_obj.state, off_obj.name)\n",
    "\n",
    "    # d = {'Maryland' : #_of_officials, 'California' : #_of_officials, ...}\n",
    "    d = dict_utils.flatten_len(d_prime, inner_set=True)\n",
    "    \n",
    "    d = dict_utils.sort_dictionary_by_values(d)\n",
    "    \n",
    "    filename = \"num_of_off_per_state\"\n",
    "    key_header = constants.STATE\n",
    "    value_header = \"number_of_officials\"\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    \n",
    "    print(\"Number of states represented: {}\".format(len(d)))\n",
    "\n",
    "profile_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seniority (Lowest, Highest, Average?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_seniority():\n",
    "    # d = {x_years_in_congress, y_years_in_congres, ...}\n",
    "    l = []\n",
    "    \n",
    "    for off_obj in input_all_officials_objects: \n",
    "        l.append(off_obj.get_seniority())\n",
    "    \n",
    "    l.sort()\n",
    "    \n",
    "    print(\"Lowest Seniority: {}\".format(l[0]))\n",
    "    print(\"Average Seniority: {}\".format((sum(l) / len(l))))\n",
    "    print(\"Highest Seniority: {}\".format(l[len(l)-1]))\n",
    "    \n",
    "profile_seniority()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get_Congress (Lowest, Highest, Average?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_congress():\n",
    "    lowest = highest = None \n",
    "    \n",
    "    for off_obj in input_all_officials_objects:\n",
    "        res = off_obj.get_congress()\n",
    "        \n",
    "        if not lowest or res[0] < lowest:\n",
    "            lowest = res[0]\n",
    "    \n",
    "        if not highest or res[len(res) - 1] > highest:\n",
    "            highest = res[len(res) - 1]\n",
    "                    \n",
    "    print(\"Lowest Congress: {}\".format(lowest))\n",
    "    print(\"Highest Congress: {}\".format(highest))\n",
    "    \n",
    "                        \n",
    "profile_congress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Degrees (Lowest, Highest, Average?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_degrees():\n",
    "    # d = {x_degrees, y_degrees, ...}\n",
    "    l = []\n",
    "    \n",
    "    for off_obj in input_all_officials_objects: \n",
    "        l.append(off_obj.get_num_of_degrees())\n",
    "    \n",
    "    l.sort()\n",
    "    \n",
    "    print(\"Lowest Number of Degrees: {}\".format(l[0]))\n",
    "    print(\"Average Number of Degrees: {}\".format((sum(l) / len(l))))\n",
    "    print(\"Highest Number of Degrees: {}\".format(l[len(l)-1]))\n",
    "    \n",
    "profile_degrees()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JD (Average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_JD():\n",
    "    # d = {x_degrees, y_degrees, ...}\n",
    "    yes = total = 0 \n",
    "    \n",
    "    for off_obj in input_all_officials_objects: \n",
    "        if off_obj.has_JD():\n",
    "            yes += 1 \n",
    "        total += 1 \n",
    "            \n",
    "    print(\"Percant that have JDs: {}%\".format(ptr_utils.make_percent(yes, total))\n",
    "    \n",
    "profile_JD()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transaction Date (transaction_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each sector. TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_sector():\n",
    "\n",
    "    # d_prime = {'sector' : {'date' : #_of_transactions, ....} , 'sector2' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in input_df.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            sector = dir_utils.get_sector(t[constants.TICKER])            \n",
    "            d_prime = dict_utils.increment_dictionary_in_dictionary(d_prime, sector, ptr_utils.format_date(t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten(d_prime)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    filename = \"most_popular_td_fe_sector\"\n",
    "    key_header = constants.SECTOR\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "transaction_date_wrt_sector_res = transaction_date_wrt_sector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each sector controlling for each official. TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_sector_controlled():\n",
    "\n",
    "    # d_prime = { ('ticker' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "    d_prime = {}\n",
    "\n",
    "    \n",
    "    for _,t in input_df.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            industry = dir_utils.search_mapping(sector_df, t[constants.TICKER], sector=True)\n",
    "            \n",
    "            \n",
    "            d_prime = dict_utils.increment_set_in_dictionary(d_prime, industry, ptr_utils.format_date(t[constants.TDATE]), official.get_canonical_name(t[title]))\n",
    "       \n",
    "\n",
    "    for ticker in d_prime:\n",
    "        for date in d_prime[ticker]:\n",
    "            d_prime[ticker][date] = len(d_prime[ticker][date])\n",
    "            \n",
    "    \n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten(d_prime)\n",
    "\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    \n",
    "    filename = \"most_popular_td_fe_sector_controlled\"\n",
    "    key_header = constants.SECTOR\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "transaction_date_wrt_sector_controlled_res = transaction_date_wrt_sector_controlled()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each industry. TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_industry():\n",
    "    \n",
    "    # d_prime = {'industry' : {'date' : #_of_transactions, ....} , 'industry2' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in input_df.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            industry = dir_utils.search_mapping(industry_df, t[constants.TICKER])\n",
    "\n",
    "            d_prime = dict_utils.increment_dictionary_in_dictionary(d_prime, industry, ptr_utils.format_date(t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten(d_prime)\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    filename = \"most_popular_td_fe_industry\"\n",
    "    key_header = constants.INDUSTRY\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "transaction_date_wrt_industry_res = transaction_date_wrt_industry()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each industry controlling for official. TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_industry_controlled():\n",
    "    \n",
    "    # d_prime = { ('ticker' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "    d_prime = {}\n",
    "\n",
    "    \n",
    "    for _,t in input_df.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            industry = dir_utils.search_mapping(industry_df, t[constants.TICKER])\n",
    "            \n",
    "            d_prime = dict_utils.increment_set_in_dictionary(d_prime, industry, ptr_utils.format_date(t[constants.TDATE]), official.get_canonical_name(t[title]))\n",
    "       \n",
    "\n",
    "    for ticker in d_prime:\n",
    "        for date in d_prime[ticker]:\n",
    "            d_prime[ticker][date] = len(d_prime[ticker][date])\n",
    "            \n",
    "    \n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten(d_prime)\n",
    "\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "    \n",
    "    \n",
    "    filename = \"most_popular_td_fe_industry_controlled\"\n",
    "    key_header = constants.INDUSTRY\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "transaction_date_wrt_industry_controlled_res = transaction_date_wrt_industry_controlled()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each ticker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_ticker():\n",
    "        \n",
    "    # d_prime = {'ticker' : {'date' : #_of_transactions, ....} , 'ticker2' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in input_df.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime = dict_utils.increment_dictionary_in_dictionary(d_prime, t[constants.TICKER], ptr_utils.format_date(t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten(d_prime)\n",
    "\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    filename = \"most_popular_td_fe_ticker\"\n",
    "    key_header = constants.TICKER\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "transaction_date_wrt_ticker_res = transaction_date_wrt_ticker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each ticker controlling for official."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_ticker_controlled():\n",
    "    # d_prime = { ('ticker' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "    d_prime = {}\n",
    "    \n",
    "    # search.wiki_search(\"Chabot, Steve\").check()\n",
    "    names = set()\n",
    "    for _,t in input_df.iterrows():\n",
    "        \n",
    "    #     # name = official.get_canonical_name(t[constants.SENATOR]) if ptr_utils.isvalid(t[constants.SENATOR]) else official.get_canonical_name(t[constants.REPRESENTATIVE])\n",
    "        \n",
    "        name = official.get_canonical_name(t[constants.SENATOR]) if ptr_utils.isvalid(t[constants.SENATOR]) else official.get_canonical_name(t[constants.REPRESENTATIVE])\n",
    "        names.add(name)\n",
    "    \n",
    "    # john, rutherford \n",
    "    \n",
    "    for i in names:\n",
    "        print(i)\n",
    "        print(search.wiki_search(i).check())\n",
    "        print()\n",
    "        # break\n",
    "\n",
    "    #     print(search.wiki_search(i).check())\n",
    "    #     print()\n",
    "        \n",
    "    #     d_prime = dict_utils.increment_set_in_dictionary(d_prime, t[constants.TICKER], ptr_utils.format_date(t[constants.TDATE]), name)\n",
    "       \n",
    "    # for ticker in d_prime:\n",
    "    #     for date in d_prime[ticker]:\n",
    "    #         d_prime[ticker][date] = len(d_prime[ticker][date])\n",
    "            \n",
    "    \n",
    "    # # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "    # d = dict_utils.flatten(d_prime)\n",
    "    # d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    \n",
    "    # filename = \"most_popular_td_fe_ticker_controlled\"\n",
    "    # key_header = constants.TICKER\n",
    "    # value_header = constants.TDATE\n",
    "    # value_header2 = constants.NUMT\n",
    "\n",
    "    # dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    # wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    # df = pd.read_csv(wd)\n",
    "    # print(df.head(5))\n",
    "    # return d \n",
    "\n",
    "transaction_date_wrt_ticker_controlled_res = transaction_date_wrt_ticker_controlled()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_type():\n",
    "        \n",
    "    # d_prime = {'type' : {'date' : #_of_transactions, ....} , 'type2' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in input_df.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime = dict_utils.increment_dictionary_in_dictionary(d_prime, ptr_utils.format_type(t[constants.TYPE]), ptr_utils.format_date(t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'type' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten(d_prime)\n",
    "\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    filename = \"most_popuar_td_for_type\"\n",
    "    key_header = constants.TYPE\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df)\n",
    "    return d \n",
    "\n",
    "transaction_date_wrt_type_res = transaction_date_wrt_type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for type controlling for official. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_type_controlled():\n",
    "    \n",
    "    # d_prime = { ('type' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "    d_prime = {}\n",
    "\n",
    "    \n",
    "    for _,t in input_df.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime = dict_utils.increment_set_in_dictionary(d_prime, t[constants.TYPE], ptr_utils.format_date(t[constants.TDATE]), official.get_canonical_name(t[title]))\n",
    "       \n",
    "\n",
    "    for ticker in d_prime:\n",
    "        for date in d_prime[ticker]:\n",
    "            d_prime[ticker][date] = len(d_prime[ticker][date])\n",
    "            \n",
    "    \n",
    "    # d = {'type' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten(d_prime)\n",
    "\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "    \n",
    "    \n",
    "    filename = \"most_popular_td_fe_type_controlled\"\n",
    "    key_header = constants.TYPE\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "transaction_date_wrt_type_controlled_res = transaction_date_wrt_type_controlled()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_amount():\n",
    "    # d_prime = {'amount' : {'date' : #_of_transactions, ....} , 'amount1' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in input_df.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime = dict_utils.increment_dictionary_in_dictionary(d_prime, t[constants.AMOUNT], ptr_utils.format_date(t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'type' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten(d_prime)\n",
    "\n",
    "    d = dict_utils.add_sort_key_for_amount(d)\n",
    "    d = dict_utils.sort_dictionary_by_sort_key(d)\n",
    "\n",
    "    filename = \"most_popuar_td_for_amount\"\n",
    "    key_header = constants.TYPE\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, key_header)\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "transaction_date_wrt_amount_res = transaction_date_wrt_amount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for amount controlling for official."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_amount_controlled():\n",
    "\n",
    "    # d_prime = { ('amount' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "    d_prime = {}\n",
    "\n",
    "    \n",
    "    for _,t in rows:\n",
    "       d_prime = dict_utils.increment_set_in_dictionary(d_prime, t[constants.AMOUNT], ptr_utils.format_date(t[constants.TDATE]), official.get_canonical_name(t[title]))\n",
    "       \n",
    "\n",
    "    for ticker in d_prime:\n",
    "        for date in d_prime[ticker]:\n",
    "            d_prime[ticker][date] = len(d_prime[ticker][date])\n",
    "            \n",
    "    \n",
    "    # d = {'amount' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten(d_prime)\n",
    "\n",
    "    d = dict_utils.add_sort_key_for_amount(d)\n",
    "    d = dict_utils.sort_dictionary_by_sort_key(d)\n",
    "    \n",
    "    \n",
    "    filename = \"most_popular_td_fe_amount_controlled\"\n",
    "    key_header = constants.AMOUNT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, key_header                                                                                                                                                                                                                                      )\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "transaction_date_wrt_amount_controlled_res = transaction_date_wrt_amount_controlled()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each official."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_date_wrt_official():\n",
    "\n",
    "    # d_prime = {'person1' : {'date' : #_of_transactions, ....} , 'person2' : .... }\n",
    "    d_prime = {}\n",
    "    \n",
    "    for _,t in input_df.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "            d_prime = dict_utils.increment_dictionary_in_dictionary(d_prime, official.get_canonical_name(t[title]), ptr_utils.format_date(t[constants.TDATE]))\n",
    "       \n",
    "    # d = {'person' : {'best_date' : #_of_transactions}, .... }\n",
    "    d = dict_utils.flatten(d_prime)\n",
    "\n",
    "\n",
    "    d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    filename = \"most_popular_td_fe_official\"\n",
    "    key_header = title\n",
    "    value_header = constants.TDATE\n",
    "    value_header2 = constants.NUMT\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "transaction_date_wrt_official_res = transaction_date_wrt_official()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The average amount size of transactions (i.e., activity) for each transaction_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dates_and_size_of_amount():\n",
    "\n",
    "    d={}\n",
    "    \n",
    "    for _, t in input_df.iterrows():\n",
    "        if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "            \n",
    "            # if 'Purchase' in transaction['type']:\n",
    "                \n",
    "            # if 'Sale' in transaction['type']:\n",
    "            d = dict_utils.increment_dictionary_in_dictionary(d, ptr_utils.format_date(t[constants.TDATE]), ptr_utils.average_amount(t[constants.AMOUNT]))\n",
    "\n",
    "\n",
    "    d2 = {}\n",
    "    for date in d:\n",
    "        l = []\n",
    "        for amount in d[date]:   \n",
    "            l.append(d[date][amount]*amount)\n",
    "            \n",
    "        d2[date] = l \n",
    "        \n",
    "        \n",
    "    for date in d2:\n",
    "        d2[date] = int(gmean(d2[date]))\n",
    "    \n",
    "    filename = \"dates_and_size_of_amount\"\n",
    "    key_header = \"date\" \n",
    "    value_header = \"average_size_of_transactions\"\n",
    "\n",
    "    d2 = dict_utils.sort_dictionary_by_values(d2)\n",
    "    d2 = dict_utils.commify(d2)\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d2, [key_header, value_header])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "\n",
    "    return d2 \n",
    "\n",
    "dates_and_size_of_amount_res = dates_and_size_of_amount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Person by Date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_per_person_per_date():    \n",
    "\n",
    "    d={}\n",
    "\n",
    "    for _, t in input_df.iterrows():\n",
    "        d = dict_utils.increment_dictionary_in_dictionary(d, official.get_canonical_name(t[title]), ptr_utils.format_date(t[constants.TDATE]))\n",
    "\n",
    "    filename = \"num_of_trans_per_person_per_date\"\n",
    "    \n",
    "    \n",
    "    # some sort of error \n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv_breakdown(dir, filename, d, title)\n",
    "    print(pd.read_csv(wd).head(5))\n",
    "\n",
    "num_of_trans_per_person_per_date()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_per_person_per_date():\n",
    "\n",
    "    d={}\n",
    "\n",
    "    for _, t in input_df.iterrows():\n",
    "        d = dict_utils.increment_dictionary(d, ptr_utils.format_date(t[constants.TDATE]))\n",
    "        \n",
    "\n",
    "    filename = \"num_of_trans_per_person_per_date\"\n",
    "    key_header = \"date\"\n",
    "    value_header = \"number_of_transactions\"\n",
    "    \n",
    "    d = dict_utils.sort_dictionary_by_values(d)\n",
    "    \n",
    "    dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "    wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header])\n",
    "    # fig = graph_csv(dir, path_html, filename, key_header, value_header)\n",
    "    # fig.show()\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "\n",
    "trans_per_person_per_date_res = num_of_trans_per_person_per_date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Transactions per Date Controlled\n",
    "_Number of transactions per date controlled by official. E.g. if Ted Baker made 40 transactions on 1/1/02 and Sam Wall made 2 transactions on 1/1/02, we conclude that there were two transactions on 1/1/02._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_per_date_controlled():\n",
    "\n",
    "    d = {}\n",
    "\n",
    "    for _, t in input_df.iterrows():\n",
    "        d = dict_utils.increment_dictionary_in_dictionary(d, ptr_utils.format_date(t[constants.TDATE]), official.get_canonical_name(t[title]))\n",
    "    \n",
    "    d2 = {}\n",
    "    for date in d:\n",
    "        d2[date] =  len(d[date])\n",
    "        \n",
    "    d2 = dict_utils.sort_dictionary_by_values(d2)\n",
    "        \n",
    "    filename = \"num_of_trans_per_date_controlled\"\n",
    "    key_header = \"date\"\n",
    "    value_header = \"number_of_transactions_unique\"\n",
    "\n",
    "\n",
    "    dir = dir_utils.makesubdir(constants.path_csv, \"transaction_date\")\n",
    "    wd = csv_utils.make_csv(dir, filename, d2, [key_header, value_header])\n",
    "    # fig = graph_csv(dir, path_html, filename, key_header, value_header, scatter=True)\n",
    "    # fig.show()\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "    return d \n",
    "    \n",
    "num_of_trans_per_date_controlled_res = num_of_trans_per_date_controlled()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tax (not touched.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Transactions Within 2 Weeks Prior to Quarterly Tax Date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i should like type of transactions @TODO. \n",
    "\n",
    "def num_of_trans_within_tax_date(rows):\n",
    "        total = within = 0 \n",
    "        \n",
    "        for k,v in rows.items():  \n",
    "                total += 1 \n",
    "                if ptr_utils.within_tax_date(k):\n",
    "                        within += v \n",
    "\n",
    "        print(\"Percent of transactions posted within two weeks of quarterly tax deadline: {percent}%\".format(percent=str((within/total)*100)[:5]))\n",
    "        return (within/total)*100\n",
    "\n",
    "frac = num_of_trans_within_tax_date(trans_per_person_per_date_res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Transactions Within 2 Weeks Prior to Quarterly Tax Date Semi-Controlled \n",
    "\n",
    "_Given dict='09/03/2021': {'Thomas H Tuberville': 1, 'Cynthia M Lummis': 1, 'A. Mitchell Mcconnell, Jr.': 1}...I only incremement the number of within (tax date) once per date per official. So, if an official does 100 transactions on a date within two weeks of a quarterly deadline, then I only count it as one transaction._\n",
    "\n",
    "_A Note: total === number of transactions per person per date (so not really all transactions) because someone could have potentially made 60 transactions on one date which we don't include in neither total or within, if applicable._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_within_tax_date_controlled(rows):\n",
    "        total = within = 0 \n",
    "        people = set()\n",
    "\n",
    "        for date, inner_dict in rows.items():\n",
    "                if ptr_utils.within_tax_date(date):\n",
    "                    for person in inner_dict:\n",
    "                                people.add(person)\n",
    "                                within += 1 \n",
    "                                total += 1 \n",
    "                else:\n",
    "                        for person in inner_dict:\n",
    "                                total += 1 \n",
    "     \n",
    "     \n",
    "        print(\"Percent of transactions posted within two weeks of quarterly tax deadline: {percent}%\".format(percent=str((within/total)*100)[:5]))\n",
    "        return people\n",
    "\n",
    "num_of_trans_within_tax_date_controlled_res = num_of_trans_within_tax_date_controlled(num_of_trans_per_date_controlled_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import sort_dictionary_by_keys\n",
    "\n",
    "def people_and_within_tax_date(people):        \n",
    "        # todo get number of senators. \n",
    "        # todo is the monetary value of that equal!!!! \n",
    "        d = {}\n",
    "        for i in people:\n",
    "                d[i] = \"\"\n",
    "                \n",
    "        d = dict_utils.sort_dictionary_by_keys(d)\n",
    "        \n",
    "        dir = dir_utils.makesubdir(path_csv, \"transaction_date/tax\")\n",
    "        wd = csv_utils.make_csv(dir, \"people_and_within_tax_date_list\", d, [\"Officials\"])\n",
    "        df = pd.read_csv(wd)\n",
    "        print(\"People who posted transactions within two weeks of quarterly tax deadline:\\n {}\\n\".format(df.head(5)))\n",
    "\n",
    "        print(\"Number of people who posted transactions within two weeks of quarterly tax deadline: {}\\n\".format(len(people)))\n",
    "        \n",
    "        party = {}\n",
    "        for p in people:\n",
    "                party = dict_utils.increment_dictionary(party, search.wiki_search(p).get_party())\n",
    "                \n",
    "        party = dict_utils.sort_dictionary_by_values(party)\n",
    "        \n",
    "        wd = csv_utils.make_csv(dir, \"people_and_within_tax_date_list_w_aff\", party, [\"party\", \"number_of_filing_within_tax_date\"])\n",
    "        df = pd.read_csv(wd)\n",
    "        print(\"Party breakdown of people who posted transactions within two weeks of quarterly tax deadline:\\n {}\\n\".format(df.head(5)))\n",
    "\n",
    "people_and_within_tax_date(num_of_trans_within_tax_date_controlled_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def people_and_within_tax_date_how_often(people):\n",
    "\n",
    "        d = {}\n",
    "        d_controlled_by_dates = {}\n",
    "        \n",
    "        for _, t in input_df.iterrows():\n",
    "                if official.get_canonical_name(t[title]) in people and ptr_utils.within_tax_date(t[constants.TDATE]):\n",
    "                        d = dict_utils.increment_dictionary(d, t[title])\n",
    "                        d_controlled_by_dates = dict_utils.increment_dictionary_in_dictionary(d_controlled_by_dates, t[constants.TDATE], t[title])\n",
    "\n",
    "        d_controlled_by_dates_res  = {}\n",
    "        for date in d_controlled_by_dates:\n",
    "                for person in d_controlled_by_dates[date]:\n",
    "                        d_controlled_by_dates_res = dict_utils.increment_dictionary(d_controlled_by_dates_res, person)\n",
    "\n",
    "        d = dict_utils.sort_dictionary_by_values(d)\n",
    "        d_controlled_by_dates_res = dict_utils.sort_dictionary_by_values(d_controlled_by_dates_res)\n",
    "\n",
    "        dir = dir_utils.makesubdir(constants.path_csv, \"transaction_date/tax\")\n",
    "        wd = csv_utils.make_csv(dir, \"people_and_within_tax_date_how_often\", d, [title, \"number_of_filing_within_tax_date\"])\n",
    "        df = pd.read_csv(wd)\n",
    "        print(\"People who posted transactions within two weeks of quarterly tax deadline and the number of transactions posted:\\n {}\\n\".format(df.head(5)))\n",
    "\n",
    "        wd = csv_utils.make_csv(dir, \"people_and_within_tax_date_how_often_date_controlled\", d_controlled_by_dates_res, [title, \"number_of_filing_within_tax_date_date_controlled\"])\n",
    "        df = pd.read_csv(wd)\n",
    "        print(\"People who posted transactions within two weeks of quarterly tax deadline and the number of transactions posted controlled by date:\\n {}\\n\".format(df.head(5)))\n",
    "\n",
    "          \n",
    "people_and_within_tax_date_how_often(num_of_trans_within_tax_date_controlled_res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Owner (owner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ticker (ticker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Ticker per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_ticker_breakdown_ticker():\n",
    "    d = {}\n",
    "\n",
    "\n",
    "    for _, transaction in input_df.iterrows():\n",
    "        if isvalid(transaction['ticker']):\n",
    "            d = increment_dictionary_in_dictionary(d, transaction['ticker'], get_year(transaction['transaction_date']))\n",
    "            d = increment_dictionary_in_dictionary(d, transaction['ticker'], \"Total\")\n",
    "\n",
    "    d = sort_dictionary_by_keys(d)\n",
    "    \n",
    "    filename = \"trans_per_year_breakdown\"\n",
    "    key_header = \"ticker\"\n",
    "    \n",
    "    \n",
    "    dir = makesubdir(path_csv, \"ticker\")\n",
    "    wd = make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "\n",
    "frequency_of_ticker_breakdown_ticker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Ticker per Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_year, increment_dictionary_in_dictionary, path_csv\n",
    "from csv_utils import make_csv_breakdown\n",
    "\n",
    "def frequency_of_ticker_by_date():\n",
    "    d = {}\n",
    "\n",
    "    \n",
    "    for _, transaction in rows:\n",
    "        if isvalid(transaction['ticker']):\n",
    "            d = increment_dictionary_in_dictionary(d, transaction['ticker'], transaction['transaction_date'])\n",
    "\n",
    "    filename = \"frequency_of_ticker_by_date\"\n",
    "    key_header = \"ticker\"\n",
    "    \n",
    "    dir = makesubdir(path_csv, \"ticker\")\n",
    "    wd = make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "\n",
    "frequency_of_ticker_by_date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Industry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Transactions per Industry\n",
    "_Not controlled in any way._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_transactions_per_indusry():        \n",
    "    d = {}\n",
    "\n",
    "    df = get_mapping()\n",
    "    \n",
    "    for _, transaction in rows:\n",
    "        ticker = transaction['ticker']\n",
    "        industry = search_mapping(df, ticker)\n",
    "        if industry: \n",
    "            d = increment_dictionary(d, industry)\n",
    "\n",
    "    filename = \"number_of_transactions_per_indusry\"\n",
    "    key_header = \"industry\"\n",
    "    value_header = \"number_of_transactions\"\n",
    "\n",
    "    d = sort_dictionary_by_values(d)\n",
    "    \n",
    "    dir = makesubdir(path_csv, \"ticker/industry\")\n",
    "    wd = make_csv(dir, filename, d, [key_header, value_header])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))    \n",
    "    \n",
    "    return d \n",
    "\n",
    "number_of_transactions_per_indusry_res = number_of_transactions_per_indusry()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Industry Breakdown per Official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_industry_breakdown_official():\n",
    "    d = {}\n",
    "\n",
    "    df = get_mapping()\n",
    "\n",
    "    for _, transaction in rows:\n",
    "        industry = search_mapping(df, transaction['ticker'])\n",
    "        if industry: \n",
    "            d = increment_dictionary_in_dictionary(d, get_canonical_name(transaction[title]), industry)\n",
    "\n",
    "    d = sort_dictionary_by_keys(d)\n",
    "    \n",
    "    filename = \"frequency_of_industry_per_official\"\n",
    "    dir = makesubdir(path_csv, \"ticker/industry\")\n",
    "\n",
    "    wd = make_csv_breakdown(dir, filename, d, title)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "\n",
    "frequency_of_industry_breakdown_official()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency of Industry per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_industry_breakdown():\n",
    "    \n",
    "    d = {}\n",
    "    df = get_mapping()\n",
    "\n",
    "    for _, transaction in rows:\n",
    "        ticker = transaction['ticker']\n",
    "        \n",
    "        if isvalid(ticker):\n",
    "            industry = search_mapping(df, ticker)\n",
    "            if industry: \n",
    "                d = increment_dictionary_in_dictionary(d, industry, get_year(transaction['transaction_date']))\n",
    "\n",
    "    d = sort_dictionary_by_keys(d)\n",
    "    \n",
    "    filename = \"frequency_of_industry_breakdown\"\n",
    "    key_header = \"industry\"\n",
    "    \n",
    "    \n",
    "    dir = makesubdir(path_csv, \"ticker/industry\")\n",
    "    wd = make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "\n",
    "frequency_of_industry_breakdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asset Description (asset_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asset Type (asset_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Asset Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_asset_type():\n",
    "    d = {}\n",
    "\n",
    "\n",
    "    for _, transaction in rows:\n",
    "        if isvalid(transaction['asset_type']):\n",
    "            d = increment_dictionary(d, transaction['asset_type'])\n",
    "      \n",
    "    d = sort_dictionary_by_values(d)\n",
    "  \n",
    "    filename = \"frequency_of_asset_type\"\n",
    "    key_header = \"asset_type\"\n",
    "    value_header = \"number_of_transactions\"\n",
    "    \n",
    "    dir = makesubdir(path_csv, \"asset_type\")\n",
    "    wd = make_csv(dir, filename, d, [key_header, value_header])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "\n",
    "\n",
    "frequency_of_asset_type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Amount by Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_amount_by_persom():\n",
    "    d = {}\n",
    "\n",
    "\n",
    "    for _, transaction in rows:\n",
    "        d = increment_dictionary_in_dictionary(d, get_canonical_name(transaction[title]), transaction['amount'])\n",
    "\n",
    "    \n",
    "    d = sort_dictionary_by_keys(d)\n",
    "    \n",
    "    filename = \"frequency_of_amount_by_persom\"\n",
    "    key_header = \"amount\"\n",
    "    \n",
    "    dir = makesubdir(path_csv, \"amount\")\n",
    "    wd = make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "   \n",
    "    \n",
    "frequency_of_amount_by_persom()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Transactions by Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_amount_total():\n",
    "    d = {}\n",
    "\n",
    "\n",
    "    for _, transaction in rows:\n",
    "        d = increment_dictionary(d, transaction['amount'])\n",
    "\n",
    "    d = add_sort_key_for_amount(d, normal_header=\"num_of_transactions\", normal=True)\n",
    "    d = sort_dictionary_by_sort_key(d)\n",
    "\n",
    "    filename = \"frequency_of_amount_total\"\n",
    "    key_header = \"amount\"\n",
    "\n",
    "\n",
    "    dir = makesubdir(path_csv, \"amount\")\n",
    "    wd = make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "   \n",
    "    \n",
    "frequency_of_amount_total()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Amount by Gender "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_amount_by_gender():\n",
    "    d = {}\n",
    "\n",
    "\n",
    "    gender = {}\n",
    "    for _, transaction in rows:\n",
    "        person = transaction[title]\n",
    "        \n",
    "        if person not in gender: \n",
    "            rep = wiki_search(person) \n",
    "            gender.update({person : rep.get_gender()})\n",
    "            \n",
    "        d = increment_dictionary_in_dictionary(d, transaction['amount'], gender[person])\n",
    "        \n",
    "\n",
    "    d = add_sort_key_for_amount(d)\n",
    "    d = sort_dictionary_by_sort_key(d)\n",
    "    \n",
    "        \n",
    "    filename = \"frequency_of_amount_by_gender\"\n",
    "    key_header = \"amount\"\n",
    "    \n",
    "    \n",
    "    dir = makesubdir(path_csv, \"amount\")\n",
    "    wd = make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "   \n",
    "    \n",
    "frequency_of_amount_by_gender()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Transactions by Political Affiliation and Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def frequency_of_amount_by_aff():\n",
    "    d = {}\n",
    "\n",
    "\n",
    "    affiliations = {}\n",
    "    for _, transaction in rows:\n",
    "        person = transaction[title]\n",
    "        \n",
    "        if person not in affiliations: \n",
    "            rep = wiki_search(person) \n",
    "            affiliations.update({person : rep.party})\n",
    "            \n",
    "        d = increment_dictionary_in_dictionary(d, transaction['amount'], affiliations[person])\n",
    "\n",
    "\n",
    "    d = add_sort_key_for_amount(d)\n",
    "    d = sort_dictionary_by_sort_key(d)\n",
    "    \n",
    "        \n",
    "    filename = \"frequency_of_amount_by_aff\"\n",
    "    key_header = \"amount\"\n",
    "    \n",
    "    \n",
    "    dir = makesubdir(path_csv, \"amount\")\n",
    "    wd = make_csv_breakdown(dir, filename, d, key_header)\n",
    "    print(pd.read_csv(wd).head(2))\n",
    "   \n",
    "    \n",
    "frequency_of_amount_by_aff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average For Buys and Sells per Official "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_per_person():\n",
    "\n",
    "    d={}\n",
    "    \n",
    "    for _, transaction in rows:\n",
    "        if isvalid(transaction['amount']):\n",
    "            \n",
    "            # if 'Purchase' in transaction['type']:\n",
    "                \n",
    "            # if 'Sale' in transaction['type']:\n",
    "            d = increment_dictionary_in_dictionary(d, get_canonical_name(transaction[title]), average_amount(transaction['amount']))\n",
    "\n",
    "\n",
    "    d2 = {}\n",
    "    for person in d:\n",
    "        l = []\n",
    "        for amount in d[person]:   \n",
    "            l.append(d[person][amount]*amount)\n",
    "            \n",
    "        d2[person] = l \n",
    "        \n",
    "        \n",
    "    for person in d2:\n",
    "        d2[person] = int(gmean(d2[person]))\n",
    "    \n",
    "    filename = \"average_per_person\"\n",
    "    key_header = title \n",
    "    value_header = \"average_size_of_transactions\"\n",
    "\n",
    "    d2 = sort_dictionary_by_values(d2)\n",
    "    d2 = commify(d2)\n",
    "\n",
    "    dir = makesubdir(path_csv, \"amount\")\n",
    "    wd = make_csv(dir, filename, d2, [key_header, value_header])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "\n",
    "    return d2 \n",
    "\n",
    "average_per_person_res = average_per_person()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types (type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Actions Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_act():\n",
    "    d = {}\n",
    "\n",
    "    for _, transaction in rows:\n",
    "        if isvalid(transaction['type']): \n",
    "            d = increment_dictionary(d, transaction['type'])\n",
    "    \n",
    "    d = sort_dictionary_by_values(d)\n",
    "    \n",
    "    filename = \"frequency_of_act\"\n",
    "    key_header = \"type\"\n",
    "    value_header = \"number_of_transactions\"\n",
    "    \n",
    "    dir = makesubdir(path_csv, \"type\")\n",
    "    wd = make_csv(dir, filename, d, [key_header, value_header])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "\n",
    "     \n",
    "frequency_of_act()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Transactions per Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import increment_dictionary_in_dictionary, sort_dictionary_by_keys, get_data, path_csv,makesubdir\n",
    "from csv_utils import make_csv_breakdown\n",
    "import pandas as pd \n",
    "from official import get_canonical_name\n",
    "\n",
    "\n",
    "def types_of_transactions_per_person():\n",
    "\n",
    "    d={}\n",
    "    \n",
    "    for _, transaction in rows:\n",
    "        d = increment_dictionary_in_dictionary(d, get_canonical_name(transaction[title]), transaction['type'])\n",
    "\n",
    "\n",
    "    filename = \"types_of_transactions_per_person\"\n",
    "\n",
    "    d = sort_dictionary_by_keys(d)\n",
    "\n",
    "    dir = makesubdir(path_csv, \"type\")\n",
    "    wd = make_csv_breakdown(dir, filename, d, title)\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "\n",
    "    return d \n",
    "\n",
    "types_of_transactions_per_person_res = types_of_transactions_per_person()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment (comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def num_of_trans_per_year():\n",
    "    d={}\n",
    "    \n",
    "    for _, transaction in rows:\n",
    "        d = increment_dictionary(d, get_year(transaction['transaction_date']))\n",
    "\n",
    "    filename = \"num_of_trans_per_year\"\n",
    "    key_header = \"year\"\n",
    "    value_header = \"number_of_transactions\"\n",
    "\n",
    "    d = sort_dictionary_by_values(d)\n",
    "    \n",
    "    dir = makesubdir(path_csv, \"frequency\")\n",
    "    wd = make_csv(dir, filename, d, [key_header, value_header])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "\n",
    "    return d \n",
    "\n",
    "num_of_trans_per_year_res = num_of_trans_per_year()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Person \n",
    "_Not controlling for number of years in position or size of transaction._ For each official, we want their total number of transactions.  {'Sam': 5, 'Alex': 2424, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def num_of_trans_per_person():\n",
    "\n",
    "    d={}\n",
    "    \n",
    "    for _, transaction in rows:\n",
    "        d = increment_dictionary(d, get_canonical_name(transaction[title]))\n",
    "\n",
    "    filename = \"num_of_trans_per_person\"\n",
    "    key_header = title\n",
    "    value_header = \"number_of_transactions\"\n",
    "\n",
    "    d = sort_dictionary_by_values(d)\n",
    "    \n",
    "    dir = makesubdir(path_csv, \"frequency\")\n",
    "    wd = make_csv(dir, filename, d, [key_header, value_header])\n",
    "    df = pd.read_csv(wd)\n",
    "    print(df.head(5))\n",
    "\n",
    "    return d \n",
    "\n",
    "trans_per_person_res = num_of_trans_per_person()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Person Controlled\n",
    "_Divide number of transactions by number of years in official position.  Not controlling for size of transaction._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_per_person_controlled(rows):    \n",
    "\n",
    "    d={}\n",
    "\n",
    "    for person, num_of_trans in rows.items():\n",
    "        official = wiki_search(person)    \n",
    "        years_in_office = official.get_num_of_years()\n",
    "        d[person] = math.ceil(num_of_trans/years_in_office) \n",
    "\n",
    "    filename = \"num_of_trans_per_person_controlled\"\n",
    "    value_header = \"avg_number_of_transactions\"\n",
    "\n",
    "    d = sort_dictionary_by_values(d)\n",
    "   \n",
    "    dir = makesubdir(path_csv, \"frequency\")\n",
    "    wd = make_csv(dir, filename, d, [title, value_header])\n",
    "    print(pd.read_csv(wd).head(5))\n",
    "    \n",
    "    return d \n",
    "\n",
    "num_of_trans_per_person_controlled_res = num_of_trans_per_person_controlled(trans_per_person_res)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Person Controlled w/Number of Years in Congress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_per_person_controlled_w_seniority(rows):    \n",
    "\n",
    "    d={}\n",
    "\n",
    "    for person, num_of_trans in rows.items():\n",
    "        official = wiki_search(person)    \n",
    "        years_in_office = official.get_num_of_years()\n",
    "        d[person] = math.ceil(num_of_trans/years_in_office), official.get_num_of_years()\n",
    "\n",
    "    filename = \"num_of_trans_per_person_controlled_w_seniority\"\n",
    "    value_header = \"avg_number_of_transactions\"\n",
    "\n",
    "    d = sort_dictionary_by_values(d)\n",
    "   \n",
    "    dir = makesubdir(path_csv, \"frequency\")\n",
    "    wd = make_csv(dir, filename, d, [title, value_header, \"seniority\"])\n",
    "    print(pd.read_csv(wd).head(5))\n",
    "    \n",
    "    return d \n",
    "\n",
    "num_of_trans_per_person_controlled_w_seniority_res = num_of_trans_per_person_controlled_w_seniority(trans_per_person_res)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Person Controlled w/Degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_trans_per_person_controlled_w_degrees(rows):    \n",
    "\n",
    "\n",
    "    d={}\n",
    "\n",
    "    for person, num_of_trans in rows.items():\n",
    "        official = wiki_search(person)    \n",
    "        years_in_office = official.get_num_of_years()\n",
    "        d[person] = math.ceil(num_of_trans/years_in_office), official.get_num_of_degrees()\n",
    "\n",
    "    filename = \"num_of_trans_per_person_controlled_w_degrees\"\n",
    "    value_header = \"avg_number_of_transactions\"\n",
    "\n",
    "    d = sort_dictionary_by_values(d)\n",
    "   \n",
    "    dir = makesubdir(path_csv, \"frequency\")\n",
    "    wd = make_csv(dir, filename, d, [title, value_header, \"num_of_degrees\"])\n",
    "    print(pd.read_csv(wd).head(5))\n",
    "    \n",
    "    return d \n",
    "\n",
    "num_of_trans_per_person_controlled_w_degrees_res = num_of_trans_per_person_controlled_w_degrees(trans_per_person_res)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Person Controlled w/Affiliation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def num_of_trans_per_person_controlled_w_aff(rows):\n",
    "\n",
    "    d={}\n",
    "    \n",
    "    for person, val in rows.items():\n",
    "        official = wiki_search(person)     \n",
    "        d[person] = val, official.get_party()\n",
    "\n",
    "    filename = \"num_of_trans_per_person_controlled_w_aff\"\n",
    "    value_header = \"avg_number_of_transactions\"\n",
    "\n",
    "    d = sort_dictionary_by_values(d)\n",
    "        \n",
    "    dir = makesubdir(path_csv, \"frequency\")\n",
    "    wd = make_csv(dir, filename, d, [title, value_header, \"party\"])\n",
    "    print(pd.read_csv(wd).head(5))\n",
    "    \n",
    "    return d, pd.read_csv(wd).head(10)\n",
    "\n",
    "num_of_trans_per_person_controlled_w_aff_res, top_10 = num_of_trans_per_person_controlled_w_aff(num_of_trans_per_person_controlled_res)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transaction Date (transaction_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency of Differences between Transaction and Disclosure Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_differences():\n",
    "    d = {}\n",
    "    match = {}\n",
    "    total = num = 0 \n",
    "\n",
    "    for _, transaction in rows:\n",
    "        transaction_date = transaction['transaction_date']\n",
    "        disclosure_date = transaction['disclosure_date']\n",
    "\n",
    "        # Negative, X days BEFORE\n",
    "        # Positive, Y dayas AFTER\n",
    "        diff = difference_between_dates(disclosure_date, transaction_date)      \n",
    "        total += 1 \n",
    "        num += diff   \n",
    "        \n",
    "        # match = {5 days: {'Tom' : 1313, 'X': 3 , ...}. ..}\n",
    "        match = increment_dictionary_in_dictionary(match, diff, transaction[title])\n",
    "            \n",
    "            \n",
    "        d = increment_dictionary(d, int(diff))\n",
    "    \n",
    "    d = sort_dictionary_by_keys(d)\n",
    "        \n",
    "    filename = \"frequency_of_differences\"\n",
    "    key_header = \"difference_in_days\"\n",
    "    value_header = \"#_of_transactions_with_that_diff\"\n",
    "    \n",
    "    \n",
    "    dir = makesubdir(path_csv, \"disclosure_date/transaction_date\")\n",
    "    make_csv(dir, filename, d, [key_header, value_header])\n",
    "    # fig = graph_csv(dir, path_html, filename, key_header, value_header)\n",
    "    # fig.show()\n",
    "    \n",
    "    print(\"Average difference in days: {}\".format(num//total))\n",
    "\n",
    "frequency_of_differences()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e534e48711db4d1e1c48977d0d14ff85b1f16d41bcc4fdfd88268a329b3c9d66"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
