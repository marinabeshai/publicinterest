{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHASE 3: PROFILE + GEN Q'S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.csv_utils as csv_utils \n",
    "import utils.dir_utils as dir_utils\n",
    "import utils.dict_utils as dict_utils \n",
    "import utils.ptr_utils as ptr_utils\n",
    "import utils.constants as constants \n",
    "import helpers.official as official\n",
    "import helpers.search as search\n",
    "import helpers.congress as congress\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, input_df = dir_utils.get_data(combined=True)\n",
    "_, house_input_df = dir_utils.get_data(house=True)\n",
    "_, senate_input_df = dir_utils.get_data(senate=True)\n",
    "\n",
    "sector_df = dir_utils.get_mapping(sector=True)\n",
    "industry_df = dir_utils.get_mapping(industry=True)\n",
    "\n",
    "# {canonical_name_input_based : link, ...}\n",
    "input_all_officials_name = {}\n",
    "# {link : canonical_name_input_based, ....} \n",
    "input_all_officials_link = {} \n",
    "# (canonical_name_input_based, ...)\n",
    "names = set()\n",
    "\n",
    "for _,t in input_df.iterrows():        \n",
    "    name = official.get_name(t)\n",
    "    if name not in names:    \n",
    "        link = search.get_wiki_link(name)        \n",
    "        input_all_officials_link = dict_utils.increment_dictionary(input_all_officials_link, link, name, not_math=True)\n",
    "        input_all_officials_name = dict_utils.increment_dictionary(input_all_officials_name, name, link, not_math=True)\n",
    "        names.add(name)\n",
    "\n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "input_all_officials_objects = {}\n",
    "for link, person in input_all_officials_link.items(): \n",
    "    off = search.wiki_search(person)        \n",
    "    input_all_officials_objects[link] = (person, off)\n",
    "        \n",
    "def t_to_obj(t):\n",
    "    name = official.get_name(t)\n",
    "    link = input_all_officials_name[name]\n",
    "    _, obj = input_all_officials_objects[link]\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questionable_people = set()\n",
    "# {link : (canonical_name_input_based, official_object), ... }\n",
    "questionable_people_objects = {}\n",
    "\n",
    "\n",
    "for _,t in input_df.iterrows():\n",
    "    if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "        name = official.get_name(t)\n",
    "        year = str(ptr_utils.get_year((t[constants.TDATE])))\n",
    "        sector = dir_utils.search_mapping(sector_df, t[constants.TICKER], sector=True)\n",
    "        obj = t_to_obj(t)\n",
    "        committees = obj.asgts\n",
    "        \n",
    "        for comm in committees:\n",
    "            comm_year = official.get_committee_year(comm)                \n",
    "            if sector in comm and year in comm_year: \n",
    "                # questionable_people.add(name)\n",
    "                link = input_all_officials_name[name]\n",
    "                questionable_people_objects[link] =  (name, obj)\n",
    "                break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # {'name (d-ia), commitee' : ticker, tdate}\n",
    "# d = {}\n",
    "# c = 0 \n",
    "\n",
    "# for _,t in input_df.iterrows():\n",
    "#     #  and  'Purchase' in t[constants.TYPE]\n",
    "#     if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "#         name = official.get_name(t)\n",
    "#         year = str(ptr_utils.get_year((t[constants.TDATE])))\n",
    "#         sector = dir_utils.search_mapping(sector_df, t[constants.TICKER], sector=True)\n",
    "#         obj = t_to_obj(t)\n",
    "#         committees = obj.asgts\n",
    "        \n",
    "#         for comm in committees:\n",
    "#             comm_year = official.get_committee_year(comm)                \n",
    "#             if sector in comm and year in comm_year: \n",
    "#                 c += 1 \n",
    "#                 d = dict_utils.increment_list_in_dictionary(d, (obj.get_label() + ' ' + comm), (t[constants.TICKER]))   \n",
    "#                 break \n",
    "\n",
    "# print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def committee_and_industry(group):\n",
    "#     # d = {name : { commitee : set(tickers)}, }\n",
    "#     d = {} \n",
    "#     # name : freq\n",
    "#     freq_w_names = {}\n",
    "#     count = 0\n",
    "    \n",
    "#     for _,t in group.iterrows():\n",
    "#         if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "#             name = official.get_name(t)\n",
    "#             year = str(ptr_utils.get_year((t[constants.TDATE])))\n",
    "#             sector = dir_utils.search_mapping(sector_df, t[constants.TICKER], sector=True)\n",
    "#             obj = t_to_obj(t)\n",
    "#             committees = obj.asgts\n",
    "            \n",
    "#             for comm in committees:\n",
    "#                 comm_year = official.get_committee_year(comm)                \n",
    "#                 if sector in comm and year in comm_year: \n",
    "#                     d = dict_utils.increment_set_in_inner_dictionary(d, name, comm, t[constants.TICKER])\n",
    "#                     freq_w_names = dict_utils.increment_dictionary(freq_w_names, name)\n",
    "#                     count += 1\n",
    "#                     break \n",
    "\n",
    "#     flatten_freq_w_names = []\n",
    "#     for k,v in freq_w_names.items():\n",
    "#         link = input_all_officials_name[k]\n",
    "#         _, obj = input_officials_objects[link]\n",
    "#         flatten_freq_w_names.append([obj.get_label(), v, obj.get_color()])\n",
    "        \n",
    "#     return d, flatten_freq_w_names, count          \n",
    "    \n",
    "# d1, d2, c = committee_and_industry(house_input_df)\n",
    "# print(c)\n",
    "# d3, d4, c = committee_and_industry(senate_input_df)\n",
    "# print(c)\n",
    "# d5, people_doing_this, c = committee_and_industry(input_df)\n",
    "# print(c)\n",
    "\n",
    "\n",
    "# dir = dir_utils.makesubdir(constants.path_csv, constants.INSIDER)\n",
    "# wd = csv_utils.make_csv_breakdown(dir, \"committee_and_sector_house\", d1,  \"\")\n",
    "# wd = csv_utils.make_csv_breakdown(dir, \"committee_and_sector_senate\", d3,  \"\")\n",
    "# wd = csv_utils.make_csv_breakdown(dir, \"committee_and_sector_input\", d5,  \"\")\n",
    "\n",
    "# wd = csv_utils.make_csv_base(dir, \"committee_and_sector_house_names\", [\"name\", \"count\", \"color\"], d2)\n",
    "# wd = csv_utils.make_csv_base(dir, \"committee_and_sector_senate_names\", [\"name\", \"count\", \"color\"], d4)\n",
    "# wd = csv_utils.make_csv_base(dir, \"committee_and_sector_input_names\", [\"name\", \"count\", \"color\"], people_doing_this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# people = []\n",
    "# for k, _, _ in people_doing_this:\n",
    "#     k = k[ : k.find(\" (\")]\n",
    "#     people.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # {'25-44': 4, '45-64': 18, '65-84': 25, '85-100': 0}\n",
    "# ages = dict(constants.age_groups)\n",
    "# for k in people:\n",
    "#     link = input_all_officials_name[k]\n",
    "#     _, obj = input_officials_objects[link]    \n",
    "#     ages = dict_utils.increment_dictionary(ages, ptr_utils.which_age_group(obj.get_age())) \n",
    "\n",
    "# ages_normalized = {}\n",
    "# for k,v in ages.items():\n",
    "#     ages_normalized[k] = round(v/len(people), 2) \n",
    "\n",
    "# ages = dict_utils.sort_dictionary_by_keys(ages)\n",
    "# ages_normalized = dict_utils.sort_dictionary_by_keys(ages_normalized)\n",
    "\n",
    "# print(ages)\n",
    "# print(ages_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # {'Republican, male': 0.47, 'Democratic, male': 0.34, 'Democratic, female': 0.11, 'Republican, female': 0.06, 'Independent, male': 0.02}\n",
    "# genderandparty = {}\n",
    "    \n",
    "# for k in people:\n",
    "#     link = input_all_officials_name[k]\n",
    "#     _, obj = input_officials_objects[link]    \n",
    "#     genderandparty = dict_utils.increment_dictionary(genderandparty,  obj.party + \", \" + official.get_gender(k) ) \n",
    "\n",
    "# genderandparty_normalized = {}\n",
    "# for k,v in genderandparty.items():\n",
    "#     genderandparty_normalized[k] = round(v/len(people), 2) \n",
    "\n",
    "# genderandparty = dict_utils.sort_dictionary_by_keys(genderandparty)\n",
    "# genderandparty_normalized = dict_utils.sort_dictionary_by_keys(genderandparty_normalized)\n",
    "\n",
    "# print(genderandparty)\n",
    "# print(genderandparty_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # {'BA': 0.66, 'JD': 0.45, 'BS': 0.26, 'MBA': 0.19, 'MA': 0.17, 'MS': 0.09, 'MD': 0.04, 'AB': 0.04, 'MPP': 0.02, 'MEd': 0.02, 'DVM': 0.02, 'BEng': 0.02, 'MSc': 0.02, 'MPA': 0.02, 'BBA': 0.02}\n",
    "# degrees = {}\n",
    "    \n",
    "# for k in people:\n",
    "#     link = input_all_officials_name[k]\n",
    "#     _, obj = input_officials_objects[link]    \n",
    "#     for d in obj.get_degrees():\n",
    "#         degrees = dict_utils.increment_dictionary(degrees,  d) \n",
    "\n",
    "# degrees_normalized = {}\n",
    "# for k,v in degrees.items():\n",
    "#     degrees_normalized[k] = round(v/len(people), 2) \n",
    "\n",
    "# degrees = dict_utils.sort_dictionary_by_keys(degrees)\n",
    "# degrees_normalized = dict_utils.sort_dictionary_by_keys(degrees_normalized)\n",
    "\n",
    "# print(degrees)\n",
    "# print(degrees_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # {'male': 0.83, 'female': 0.17}\n",
    "# gender = {}\n",
    "    \n",
    "# for k in people:\n",
    "#     link = input_all_officials_name[k]\n",
    "#     _, obj = input_officials_objects[link]    \n",
    "#     gender = dict_utils.increment_dictionary(gender, official.get_gender(k)) \n",
    "\n",
    "# gender_normalized = {}\n",
    "# for k,v in gender.items():\n",
    "#     gender_normalized[k] = round(v/len(people), 2) \n",
    "\n",
    "# gender = dict_utils.sort_dictionary_by_keys(gender)\n",
    "# gender_normalized = dict_utils.sort_dictionary_by_keys(gender_normalized)\n",
    "\n",
    "# print(gender)\n",
    "# print(gender_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # {'Republican': 0.53, 'Democratic': 0.45, 'Independent': 0.02}\n",
    "# party = {}\n",
    "\n",
    "    \n",
    "# for k in people:\n",
    "#     link = input_all_officials_name[k]\n",
    "#     _, obj = input_officials_objects[link]    \n",
    "#     party = dict_utils.increment_dictionary(party,  obj.party) \n",
    "\n",
    "# party_normalized = {}\n",
    "# for k,v in party.items():\n",
    "#     party_normalized[k] = round(v/len(people), 2) \n",
    "\n",
    "# party = dict_utils.sort_dictionary_by_keys(party)\n",
    "# party_normalized = dict_utils.sort_dictionary_by_keys(party_normalized)\n",
    "\n",
    "# print(party)\n",
    "# print(party_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # {1: 0.81, 13: 0.04, 31: 0.04, 25: 0.02, 41: 0.02, 23: 0.02, 21: 0.02, 5: 0.02}\n",
    "# seniority = {}\n",
    "    \n",
    "# for k in people:\n",
    "#     link = input_all_officials_name[k]\n",
    "#     _, obj = input_officials_objects[link]    \n",
    "#     if obj.get_seniority() == 1 and len(obj.get_congress()) > 1:\n",
    "#         l = [] \n",
    "#         if obj._senate:\n",
    "#             l.append(obj._senate)\n",
    "#         if obj._house:\n",
    "#             l.append(obj._house)\n",
    "#         if len(l) == 1 and \"-\" in l and l[0].split(\"-\")[0] == l[0].split(\"-\")[1]:\n",
    "#             print(\"hi\")\n",
    "#         print(l)\n",
    "#         if len(l) == 1 and \"-\" not in l[0]:\n",
    "#             print(\"bye\")\n",
    "#         # print(obj.check())\n",
    "        \n",
    "#     seniority = dict_utils.increment_dictionary(seniority,  obj.get_seniority()) \n",
    "\n",
    "# seniority_normalized = {}\n",
    "# for k,v in seniority.items():\n",
    "#     seniority_normalized[k] = round(v/len(people), 2) \n",
    "\n",
    "# seniority = dict_utils.sort_dictionary_by_keys(seniority)\n",
    "# seniority_normalized = dict_utils.sort_dictionary_by_keys(seniority_normalized)\n",
    "\n",
    "# print(seniority)\n",
    "# print(seniority_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # {'New Jersey': 0.09, 'Michigan': 0.06, 'Texas': 0.06, 'Kansas': 0.04, 'Tennessee': 0.04, 'Alabama': 0.04, 'Colorado': 0.04, 'Rhode Island': 0.04, 'Maine': 0.04, 'Oregon': 0.04, 'Georgia': 0.04, 'North Carolina': 0.04, 'California': 0.04, 'Louisiana': 0.02, 'North Dakota': 0.02, 'Washington': 0.02, 'West Virginia': 0.02, 'Delaware': 0.02, 'Ohio': 0.02, 'Virginia': 0.02, 'Missouri': 0.02, 'Minnesota': 0.02, 'Iowa': 0.02, 'New York': 0.02, 'Montana': 0.02, 'Vermont': 0.02, 'Utah': 0.02, 'South Carolina': 0.02, 'Indiana': 0.02, 'Massachusetts': 0.02}\n",
    "# state = {}\n",
    "\n",
    "# for k in people:\n",
    "#     link = input_all_officials_name[k]\n",
    "#     _, obj = input_officials_objects[link]    \n",
    "#     state = dict_utils.increment_dictionary(state,  obj.state) \n",
    "\n",
    "# state_normalized = {}\n",
    "# for k,v in state.items():\n",
    "#     state_normalized[k] = round(v/len(people), 2) \n",
    "\n",
    "# state = dict_utils.sort_dictionary_by_values(state)\n",
    "# state_normalized = dict_utils.sort_dictionary_by_values(state_normalized)\n",
    "\n",
    "# print(state)\n",
    "# print(state_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Party and Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_party_and_gender(group, normalized=None):\n",
    "    # {party_and_gender : 45_ppl}\n",
    "    d = {}\n",
    "        \n",
    "    for link, (name, obj) in group.items(): \n",
    "        grouped = obj.party + \", \" + official.get_gender(name, link=link)\n",
    "        d = dict_utils.increment_dictionary(d, grouped)\n",
    "\n",
    "    # Normalize\n",
    "    if normalized: \n",
    "        d = dict_utils.normalize(d, normalized, percent=True)\n",
    "\n",
    "    return d\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"insider_trading/profile/partyandgender\")\n",
    "\n",
    "d1 = profile_party_and_gender(questionable_people_objects)\n",
    "csv_utils.make_csv(dir, \"profile_party_and_gender\", d1, [constants.PARTY + \", \" + constants.GENDER, constants.INPUT])\n",
    "\n",
    "d3 = profile_party_and_gender(questionable_people_objects, profile_party_and_gender(input_all_officials_objects))\n",
    "csv_utils.make_csv(dir, \"profile_party_and_gender_normalized\", d3, [constants.PARTY + \", \" + constants.GENDER, constants.INPUT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def profile_active_party_and_gender(group, normalized=None):\n",
    "#     # {party_and_gender : 45_transactions}\n",
    "#     d_number = {}\n",
    "#     # {party_and_gender : [gmean, gmean, ...]}\n",
    "#     d_size = {}\n",
    "    \n",
    "#     for _,t in group.iterrows():\n",
    "#         if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "#             name = official.get_name(t)\n",
    "#             link = input_all_officials_name[name]\n",
    "\n",
    "#             gender = all_officials_gender[link]\n",
    "#             obj = t_to_obj(t)\n",
    "#             x = obj.party\n",
    "#             grouped = x + \", \" + gender\n",
    "\n",
    "            \n",
    "#             d_number =  dict_utils.increment_dictionary(d_number, grouped)\n",
    "            \n",
    "#             mean =  ptr_utils.get_gmean(t[constants.AMOUNT])             \n",
    "#             d_size = dict_utils.increment_list_in_dictionary(d_size, grouped, mean)\n",
    "\n",
    "#     d_size = dict_utils.flatten_gmean(d_size)\n",
    "\n",
    "#     # Normalize\n",
    "#     if normalized: \n",
    "#         d_number = dict_utils.normalize(d_number, normalized, percent=True)\n",
    "#         d_number = dict_utils.sort_dictionary_by_tuple(d_number)\n",
    "        \n",
    "#         d_size = dict_utils.normalize(d_size, normalized, percent=True)\n",
    "#         d_size = dict_utils.sort_dictionary_by_tuple(d_size)\n",
    "\n",
    "#     return d_number, d_size\n",
    "    \n",
    "# d1,d4 = profile_active_party_and_gender(questionable_people_objects, house_officials_party_and_gender)\n",
    "\n",
    "# dir = dir_utils.makesubdir(constants.path_csv, \"insider_trading/active\")\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_active_party_and_gender_number_normalized\", (d1,d2,d3), [constants.PARTY + \", \" + constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_active_party_and_gender_size_normalized\", (d4,d5,d6), [constants.PARTY + \", \" + constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "\n",
    "# d1,d4 = profile_active_party_and_gender(house_input_df)\n",
    "# d2,d5 = profile_active_party_and_gender(senate_input_df)\n",
    "# d3,d6 = profile_active_party_and_gender(input_df)\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_active_party_and_gender_number\", (d1,d2,d3), [constants.PARTY + \", \" + constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_active_party_and_gender_size\", (d4,d5,d6), [constants.PARTY + \", \" + constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age (Lowest, Highest, Average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_age(group):\n",
    "    # {age, age, ...}\n",
    "    l = []\n",
    "    \n",
    "    # group = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for _, (_, off_obj) in group.items(): \n",
    "        l.append(off_obj.get_age())\n",
    "    \n",
    "    l.sort()\n",
    "    \n",
    "    d = {}\n",
    "    d[\"0. Youngest\"] = l[0]\n",
    "    d[\"1. Average\"] = round((sum(l) / len(l)))\n",
    "    d[\"2. Oldest\"] = l[len(l)-1]\n",
    "    \n",
    "    return d \n",
    "    \n",
    "d1 = profile_age(questionable_people_objects)\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"insider_trading/profile/age\")\n",
    "csv_utils.make_csv(dir, \"profile_age\", d1, [\"Age\", constants.INPUT])\n",
    "\n",
    "\n",
    "def profile_age_2(group, normalized=None):\n",
    "    # {age : #_of_people, ...}\n",
    "    d = dict(constants.age_groups)\n",
    "    \n",
    "    for (_, off_obj) in group.values(): \n",
    "        age = off_obj.get_age()\n",
    "        d = dict_utils.increment_dictionary(d, ptr_utils.which_age_group(age)) \n",
    "    \n",
    "    if normalized: \n",
    "        print(d)\n",
    "        d_prime = dict_utils.normalize(d, normalized, percent=True)\n",
    "        print(d)\n",
    "        return d, d_prime\n",
    "        \n",
    "    return d \n",
    "\n",
    "d1, d4 = profile_age_2(questionable_people_objects, profile_age_2(input_all_officials_objects))\n",
    "\n",
    "csv_utils.make_csv(dir, \"profile_age_2\", (d1), [\"Age\", constants.INPUT])\n",
    "csv_utils.make_csv(dir, \"profile_age_2_normalized\", (d4), [\"Age\", constants.INPUT])\n",
    "\n",
    "\n",
    "def profile_age_3(group):\n",
    "    # {age: freq_count , .... }\n",
    "    d = {}\n",
    "    \n",
    "    # group = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for _, (_, off_obj) in group.items(): \n",
    "        d = dict_utils.increment_dictionary(d, off_obj.get_age())\n",
    "    \n",
    "    return d \n",
    "    \n",
    "d3 = profile_age_3(questionable_people_objects)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"insider_trading/profile/age\")\n",
    "csv_utils.make_csv(dir, \"profile_age_3\", (d3), [\"Age\", constants.INPUT])\n",
    "\n",
    "\n",
    "def profile_age_box(group):\n",
    "    # {age, age, ...}\n",
    "    l = []\n",
    "    \n",
    "    # group = {link : (canonical_name_input_based, official_object) ... }\n",
    "    for _, (_, off_obj) in group.items(): \n",
    "        l.append([off_obj.get_age()])\n",
    "        \n",
    "    return l \n",
    "    \n",
    "d1 = profile_age_box(questionable_people_objects)\n",
    "\n",
    "dir = dir_utils.makesubdir(constants.path_csv, \"insider_trading/profile/age\")\n",
    "csv_utils.make_csv_base(dir, \"profile_age_box_input\", [\"Age_Input\"], d1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age (Which age is most active?) Active = No. of Trades &  Size of Transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def profile_active_age(group, normalized=None):\n",
    "#     # {age : 45_transactions}\n",
    "#     d_number = dict(constants.age_groups)\n",
    "    \n",
    "#     # {age : [gmean, gmean, ...]}\n",
    "#     d_size = dict(constants.age_groups)\n",
    "#     for k,_ in d_size.items():\n",
    "#         d_size[k] = []\n",
    "    \n",
    "#     for _,t in group.iterrows():\n",
    "#         if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "#             obj = t_to_obj(t)\n",
    "#             age = obj.get_age()\n",
    "            \n",
    "#             age_group = ptr_utils.which_age_group(age)\n",
    "#             d_number =  dict_utils.increment_dictionary(d_number, age_group)\n",
    "            \n",
    "#             mean =  ptr_utils.get_gmean(t[constants.AMOUNT])             \n",
    "#             d_size = dict_utils.increment_list_in_dictionary(d_size, age_group, mean)\n",
    "\n",
    "#     d_size = dict_utils.flatten_gmean(d_size)\n",
    "\n",
    "#     # Normalize\n",
    "#     if normalized: \n",
    "#         d_number = dict_utils.normalize(d_number, normalized, percent=True)\n",
    "#         d_number = dict_utils.sort_dictionary_by_tuple(d_number)\n",
    "        \n",
    "#         d_size = dict_utils.normalize(d_size, normalized, percent=True)\n",
    "#         d_size = dict_utils.sort_dictionary_by_tuple(d_size)\n",
    "\n",
    "#     return d_number, d_size\n",
    "    \n",
    "# d1,d4 = profile_active_age(house_input_df, profile_age_2(input_house_officials_objects))\n",
    "# d2,d5 = profile_active_age(senate_input_df, profile_age_2(input_senate_officials_objects))\n",
    "# d3,d6 = profile_active_age(input_df, profile_age_2(input_officials_objects))\n",
    "\n",
    "# dir = dir_utils.makesubdir(constants.path_csv, \"insider_trading/active\")\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_age_active_number_normalized\", (d1,d2,d3), [constants.AGE, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_age_active_size_normalized\", (d4,d5,d6), [constants.AGE, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "# d1,d4 = profile_active_age(house_input_df)\n",
    "# d2,d5 = profile_active_age(senate_input_df)\n",
    "# d3,d6 = profile_active_age(input_df)\n",
    "\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_age_active_number\", (d1,d2,d3), [constants.AGE, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_age_active_size\", (d4,d5,d6), [constants.AGE, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oldest and Most Recent Dates (transaction and disclosure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def profile_dates(group, type):\n",
    "#     lowest_tdate = lowest_ddate = highest_tdate = highest_ddate = None\n",
    "#     lowest_tdate_obj = lowest_ddate_obj = highest_tdate_obj = highest_ddate_obj = None\n",
    "\n",
    "#     for _,t in group.iterrows():\n",
    "#         curr = t[constants.TDATE]            \n",
    "#         if not lowest_tdate or curr < lowest_tdate:\n",
    "#             lowest_tdate = curr \n",
    "#             lowest_tdate_obj = t\n",
    "#         if not highest_tdate or curr > highest_tdate:\n",
    "#             highest_tdate = curr  \n",
    "#             highest_tdate_obj = t\n",
    "\n",
    "#         curr = t[constants.DDATE]\n",
    "#         if not lowest_ddate or curr < lowest_ddate:\n",
    "#             lowest_ddate = curr \n",
    "#             lowest_ddate_obj = t\n",
    "#         if not highest_ddate or curr > highest_ddate:\n",
    "#             highest_ddate = curr \n",
    "#             highest_ddate_obj = t\n",
    "\n",
    "#     print(\"Oldest transaction_date for {}: {} by {} \\n {}\".format(type, lowest_tdate, official.get_name(lowest_tdate_obj), lowest_tdate_obj[constants.PTR_LINK]))\n",
    "#     print(\"Most recent transaction_date for {}: {} by {} \\n {} \".format(type, highest_tdate, official.get_name(highest_tdate_obj), highest_tdate_obj[constants.PTR_LINK]))\n",
    "    \n",
    "#     print(\"Oldest disclosure_date for {}: {} by {} \\n {}\".format(type, lowest_ddate,  official.get_name(lowest_ddate_obj), lowest_ddate_obj[constants.PTR_LINK]))\n",
    "#     print(\"Most recent disclosure_date for {}: {} by {}  \\n {}\\n\".format(type, highest_ddate,  official.get_name(highest_ddate_obj), highest_ddate_obj[constants.PTR_LINK]))\n",
    "    \n",
    "\n",
    "# profile_dates(house_input_df, constants.HOUSE)\n",
    "# profile_dates(senate_input_df, constants.SENATE)\n",
    "# profile_dates(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def profile_gender(group, normalized=None):\n",
    "#     # d_prime = {'Female' : set(Officials), 'Male' : set(Officials), ...}\n",
    "#     d_prime = {}\n",
    "\n",
    "#     for link, name in group.items(): \n",
    "#         gender = all_officials_gender[link]\n",
    "#         d_prime = dict_utils.increment_set_in_dictionary(d_prime, gender, name)\n",
    "\n",
    "#     # d = {'Female' : #_of_officials, 'Male' : #_of_officials, ...}\n",
    "#     d = dict_utils.flatten_len(d_prime, inner_set=True)\n",
    "    \n",
    "#     if normalized:\n",
    "#         d = dict_utils.normalize(d, normalized, percent=True)\n",
    "#         d = dict_utils.sort_dictionary_by_tuple(d)\n",
    "                 \n",
    "#     return d\n",
    "\n",
    "# d1 = profile_gender(input_house_officials_link, profile_gender(house_officials))\n",
    "# d2 = profile_gender(input_senate_officials_link, profile_gender(senate_officials))\n",
    "# d3 = profile_gender(input_all_officials_link, profile_gender(all_officials))\n",
    "\n",
    "# dir = dir_utils.makesubdir(constants.path_csv, \"insider_trading/profile/gender\")\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_gender_normalized\", (d1,d2,d3), [constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "\n",
    "# d1 = profile_gender(input_house_officials_link)\n",
    "# d2 = profile_gender(input_senate_officials_link)\n",
    "# d3 = profile_gender(input_all_officials_link)\n",
    "\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_gender\", (d1,d2,d3), [constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender (Which gender is the most active?) Active = No. of Trades &  Size of Transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def profile_active_gender(group, normalized=None):\n",
    "#     # {'gender' : 5_trades, ...}\n",
    "#     d_number = {}\n",
    "    \n",
    "#     # {gender : [gmean of amount, gmean of amount....] }\n",
    "#     d_size = {}\n",
    "\n",
    "#     for _,t in group.iterrows():\n",
    "#         if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "#             name = official.get_name(t)\n",
    "#             link = input_all_officials_name[name]\n",
    "#             g = all_officials_gender[link]\n",
    "            \n",
    "#             d_number =  dict_utils.increment_dictionary(d_number, g)\n",
    "            \n",
    "#             mean =  ptr_utils.get_gmean(t[constants.AMOUNT])             \n",
    "#             d_size = dict_utils.increment_list_in_dictionary(d_size, g, mean)\n",
    "\n",
    "#     d_size = dict_utils.flatten_gmean(d_size)\n",
    "        \n",
    "#     # Normalize\n",
    "#     if normalized:\n",
    "#         d_number = dict_utils.normalize(d_number, normalized, percent=True)\n",
    "#         d_number = dict_utils.sort_dictionary_by_tuple(d_number)\n",
    "        \n",
    "#         d_size = dict_utils.normalize(d_size, normalized, percent=True)\n",
    "#         d_size = dict_utils.sort_dictionary_by_tuple(d_size)\n",
    "\n",
    "#     return d_number, d_size\n",
    "\n",
    "\n",
    "# d1,d4 = profile_active_gender(house_input_df, profile_gender(house_officials))\n",
    "# d2,d5 = profile_active_gender(senate_input_df, profile_gender(senate_officials))\n",
    "# d3,d6 = profile_active_gender(input_df, profile_gender(all_officials))\n",
    "\n",
    "# dir = dir_utils.makesubdir(constants.path_csv, \"insider_trading/active\")\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_active_gender_number_normalized\", (d1,d2,d3), [constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_active_gender_size_normalized\", (d4,d5,d6), [constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "\n",
    "# d1,d4 = profile_active_gender(house_input_df)\n",
    "# d2,d5 = profile_active_gender(senate_input_df)\n",
    "# d3,d6 = profile_active_gender(input_df)\n",
    "\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_active_gender_number\", (d1,d2,d3), [constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_active_gender_size\", (d4,d5,d6), [constants.GENDER, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def profile_party(group, normalized=None):\n",
    "#     # d_prime = {'Republican' : set(Officials), 'Democrat' : set(Officials), ...}\n",
    "#     d_prime = {}\n",
    "    \n",
    "#     for (_, off_obj) in group.values(): \n",
    "#         d_prime = dict_utils.increment_set_in_dictionary(d_prime, off_obj.party, off_obj.name)\n",
    "        \n",
    "#     # d = {'Republican' : #_of_officials, 'Democrat' : #_of_officials, ...}\n",
    "#     d = dict_utils.flatten_len(d_prime, inner_set=True)\n",
    "    \n",
    "#     if normalized:         \n",
    "#         d = dict_utils.normalize(d, normalized, percent=True)\n",
    "#         d = dict_utils.sort_dictionary_by_tuple(d)\n",
    "\n",
    "#     return d\n",
    "\n",
    "# # {link : (canonical_name_input_based, official_object), ... }\n",
    "# d1 = profile_party(input_house_officials_objects, house_officials_party)\n",
    "# d2 = profile_party(input_senate_officials_objects, senate_officials_party)\n",
    "# # {link : (canonical_name_input_based, official_object), ... }\n",
    "# d3 = profile_party(input_officials_objects, all_officials_party)\n",
    "\n",
    "# dir = dir_utils.makesubdir(constants.path_csv, \"profile/party\")\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_party_normalized\", (d1,d2,d3), [constants.PARTY, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "# # {link : (canonical_name_input_based, official_object), ... }\n",
    "# d1 = profile_party(input_house_officials_objects)\n",
    "# d2 = profile_party(input_senate_officials_objects)\n",
    "# # {link : (canonical_name_input_based, official_object), ... }\n",
    "# d3 = profile_party(input_officials_objects)\n",
    "\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_party\", (d1,d2,d3), [constants.PARTY, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Party (Which party is the most active?) Active = No. of Trades &  Size of Transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def profile_active_party(group, normalized=None):\n",
    "#     # {'party' : 5_trades, ...}\n",
    "#     d_number = {}\n",
    "    \n",
    "#     # {party : [gmean of amount, gmean of amount....] }\n",
    "#     d_size = {}\n",
    "\n",
    "#     for _,t in group.iterrows():\n",
    "#         if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "#             obj = t_to_obj(t)\n",
    "#             party = obj.party        \n",
    "            \n",
    "#             d_number =  dict_utils.increment_dictionary(d_number, party)\n",
    "            \n",
    "#             mean =  ptr_utils.get_gmean(t[constants.AMOUNT])             \n",
    "#             d_size = dict_utils.increment_list_in_dictionary(d_size, party, mean)\n",
    "\n",
    "#     d_size = dict_utils.flatten_gmean(d_size)\n",
    "        \n",
    "#     # Normalize\n",
    "#     if normalized:\n",
    "#         d_number = dict_utils.normalize(d_number, normalized, percent=True)\n",
    "#         d_number = dict_utils.sort_dictionary_by_tuple(d_number)\n",
    "        \n",
    "#         d_size = dict_utils.normalize(d_size, normalized, percent=True)\n",
    "#         d_size = dict_utils.sort_dictionary_by_tuple(d_size)\n",
    "    \n",
    "#     return d_number, d_size\n",
    "\n",
    "# d1,d4 = profile_active_party(house_input_df, house_officials_party)\n",
    "# d2,d5 = profile_active_party(senate_input_df, senate_officials_party)\n",
    "# d3,d6 = profile_active_party(input_df, all_officials_party)\n",
    "\n",
    "# dir = dir_utils.makesubdir(constants.path_csv, \"insider_trading/active\")\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_active_party_number_normalized\", (d1,d2,d3), [constants.PARTY, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_active_party_size_normalized\", (d4,d5,d6), [constants.PARTY, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "\n",
    "# d1,d4 = profile_active_party(house_input_df)\n",
    "# d2,d5 = profile_active_party(senate_input_df)\n",
    "# d3,d6 = profile_active_party(input_df)\n",
    "\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_active_party_number\", (d1,d2,d3), [constants.PARTY, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_active_party_size\", (d4,d5,d6), [constants.PARTY, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def profile_state(group, normalized=None):\n",
    "#     # d_prime = {'Maryland' : set(Officials), 'California' : set(Officials), ...}\n",
    "#     d_prime = {}\n",
    "    \n",
    "#     # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "#     for _, off_obj in group.values(): \n",
    "#         d_prime = dict_utils.increment_set_in_dictionary(d_prime, off_obj.state, off_obj.name)\n",
    "\n",
    "#     # d = {'Maryland' : #_of_officials, 'California' : #_of_officials, ...}\n",
    "#     d = dict_utils.flatten_len(d_prime, inner_set=True)\n",
    "    \n",
    "#     if normalized:\n",
    "#         d = dict_utils.normalize(d, normalized, percent=True)\n",
    "#         d = dict_utils.sort_dictionary_by_tuple(d)\n",
    "            \n",
    "#     return d \n",
    "\n",
    "# # {link : (canonical_name_input_based, official_object), ... }\n",
    "# d1 = profile_state(input_house_officials_objects, house_officials_state_count)\n",
    "# d2 = profile_state(input_senate_officials_objects, senate_officials_state_count)\n",
    "\n",
    "# # {link : (canonical_name_input_based, official_object) ... }\n",
    "# d3 = profile_state(input_officials_objects, all_officials_state_count)\n",
    "\n",
    "# dir = dir_utils.makesubdir(constants.path_csv, \"insider_trading/profile/state\")\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_state_normalized\", (d1,d2,d3), [constants.STATE, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "# # {link : (canonical_name_input_based, official_object), ... }\n",
    "# d1 = profile_state(input_house_officials_objects)\n",
    "# d2 = profile_state(input_senate_officials_objects)\n",
    "\n",
    "# # {link : (canonical_name_input_based, official_object) ... }\n",
    "# d3 = profile_state(input_officials_objects)\n",
    "\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_state\", (d1,d2,d3), [constants.STATE, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State (Which state is the most active?) Active = No. of Trades &  Size of Transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def profile_active_state(group, normalized=None):\n",
    "#     # {'state' : 5_trades, ...}\n",
    "#     d_number = {}\n",
    "    \n",
    "#     # {state : [gmean of amount, gmean of amount....] }\n",
    "#     d_size = {}\n",
    "\n",
    "#     for _,t in group.iterrows():\n",
    "#         if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "#             obj =  t_to_obj(t)\n",
    "            \n",
    "#             d_number =  dict_utils.increment_dictionary(d_number, obj.state)\n",
    "            \n",
    "#             mean =  ptr_utils.get_gmean(t[constants.AMOUNT])             \n",
    "#             d_size = dict_utils.increment_list_in_dictionary(d_size, obj.state, mean)\n",
    "\n",
    "#     d_size = dict_utils.flatten_gmean(d_size)\n",
    "    \n",
    "#     if normalized:\n",
    "#         d_number = dict_utils.normalize(d_number, normalized, percent=True)\n",
    "#         d_number = dict_utils.sort_dictionary_by_tuple(d_number)\n",
    "        \n",
    "#         d_size = dict_utils.normalize(d_size, normalized, percent=True)\n",
    "#         d_size = dict_utils.sort_dictionary_by_tuple(d_size)\n",
    "\n",
    "#     return d_number, d_size\n",
    "\n",
    "# d1,d4 = profile_active_state(house_input_df, house_officials_state_count)\n",
    "# d2,d5 = profile_active_state(senate_input_df, senate_officials_state_count)\n",
    "# d3,d6 = profile_active_state(input_df, all_officials_state_count)\n",
    "\n",
    "# dir = dir_utils.makesubdir(constants.path_csv, \"active\")\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_active_state_number_normalized\", (d1,d2,d3), [constants.STATE, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_active_state_size_normalized\", (d4,d5,d6), [constants.STATE, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "\n",
    "# d1,d4 = profile_active_state(house_input_df)\n",
    "# d2,d5 = profile_active_state(senate_input_df)\n",
    "# d3,d6 = profile_active_state(input_df)\n",
    "\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_active_state_number\", (d1,d2,d3), [constants.STATE, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_active_state_size\", (d4,d5,d6), [constants.STATE, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seniority (Lowest, Highest, Average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def profile_seniority(group):\n",
    "#     # d = {x_years_in_congress, y_years_in_congres, ...}\n",
    "#     l = []\n",
    "    \n",
    "#     # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "#     for _, (_, off_obj) in group.items(): \n",
    "#         l.append(off_obj.get_seniority())\n",
    "    \n",
    "#     l.sort()\n",
    "    \n",
    "#     d = {}\n",
    "#     d[\"0. Lowest\"] = l[0]\n",
    "#     d[\"1. Average\"] = round((sum(l) / len(l)))\n",
    "#     d[\"2. Highest\"] = l[len(l)-1]\n",
    "\n",
    "#     return d \n",
    "\n",
    "# d1 = profile_seniority(input_house_officials_objects)\n",
    "# d2 = profile_seniority(input_senate_officials_objects)\n",
    "# d3 = profile_seniority(input_officials_objects)\n",
    "\n",
    "# dir = dir_utils.makesubdir(constants.path_csv, \"insider_trading/profile/seniority\")\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_seniority\", (d1,d2,d3), [constants.SENIORITY, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "# def profile_seniority_normalized(group, normalized=None):\n",
    "#     d = {}\n",
    "    \n",
    "#     for (_, off_obj) in group.values(): \n",
    "#         d = dict_utils.increment_dictionary(d, off_obj.get_seniority()) \n",
    "    \n",
    "#     if normalized: \n",
    "#         d_prime = dict_utils.normalize(d, normalized, percent=True)\n",
    "#         return d, d_prime\n",
    "        \n",
    "#     return d \n",
    "    \n",
    "# d1, d4 = profile_seniority_normalized(input_house_officials_objects, profile_seniority_normalized(house_officials_objects))\n",
    "# d2, d5 = profile_seniority_normalized(input_senate_officials_objects, profile_seniority_normalized(senate_officials_objects))\n",
    "# d3, d6 = profile_seniority_normalized(input_officials_objects, profile_seniority_normalized(officials_objects))\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_seniority_normalized\", (d1,d2,d3), [constants.SENIORITY, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "\n",
    "# def profile_seniority_box(group):\n",
    "#     # d = {x_years_in_congress, y_years_in_congres, ...}\n",
    "#     l = []\n",
    "    \n",
    "#     # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "#     for _, (_, off_obj) in group.items(): \n",
    "#         l.append([off_obj.get_seniority()])\n",
    "    \n",
    "#     return l\n",
    "    \n",
    "# d1 = profile_seniority_box(input_house_officials_objects)\n",
    "# d2 = profile_seniority_box(input_senate_officials_objects)\n",
    "# csv_utils.make_csv_base(dir, \"profile_seniority_box_house\", [\"Seniority_House\"], d1)\n",
    "# csv_utils.make_csv_base(dir, \"profile_seniority_box_senate\", [\"Seniority_Senate\"], d2)\n",
    "\n",
    "\n",
    "# def profile_seniority_2(group):\n",
    "#     # d = {x_years_in_congress : #_of_people, }\n",
    "#     d = {}\n",
    "    \n",
    "#     # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "#     for (_, off_obj) in group.values(): \n",
    "#         print(off_obj.check())\n",
    "#         d =  dict_utils.increment_dictionary(d, off_obj.get_seniority())\n",
    "    \n",
    "#     return d \n",
    "\n",
    "# # d1 = profile_seniority_2(input_house_officials_objects)\n",
    "# # d2 = profile_seniority_2(input_senate_officials_objects)\n",
    "# # d3 = profile_seniority_2(input_officials_objects)\n",
    "\n",
    "\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_seniority_2\", (d1,d2,d3), [constants.SENIORITY, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seniority (Which seniority is most active?) Active = No. of Trades & Size of Transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def profile_active_seniority(group, normalized=None):\n",
    "#     # {'seniority' : 5_peeps_with_it, ...}\n",
    "#     d_number = {}\n",
    "    \n",
    "#     # {'seniority' :  [gmean of amount, gmean of amount....] }\n",
    "#     d_size = {}\n",
    "\n",
    "#     for _,t in group.iterrows():\n",
    "#         if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "#             obj = t_to_obj(t)\n",
    "#             seniority = obj.get_seniority()\n",
    "            \n",
    "#             d_number =  dict_utils.increment_dictionary(d_number, seniority)\n",
    "            \n",
    "#             mean =  ptr_utils.get_gmean(t[constants.AMOUNT])             \n",
    "#             d_size = dict_utils.increment_list_in_dictionary(d_size, seniority, mean)\n",
    "    \n",
    "#     d_size = dict_utils.flatten_gmean(d_size)\n",
    "\n",
    "#     # Normalize\n",
    "#     if normalized: \n",
    "#         d_number = dict_utils.normalize(d_number, normalized, percent=True)\n",
    "#         d_size = dict_utils.normalize(d_size, normalized, percent=True)\n",
    "\n",
    "#     return d_number, d_size\n",
    "\n",
    "# print(profile_seniority_2(input_house_officials_objects))\n",
    "\n",
    "# d1,d4 = profile_active_seniority(house_input_df, profile_seniority_2(input_house_officials_objects))\n",
    "# d2,d5 = profile_active_seniority(senate_input_df, profile_seniority_2(input_senate_officials_objects))\n",
    "# d3,d6 = profile_active_seniority(input_df, profile_seniority_2(input_officials_objects))\n",
    "\n",
    "# dir = dir_utils.makesubdir(constants.path_csv, \"insider_trading/activity\")\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_active_seniority_number_normalized\", (d1,d2,d3), [constants.AGE, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_active_seniority_size_normalized\", (d4,d5,d6), [constants.AGE, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "\n",
    "# d1,d4 = profile_active_seniority(house_input_df)\n",
    "# d2,d5 = profile_active_seniority(senate_input_df)\n",
    "# d3,d6 = profile_active_seniority(input_df)\n",
    "\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_active_seniority_number\", (d1,d2,d3), [constants.AGE, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_active_seniority_size\", (d4,d5,d6), [constants.AGE, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get_Congress (Lowest, Highest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def profile_congress(group):\n",
    "#     lowest = highest = None \n",
    "#     lowest_person = highest_person = None \n",
    "    \n",
    "#     # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "#     for (name, off_obj) in group.values():\n",
    "#         res = off_obj.get_congress()\n",
    "        \n",
    "#         if not lowest or res[0] < lowest:\n",
    "#             lowest = res[0]\n",
    "#             lowest_person = name\n",
    "    \n",
    "#         if not highest or res[len(res) - 1] > highest:\n",
    "#             highest = res[len(res) - 1]\n",
    "#             highest_person = name \n",
    "                    \n",
    "#     d = {}\n",
    "#     d[\"Lowest Congress\"] = lowest, lowest_person\n",
    "#     d[\"Highest Congress\"] = highest, highest_person\n",
    "\n",
    "#     return d \n",
    "                        \n",
    "# d1 = profile_congress(input_house_officials_objects)\n",
    "# d2 = profile_congress(input_senate_officials_objects)\n",
    "# d3 = profile_congress(input_officials_objects)\n",
    "\n",
    "# dir = dir_utils.makesubdir(constants.path_csv, \"insider_trading/profile/congress\")\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_congress\", (d1,d2,d3), [\"\", constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "\n",
    "# def profile_congress_box(group):\n",
    "#     l = []\n",
    "    \n",
    "#     # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "#     for (_, off_obj) in group.values():\n",
    "#         res = off_obj.get_congress()\n",
    "        \n",
    "#         l.append([res])\n",
    "\n",
    "#     return l\n",
    "                        \n",
    "# d1 = profile_congress_box(input_house_officials_objects)\n",
    "# d2 = profile_congress_box(input_senate_officials_objects)\n",
    "# csv_utils.make_csv_base(dir, \"profile_congress_box_house\", [\"Congress_House\"], d1)\n",
    "# csv_utils.make_csv_base(dir, \"profile_congress_box_senate\", [\"Congress_Senate\"], d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Degrees (Lowest, Highest, Average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def profile_degrees_2(group, normalized=None):\n",
    "#     d = {}\n",
    "#     for (_, off_obj) in group.values(): \n",
    "#         d = dict_utils.increment_dictionary(d, off_obj.get_num_of_degrees()) \n",
    "    \n",
    "    \n",
    "#     if normalized: \n",
    "#         d_prime = dict_utils.normalize(d, normalized, percent=True)\n",
    "#         return d, d_prime \n",
    "    \n",
    "#     return d\n",
    "    \n",
    "# d1, d4 = profile_degrees_2(input_house_officials_objects, profile_degrees_2(house_officials_objects))\n",
    "# d2, d5 = profile_degrees_2(input_senate_officials_objects, profile_degrees_2(senate_officials_objects))\n",
    "# d3, d6 = profile_degrees_2(input_officials_objects, profile_degrees_2(officials_objects))\n",
    "\n",
    "  \n",
    "# def profile_degrees(group):    \n",
    "#     # d = {x_degrees, y_degrees, ...}\n",
    "#     l = []\n",
    "    \n",
    "#     # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "#     for (_, off_obj) in group.values(): \n",
    "#         l.append(off_obj.get_num_of_degrees())\n",
    "    \n",
    "#     l.sort()\n",
    "    \n",
    "#     d = {}\n",
    "#     d[\"0. Lowest\"] = l[0]\n",
    "#     d[\"1. Average\"] = round((sum(l) / len(l)))\n",
    "#     d[\"2. Highest\"] = l[len(l)-1]\n",
    "\n",
    "#     return d \n",
    "    \n",
    "# d1 = profile_degrees(input_house_officials_objects)\n",
    "# d2 = profile_degrees(input_senate_officials_objects)\n",
    "# d3 = profile_degrees(input_officials_objects)       \n",
    "\n",
    "# dir = dir_utils.makesubdir(constants.path_csv, \"profile/degrees\")\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_degrees\", (d1,d2,d3), [\"No. of Degrees\", constants.HOUSE, constants.SENATE, constants.INPUT]) \n",
    "\n",
    "# def profile_degrees_box(group):    \n",
    "#     # d = {x_degrees, y_degrees, ...}\n",
    "#     l = []\n",
    "    \n",
    "#     # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "#     for (_, off_obj) in group.values(): \n",
    "#         l.append([off_obj.get_num_of_degrees()])\n",
    "    \n",
    "#     return l\n",
    "    \n",
    "# d1 = profile_degrees_box(input_house_officials_objects)\n",
    "# d2 = profile_degrees_box(input_senate_officials_objects)\n",
    "# csv_utils.make_csv_base(dir, \"profile_degrees_box_house\", [\"Degrees_House\"], d1)\n",
    "# csv_utils.make_csv_base(dir, \"profile_degrees_box_senate\", [\"Degrees_Senate\"], d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def profile_JD(group):\n",
    "#     # d = {x_degrees, y_degrees, ...}\n",
    "#     yes = total = 0 \n",
    "    \n",
    "#     # input_officials_objects = {link : (canonical_name_input_based, official_object) ... }\n",
    "#     for (_, off_obj) in group.values(): \n",
    "#         if off_obj.has_JD():\n",
    "#             yes += 1 \n",
    "#         total += 1 \n",
    "        \n",
    "#     d = {}\n",
    "    \n",
    "#     d[\"(Raw, Percent)\"] = (yes, round(yes/total, 2))\n",
    "    \n",
    "#     return d \n",
    "    \n",
    "# d1 = profile_JD(input_house_officials_objects)\n",
    "# d2 = profile_JD(input_senate_officials_objects)\n",
    "# d3 = profile_JD(input_officials_objects)        \n",
    "\n",
    "# dir = dir_utils.makesubdir(constants.path_csv, \"insider_trading/profile/education\")\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_JDs\", (d1,d2,d3), [\"\", constants.HOUSE, constants.SENATE, constants.INPUT]) \n",
    "\n",
    "\n",
    "# d1 = profile_JD(house_officials_objects)\n",
    "# d2 = profile_JD(senate_officials_objects)\n",
    "# d3 = profile_JD(officials_objects)        \n",
    "\n",
    "# dir = dir_utils.makesubdir(constants.path_csv, \"insider_trading/profile/education\")\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"profile_JDs_ALL\", (d1,d2,d3), [\"\", constants.HOUSE, constants.SENATE, constants.INPUT]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transaction Date (transaction_date) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency of Differences between Transaction and Disclosure Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def frequency_of_differences(group):\n",
    "#     d = {}\n",
    "#     # match = {}\n",
    "#     total = num = 0 \n",
    "\n",
    "#     for _,t in group.iterrows():\n",
    "#         # Negative, X days BEFORE\n",
    "#         # Positive, Y dayas AFTER\n",
    "#         diff = ptr_utils.difference_between_dates(t)      \n",
    "#         total += 1 \n",
    "#         num += diff   \n",
    "        \n",
    "#         # match = {5 days: {'Tom' : 1313, 'X': 3 , ...}. ..}\n",
    "#         # match =  dict_utils.increment_dictionary_in_dictionary(match, diff, official.get_name(t))\n",
    "            \n",
    "#         d =  dict_utils.increment_dictionary(d, int(diff))\n",
    "    \n",
    "#     d[\"Average\"] = round(num/total, 2)\n",
    "    \n",
    "#     return d \n",
    "#     # return dict_utils.sort_dictionary_by_keys(d)\n",
    "\n",
    "# d1 = frequency_of_differences(house_input_df)\n",
    "# d2 = frequency_of_differences(senate_input_df)\n",
    "# d3 = frequency_of_differences(input_df)\n",
    "\n",
    "# dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"frequency_of_differences\", (d1,d2,d3), [\"Difference\", constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each sector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transaction_date_wrt_sector(group, diff):\n",
    "#     # d_prime = {'sector' : {'date' : #_of_transactions, ....} , 'sector2' : .... }\n",
    "#     d_prime = {}\n",
    "    \n",
    "#     for _,t in group.iterrows():\n",
    "#         if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "#             sector = dir_utils.search_mapping(sector_df, t[constants.TICKER], sector=True)            \n",
    "#             d_prime =  dict_utils.increment_dictionary_in_dictionary(d_prime, sector, (t[constants.TDATE]))\n",
    "       \n",
    "#     # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "#     d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "#     d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "#     filename = \"transaction_date_wrt_sector\"  \n",
    "#     if diff:\n",
    "#         filename += \"_\" + diff \n",
    "#     key_header = constants.SECTOR\n",
    "#     value_header = constants.TDATE\n",
    "#     value_header2 = constants.NUMT\n",
    "\n",
    "#     dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "#     wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "#     df = pd.read_csv(wd)\n",
    "#     print(df.head(5))\n",
    "#     return d \n",
    "\n",
    "# _ = transaction_date_wrt_sector(house_input_df, constants.HOUSE)\n",
    "# _ = transaction_date_wrt_sector(senate_input_df, constants.SENATE)\n",
    "# _ = transaction_date_wrt_sector(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each sector controlling for each official. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transaction_date_wrt_sector_controlled(group, diff):    \n",
    "#     # d_prime = { ('ticker' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "#     d_prime = {}\n",
    "    \n",
    "#     for _,t in group.iterrows():\n",
    "#         if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "#             sector = dir_utils.search_mapping(sector_df, t[constants.TICKER], sector=True)  \n",
    "\n",
    "#             d_prime = dict_utils.increment_set_in_inner_dictionary(d_prime, sector, t[constants.TDATE], official.get_name(t))\n",
    "       \n",
    "    \n",
    "#     d_prime = dict_utils.flatten_len(d_prime)\n",
    "\n",
    "#     # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "#     d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "#     d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    \n",
    "#     filename = \"transaction_date_wrt_sector_controlled\"\n",
    "#     if diff:\n",
    "#         filename += \"_\" + diff \n",
    "     \n",
    "#     key_header = constants.SECTOR\n",
    "#     value_header = constants.TDATE\n",
    "#     value_header2 = constants.NUMT\n",
    "\n",
    "#     dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "#     wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "#     df = pd.read_csv(wd)\n",
    "#     print(df.head(5))\n",
    "#     return d \n",
    "\n",
    "# _ = transaction_date_wrt_sector_controlled(house_input_df, constants.HOUSE)\n",
    "# _ = transaction_date_wrt_sector_controlled(senate_input_df, constants.SENATE)\n",
    "# _ = transaction_date_wrt_sector_controlled(input_df, constants.INPUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transaction_date_wrt_industry(group, diff):    \n",
    "#     # d_prime = {'industry' : {'date' : #_of_transactions, ....} , 'industry2' : .... }\n",
    "#     d_prime = {}\n",
    "    \n",
    "#     for _,t in group.iterrows():\n",
    "#         if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "#             industry = dir_utils.search_mapping(industry_df, t[constants.TICKER], industry=True)\n",
    "\n",
    "#             d_prime =  dict_utils.increment_dictionary_in_dictionary(d_prime, industry, (t[constants.TDATE]))\n",
    "       \n",
    "#     # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "#     d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "#     d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "#     filename = \"transaction_date_wrt_industry\"\n",
    "#     if diff:\n",
    "#         filename += \"_\" + diff  \n",
    "#     key_header = constants.INDUSTRY\n",
    "#     value_header = constants.TDATE\n",
    "#     value_header2 = constants.NUMT\n",
    "\n",
    "#     dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "#     wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "#     df = pd.read_csv(wd)\n",
    "#     print(df.head(5))\n",
    "#     return d \n",
    "\n",
    "# _ = transaction_date_wrt_industry(house_input_df, constants.HOUSE)\n",
    "# _ = transaction_date_wrt_industry(senate_input_df, constants.SENATE)\n",
    "# _ = transaction_date_wrt_industry(input_df, constants.INPUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each industry controlling for official. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transaction_date_wrt_industry_controlled(group, diff):\n",
    "    \n",
    "#     # d_prime = { ('ticker' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "#     d_prime = {}\n",
    "    \n",
    "#     for _,t in group.iterrows():\n",
    "#         if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "#             industry = dir_utils.search_mapping(industry_df, t[constants.TICKER], industry=True)\n",
    "            \n",
    "#             d_prime = dict_utils.increment_set_in_inner_dictionary(d_prime, industry, t[constants.TDATE],  official.get_name(t))\n",
    "\n",
    "#     d_prime = dict_utils.flatten_len(d_prime)\n",
    "    \n",
    "#     # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "#     d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "#     d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "    \n",
    "#     filename = \"transaction_date_wrt_industry_controlled\"\n",
    "#     if diff:\n",
    "#         filename += \"_\" + diff  \n",
    "#     key_header = constants.INDUSTRY\n",
    "#     value_header = constants.TDATE\n",
    "#     value_header2 = constants.NUMT\n",
    "\n",
    "#     dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "#     wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "#     df = pd.read_csv(wd)\n",
    "#     print(df.head(5))\n",
    "#     return d \n",
    "\n",
    "# _ = transaction_date_wrt_industry_controlled(house_input_df, constants.HOUSE)\n",
    "# _ = transaction_date_wrt_industry_controlled(senate_input_df, constants.SENATE)\n",
    "# _ = transaction_date_wrt_industry_controlled(input_df, constants.INPUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each ticker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transaction_date_wrt_ticker(group, diff):    \n",
    "#     # d_prime = {'ticker' : {'date' : #_of_transactions, ....} , 'ticker2' : .... }\n",
    "#     d_prime = {}\n",
    "    \n",
    "#     for _,t in group.iterrows():\n",
    "#         if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "#             d_prime =  dict_utils.increment_dictionary_in_dictionary(d_prime, t[constants.TICKER], (t[constants.TDATE]))\n",
    "       \n",
    "#     # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "#     d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "#     d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "#     filename = \"transaction_date_wrt_ticker\"\n",
    "#     if diff:\n",
    "#         filename += \"_\" + diff\n",
    "#     key_header = constants.TICKER\n",
    "#     value_header = constants.TDATE\n",
    "#     value_header2 = constants.NUMT\n",
    "\n",
    "#     dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "#     wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "#     df = pd.read_csv(wd)\n",
    "#     print(df.head(5))\n",
    "#     return d \n",
    "\n",
    "# _ = transaction_date_wrt_ticker(house_input_df, constants.HOUSE)\n",
    "# _ = transaction_date_wrt_ticker(senate_input_df, constants.SENATE)\n",
    "# _ = transaction_date_wrt_ticker(input_df, constants.INPUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each ticker controlling for official."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transaction_date_wrt_ticker_controlled(group, diff):    \n",
    "#     # d_prime = { ('ticker' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "#     d_prime = {}\n",
    "    \n",
    "#     for _,t in group.iterrows():    \n",
    "#         if ptr_utils.isvalid(t[constants.TICKER]):    \n",
    "#             name = official.get_name(t)\n",
    "#             d_prime = dict_utils.increment_set_in_inner_dictionary(d_prime, t[constants.TICKER], t[constants.TDATE], name)\n",
    "       \n",
    "#     d_prime = dict_utils.flatten_len_inner_set(d_prime)\n",
    "\n",
    "#     # d = {'ticker' : {'best_date' : #_of_transactions}, .... }\n",
    "#     d = dict_utils.flatten_best(d_prime)\n",
    "#     d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "    \n",
    "#     filename = \"transaction_date_wrt_ticker_controlled\"\n",
    "#     if diff:\n",
    "#         filename += \"_\" + diff  \n",
    "        \n",
    "#     key_header = constants.TICKER\n",
    "#     value_header = constants.TDATE\n",
    "#     value_header2 = constants.NUMT\n",
    "\n",
    "#     dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "#     wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "#     return d \n",
    "\n",
    "# _ = transaction_date_wrt_ticker_controlled(house_input_df, constants.HOUSE)\n",
    "# _ = transaction_date_wrt_ticker_controlled(senate_input_df, constants.SENATE)\n",
    "# _ = transaction_date_wrt_ticker_controlled(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transaction_date_wrt_type(group, diff):        \n",
    "#     # d_prime = {'type' : {'date' : #_of_transactions, ....} , 'type2' : .... }\n",
    "#     d_prime = {}\n",
    "    \n",
    "#     for _,t in group.iterrows():\n",
    "#         if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "#             d_prime =  dict_utils.increment_dictionary_in_dictionary(d_prime, ptr_utils.format_type(t[constants.TYPE]), (t[constants.TDATE]))\n",
    "       \n",
    "#     # d = {'type' : {'best_date' : #_of_transactions}, .... }\n",
    "#     d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "#     d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "#     filename = \"transaction_date_wrt_type\"\n",
    "#     if diff:\n",
    "#         filename += \"_\" + diff  \n",
    "#     key_header = constants.TYPE\n",
    "#     value_header = constants.TDATE\n",
    "#     value_header2 = constants.NUMT\n",
    "\n",
    "#     dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "#     wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "#     df = pd.read_csv(wd)\n",
    "#     print(df)\n",
    "#     return d \n",
    "\n",
    "# _ = transaction_date_wrt_type(house_input_df, constants.HOUSE)\n",
    "# _ = transaction_date_wrt_type(senate_input_df, constants.SENATE)\n",
    "# _ = transaction_date_wrt_type(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for type controlling for official. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transaction_date_wrt_type_controlled(group, diff):    \n",
    "#     # d_prime = { ('type' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "#     d_prime = {}\n",
    "    \n",
    "#     for _,t in group.iterrows():\n",
    "#         if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "#             d_prime = dict_utils.increment_set_in_inner_dictionary(d_prime, t[constants.TYPE], (t[constants.TDATE]), official.get_name(t))\n",
    "       \n",
    "\n",
    "#     d_prime = dict_utils.flatten_len(d_prime)\n",
    "            \n",
    "#     # d = {'type' : {'best_date' : #_of_transactions}, .... }\n",
    "#     d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "#     d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "    \n",
    "    \n",
    "#     filename = \"transaction_date_wrt_type_controlled\"\n",
    "#     if diff:\n",
    "#         filename += \"_\" + diff  \n",
    "#     key_header = constants.TYPE\n",
    "#     value_header = constants.TDATE\n",
    "#     value_header2 = constants.NUMT\n",
    "\n",
    "#     dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "#     wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header, value_header2])\n",
    "#     df = pd.read_csv(wd)\n",
    "#     print(df.head(5))\n",
    "#     return d \n",
    "\n",
    "# _ = transaction_date_wrt_type_controlled(house_input_df, constants.HOUSE)\n",
    "# _ = transaction_date_wrt_type_controlled(senate_input_df, constants.SENATE)\n",
    "# _ = transaction_date_wrt_type_controlled(input_df, constants.INPUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transaction_date_wrt_amount(group, diff):\n",
    "#     # d_prime = {'amount' : {'date' : #_of_transactions, ....} , 'amount1' : .... }\n",
    "#     d_prime = {}\n",
    "    \n",
    "#     for _,t in group.iterrows():\n",
    "#         if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "#             amount = ptr_utils.consistency_amount(t)\n",
    "#             d_prime =  dict_utils.increment_dictionary_in_dictionary(d_prime, amount, (t[constants.TDATE]))\n",
    "       \n",
    "#     # d = {'type' : {'best_date' : #_of_transactions}, .... }\n",
    "#     d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "#     d = dict_utils.add_sort_key_for_amount(d)\n",
    "#     d = dict_utils.sort_dictionary_by_sort_key(d)\n",
    "\n",
    "#     filename = \"transaction_date_wrt_amount\"\n",
    "#     if diff:\n",
    "#         filename += \"_\" + diff  \n",
    "#     key_header = constants.TYPE\n",
    "\n",
    "#     dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "#     wd = csv_utils.make_csv_breakdown(dir, filename, d, key_header)\n",
    "#     df = pd.read_csv(wd)\n",
    "#     print(df.head(5))\n",
    "#     return d \n",
    "\n",
    "# _ = transaction_date_wrt_amount(house_input_df, constants.HOUSE)\n",
    "# _ = transaction_date_wrt_amount(senate_input_df, constants.SENATE)\n",
    "# _ = transaction_date_wrt_amount(input_df, constants.INPUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for amount controlling for official."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transaction_date_wrt_amount_controlled(group, diff):\n",
    "#     # d_prime = { ('amount' : {'date' : set(people_who_traded_on_that_day) , ....} , ....}\n",
    "#     d_prime = {}\n",
    "    \n",
    "#     for _,t in group.iterrows():\n",
    "#         if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "#             amount = ptr_utils.consistency_amount(t)\n",
    "#             d_prime = dict_utils.increment_set_in_inner_dictionary(d_prime, amount, (t[constants.TDATE]), official.get_name(t))\n",
    "       \n",
    "\n",
    "#     d_prime = dict_utils.flatten_len(d_prime)\n",
    "        \n",
    "#     # d = {'amount' : {'best_date' : #_of_transactions}, .... }\n",
    "#     d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "#     d = dict_utils.add_sort_key_for_amount(d)\n",
    "#     d = dict_utils.sort_dictionary_by_sort_key(d)\n",
    "    \n",
    "    \n",
    "#     filename = \"transaction_date_wrt_amount_controlled\"\n",
    "#     if diff:\n",
    "#         filename += \"_\" + diff  \n",
    "#     key_header = constants.AMOUNT\n",
    "\n",
    "#     dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "#     wd = csv_utils.make_csv_breakdown(dir, filename, d, key_header)\n",
    "#     df = pd.read_csv(wd)\n",
    "#     print(df.head(5))\n",
    "#     return d \n",
    "\n",
    "# _ = transaction_date_wrt_amount_controlled(house_input_df, constants.HOUSE)\n",
    "# _ = transaction_date_wrt_amount_controlled(senate_input_df, constants.SENATE)\n",
    "# _ = transaction_date_wrt_amount_controlled(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most popular transaction_date for each official."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transaction_date_wrt_official(group, diff):\n",
    "#     # d_prime = {'person1' : {'date' : #_of_transactions, ....} , 'person2' : .... }\n",
    "#     d_prime = {}\n",
    "    \n",
    "#     for _,t in group.iterrows():\n",
    "#         if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "#             d_prime =  dict_utils.increment_dictionary_in_dictionary(d_prime, official.get_name(t), (t[constants.TDATE]))\n",
    "       \n",
    "#     # d = {'person' : {'best_date' : #_of_transactions}, .... }\n",
    "#     d = dict_utils.flatten_best(d_prime)\n",
    "\n",
    "\n",
    "#     d = dict_utils.sort_dictionary_by_inner_values(d, reverse=True)\n",
    "\n",
    "#     filename = \"transaction_date_wrt_official\"\n",
    "#     if diff:\n",
    "#         filename += \"_\" + diff \n",
    "\n",
    "#     dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "#     wd = csv_utils.make_csv(dir, filename, d, [constants.OFFICIAL, constants.TDATE, constants.NUMT])\n",
    "#     df = pd.read_csv(wd)\n",
    "#     print(df.head(5))\n",
    "#     return d \n",
    "\n",
    "# transaction_date_wrt_official_res = transaction_date_wrt_official(house_input_df, constants.HOUSE)\n",
    "# transaction_date_wrt_official_res = transaction_date_wrt_official(senate_input_df, constants.SENATE)\n",
    "# transaction_date_wrt_official_res = transaction_date_wrt_official(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def num_of_trans_per_date(group):\n",
    "#     d={}\n",
    "\n",
    "#     for _,t in group.iterrows():\n",
    "#         d =  dict_utils.increment_dictionary(d, (t[constants.TDATE]))\n",
    "\n",
    "#     return d \n",
    "\n",
    "# d1 = num_of_trans_per_date(house_input_df)\n",
    "# d2 = num_of_trans_per_date(senate_input_df)\n",
    "# d3 = num_of_trans_per_date(input_df)\n",
    "\n",
    "# dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_per_date\", (d1,d2,d3), [constants.TDATE, constants.HOUSE, constants.SENATE, constants.INPUT])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Transactions per Date Controlled\n",
    "_Number of transactions per date controlled by official. E.g. if Ted Baker made 40 transactions on 1/1/02 and Sam Wall made 2 transactions on 1/1/02, we conclude that there were two transactions on 1/1/02._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def num_of_trans_per_date_controlled(group):    \n",
    "#     d = {}\n",
    "\n",
    "#     for _,t in group.iterrows():\n",
    "#         d =  dict_utils.increment_dictionary_in_dictionary(d, (t[constants.TDATE]), official.get_name(t))\n",
    "\n",
    "#     return dict_utils.flatten_len(d, inner_set=True)\n",
    "    \n",
    "# d1 = num_of_trans_per_date_controlled(house_input_df)\n",
    "# d2 = num_of_trans_per_date_controlled(senate_input_df)\n",
    "# d3 = num_of_trans_per_date_controlled(input_df)\n",
    "\n",
    "# dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_per_date_controlled\", (d1,d2,d3), [constants.TDATE, constants.HOUSE, constants.SENATE, constants.INPUT])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Transactions Within 2 Weeks Prior to Quarterly Tax Date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def num_of_trans_within_tax_date(group):        \n",
    "#         total = within = 0 \n",
    "#         d = {}\n",
    "\n",
    "#         for _,t in group.iterrows():  \n",
    "#                 total += 1 \n",
    "#                 if ptr_utils.within_tax_date(t[constants.TDATE]):\n",
    "#                         within += 1 \n",
    "\n",
    "#         d[\"(No. of transactions within 2 weeks of tax deadline, %)\"] = (within,  round(within/total, 2))\n",
    "\n",
    "#         return d \n",
    "\n",
    "# d1 = num_of_trans_within_tax_date(house_input_df)\n",
    "# d2 = num_of_trans_within_tax_date(senate_input_df)\n",
    "# d3 = num_of_trans_within_tax_date(input_df)\n",
    "\n",
    "# dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_within_tax_date\", (d1,d2,d3), [\"\", constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Transactions Within 2 Weeks Prior to Quarterly Tax Date Semi-Controlled \n",
    "\n",
    "_Given dict='09/03/2021': {'Thomas H Tuberville': 1, 'Cynthia M Lummis': 1, 'A. Mitchell Mcconnell, Jr.': 1}...I only incremement the number of within (tax date) once per date per official. So, if an official does 100 transactions on a date within two weeks of a quarterly deadline, then I only count it as one transaction._\n",
    "\n",
    "_A Note: total === number of transactions per person per date (so not really all transactions) because someone could have potentially made 60 transactions on one date which we don't include in neither total or within, if applicable._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def num_of_trans_within_tax_date_controlled(group):\n",
    "#         total = within = 0 \n",
    "#         people = set()\n",
    "#         d = {}\n",
    "\n",
    "#         for _, t in group.iterrows():\n",
    "#                 name = official.get_name(t)\n",
    "#                 if ptr_utils.within_tax_date(t[constants.TDATE]) and name not in people:\n",
    "#                         people.add(name)\n",
    "#                         within += 1 \n",
    "#                 total += 1         \n",
    "                \n",
    "#         d[\"(No. of transactions within 2 weeks of tax deadline, %)\"] = (within,  round(within/total, 2))\n",
    "\n",
    "#         return d\n",
    "\n",
    "# d1 = num_of_trans_within_tax_date_controlled(house_input_df)\n",
    "# d2 = num_of_trans_within_tax_date_controlled(senate_input_df)\n",
    "# d3 = num_of_trans_within_tax_date_controlled(input_df)\n",
    "\n",
    "# dir = dir_utils.makesubdir(constants.path_csv, constants.TDATE)\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_within_tax_date_controlled\", (d1,d2,d3), [\"\", constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Owner (owner) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Count of Owner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def freq_count_of_owner(group):\n",
    "#     # d = {'Joint' : 5}\n",
    "#     d = {}\n",
    "\n",
    "#     for _,t in group.iterrows():\n",
    "#         if constants.OWNER in t and ptr_utils.isvalid(t[constants.OWNER]):                \n",
    "#             d =  dict_utils.increment_dictionary(d, t[constants.OWNER].capitalize())\n",
    "        \n",
    "#     return dict_utils.sort_dictionary_by_values(d)\n",
    "    \n",
    "    \n",
    "# # {link : (canonical_name_input_based, official_object), ... }\n",
    "# d1 = freq_count_of_owner(house_input_df)\n",
    "# d2 = freq_count_of_owner(senate_input_df)\n",
    "\n",
    "# # {link : (canonical_name_input_based, official_object) ... }\n",
    "# d3 = freq_count_of_owner(input_df)\n",
    "\n",
    "# dir = dir_utils.makesubdir(constants.path_csv, constants.OWNER)\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"freq_count_of_owner\", (d1,d2,d3), [\"Owner\", constants.HOUSE, constants.SENATE, constants.INPUT]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def freq_count_by_spouse(group):\n",
    "#     # d = {'x_spouse' : 5}\n",
    "#     d = {}\n",
    "\n",
    "#     for _,t in group.iterrows():\n",
    "#         if constants.OWNER in t and ptr_utils.isvalid(t[constants.OWNER]) and t[constants.OWNER].capitalize() == 'Spouse':\n",
    "#             d =  dict_utils.increment_dictionary(d, official.get_name(t))\n",
    "        \n",
    "#     return d\n",
    "    \n",
    "    \n",
    "# # {link : (canonical_name_input_based, official_object), ... }\n",
    "# d1 = freq_count_by_spouse(house_input_df)\n",
    "# d2 = freq_count_by_spouse(senate_input_df)\n",
    "\n",
    "# # {link : (canonical_name_input_based, official_object) ... }\n",
    "# d3 = freq_count_by_spouse(input_df)\n",
    "\n",
    "# dir = dir_utils.makesubdir(constants.path_csv, constants.OWNER)\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"freq_count_by_spouse\", (d1,d2,d3), [\"Owner\", constants.HOUSE, constants.SENATE, constants.INPUT]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ticker (ticker) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def num_of_tickers(group):\n",
    "#     # d = {'ticker' : #_of_times }\n",
    "#     d = {}\n",
    "    \n",
    "#     for _,t in group.iterrows():\n",
    "#         if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "#             d =  dict_utils.increment_dictionary(d, t[constants.TICKER])\n",
    "       \n",
    "\n",
    "#     return dict_utils.sort_dictionary_by_values(d, reverse=True)\n",
    "\n",
    "# d1 = num_of_tickers(house_input_df)\n",
    "# d2 = num_of_tickers(senate_input_df)\n",
    "# d3 = num_of_tickers(input_df)\n",
    "    \n",
    "# dir = dir_utils.makesubdir(constants.path_csv, constants.TICKER)\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"num_of_tickers\", (d1,d2,d3), [constants.TICKER, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Ticker per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def frequency_of_ticker_breakdown_year(group, diff):\n",
    "#     d = {}\n",
    "\n",
    "#     # {\"ticker\" : {\"year\" : number, \"year\" : number, ...}}\n",
    "#     for _,t in group.iterrows():\n",
    "#         if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "#             d = dict_utils.increment_dictionary_in_dictionary(d, t[constants.TICKER], ptr_utils.get_year(t[constants.TDATE]))\n",
    "#             d = dict_utils.increment_dictionary_in_dictionary(d, t[constants.TICKER], 9999)\n",
    "\n",
    "#     d = dict_utils.sort_dictionary_by_keys(d)\n",
    "#     filename = \"frequency_of_ticker_breakdown_year\"\n",
    "#     if diff:\n",
    "#         filename += \"_\" + diff\n",
    "#     key_header = constants.TICKER\n",
    "    \n",
    "    \n",
    "#     dir = dir_utils.makesubdir(constants.path_csv, constants.TICKER)\n",
    "#     wd = csv_utils.make_csv_breakdown(dir, filename, d, key_header)\n",
    "#     print(pd.read_csv(wd).head(2))\n",
    "\n",
    "# frequency_of_ticker_breakdown_year(house_input_df, constants.HOUSE)\n",
    "# frequency_of_ticker_breakdown_year(senate_input_df, constants.SENATE)\n",
    "# frequency_of_ticker_breakdown_year(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Ticker per Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def frequency_of_ticker_by_date(group, diff):\n",
    "#     # {ticker : {date : ___}}\n",
    "#     d = {}\n",
    "    \n",
    "#     for _,t in group.iterrows():\n",
    "#         if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "#             d = dict_utils.increment_dictionary_in_dictionary(d, t[constants.TICKER], t[constants.TDATE])\n",
    "\n",
    "    \n",
    "#     d = dict_utils.flatten_best(d)\n",
    "    \n",
    "\n",
    "#     filename = \"frequency_of_ticker_by_date\"\n",
    "#     if diff:\n",
    "#         filename += \"_\" + diff\n",
    "    \n",
    "#     dir = dir_utils.makesubdir(constants.path_csv, constants.TICKER)\n",
    "#     wd = csv_utils.make_csv_breakdown(dir, filename, d, constants.TICKER)\n",
    "#     print(pd.read_csv(wd).head(2))\n",
    "\n",
    "# d1 = frequency_of_ticker_by_date(house_input_df, constants.HOUSE)\n",
    "# d2 = frequency_of_ticker_by_date(senate_input_df, constants.SENATE)\n",
    "# d3 = frequency_of_ticker_by_date(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Industry & Sector "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Transactions per Industry\n",
    "_Not controlled in any way._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def number_of_transactions_per_indusry(group):        \n",
    "#     d = {}\n",
    "    \n",
    "#     for _,t in group.iterrows():\n",
    "#         if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "#             industry = dir_utils.search_mapping(industry_df, t[constants.TICKER], industry=True)\n",
    "#             d = dict_utils.increment_dictionary(d, industry)\n",
    "\n",
    "#     return dict_utils.sort_dictionary_by_values(d)\n",
    "    \n",
    "\n",
    "# d1 = number_of_transactions_per_indusry(house_input_df)\n",
    "# d2 = number_of_transactions_per_indusry(senate_input_df)\n",
    "# d3 = number_of_transactions_per_indusry(input_df)\n",
    "\n",
    "# dir = dir_utils.makesubdir(constants.path_csv, constants.INDUSTRY)\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"number_of_transactions_per_indusry\", (d1,d2,d3), [constants.INDUSTRY, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "\n",
    "\n",
    "# def number_of_transactions_per_sector(group):        \n",
    "#     d = {}\n",
    "    \n",
    "#     for _,t in group.iterrows():\n",
    "#         if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "#             sector = dir_utils.search_mapping(sector_df, t[constants.TICKER], sector=True)\n",
    "#             d = dict_utils.increment_dictionary(d, sector)\n",
    "\n",
    "#     return dict_utils.sort_dictionary_by_values(d)\n",
    "    \n",
    "\n",
    "# d1 = number_of_transactions_per_sector(house_input_df)\n",
    "# d2 = number_of_transactions_per_sector(senate_input_df)\n",
    "# d3 = number_of_transactions_per_sector(input_df)\n",
    "\n",
    "# dir = dir_utils.makesubdir(constants.path_csv, constants.SECTOR)\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"number_of_transactions_per_sector\", (d1,d2,d3), [constants.SECTOR, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Industry Breakdown per Official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def frequency_of_industry_breakdown_official(group, diff):\n",
    "#     d = {}\n",
    "\n",
    "#     for _,t in group.iterrows():\n",
    "#         if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "#             industry = dir_utils.search_mapping(industry_df, t[constants.TICKER], industry=True)\n",
    "#             d = dict_utils.increment_dictionary_in_dictionary(d, official.get_name(t), industry)\n",
    "\n",
    "#     d = dict_utils.sort_dictionary_by_keys(d)\n",
    "    \n",
    "#     filename = \"frequency_of_industry_breakdown_official\"\n",
    "#     if diff:\n",
    "#         filename += \"_\" + diff\n",
    "#     dir = dir_utils.makesubdir(constants.path_csv, constants.INDUSTRY)\n",
    "\n",
    "#     wd = csv_utils.make_csv_breakdown(dir, filename, d, constants.OFFICIAL)\n",
    "#     print(pd.read_csv(wd).head(2))\n",
    "    \n",
    "#     return d \n",
    "\n",
    "# d1 = frequency_of_industry_breakdown_official(house_input_df, constants.HOUSE)\n",
    "# d2 = frequency_of_industry_breakdown_official(senate_input_df, constants.SENATE)\n",
    "# d3 = frequency_of_industry_breakdown_official(input_df, constants.INPUT)\n",
    "\n",
    "\n",
    "\n",
    "# def frequency_of_sector_breakdown_official(group, diff):\n",
    "#     d = {}\n",
    "\n",
    "#     for _,t in group.iterrows():\n",
    "#         if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "#             sector = dir_utils.search_mapping(sector_df, t[constants.TICKER], sector=True)\n",
    "#             d = dict_utils.increment_dictionary_in_dictionary(d, official.get_name(t), sector)\n",
    "\n",
    "#     d = dict_utils.sort_dictionary_by_keys(d)\n",
    "    \n",
    "#     filename = \"frequency_of_sector_breakdown_official\"\n",
    "#     if diff:\n",
    "#         filename += \"_\" + diff\n",
    "#     dir = dir_utils.makesubdir(constants.path_csv, constants.SECTOR)\n",
    "\n",
    "#     wd = csv_utils.make_csv_breakdown(dir, filename, d, constants.OFFICIAL)\n",
    "#     print(pd.read_csv(wd).head(2))\n",
    "    \n",
    "#     return d \n",
    "\n",
    "# d1 = frequency_of_sector_breakdown_official(house_input_df, constants.HOUSE)\n",
    "# d2 = frequency_of_sector_breakdown_official(senate_input_df, constants.SENATE)\n",
    "# d3 = frequency_of_sector_breakdown_official(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency of Industry per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def frequency_of_industry_breakdown(group, diff):\n",
    "#     d = {}\n",
    "\n",
    "#     for _,t in group.iterrows():     \n",
    "#         if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "#             industry = dir_utils.search_mapping(industry_df, t[constants.TICKER], industry=True)  \n",
    "#             d = dict_utils.increment_dictionary_in_dictionary(d, industry, ptr_utils.get_year(t[constants.TDATE]))\n",
    "\n",
    "#     d = dict_utils.sort_dictionary_by_keys(d)\n",
    "    \n",
    "#     filename = \"frequency_of_industry_breakdown\"\n",
    "#     if diff:\n",
    "#         filename += \"_\" + diff \n",
    "#     key_header = \"industry\"\n",
    "    \n",
    "    \n",
    "#     dir = dir_utils.makesubdir(constants.path_csv, constants.INDUSTRY)\n",
    "#     wd = csv_utils.make_csv_breakdown(dir, filename, d, key_header)\n",
    "#     print(pd.read_csv(wd).head(2))\n",
    "#     return d \n",
    "\n",
    "# d1 = frequency_of_industry_breakdown(house_input_df, constants.HOUSE)\n",
    "# d2 = frequency_of_industry_breakdown(senate_input_df, constants.SENATE)\n",
    "# d3 = frequency_of_industry_breakdown(input_df, constants.INPUT)\n",
    "\n",
    "\n",
    "# def frequency_of_sector_breakdown(group, diff):\n",
    "#     d = {}\n",
    "\n",
    "#     for _,t in group.iterrows():     \n",
    "#         if ptr_utils.isvalid(t[constants.TICKER]):\n",
    "#             sector = dir_utils.search_mapping(sector_df, t[constants.TICKER], sector=True)  \n",
    "#             d = dict_utils.increment_dictionary_in_dictionary(d, sector, ptr_utils.get_year(t[constants.TDATE]))\n",
    "\n",
    "#     d = dict_utils.sort_dictionary_by_keys(d)\n",
    "    \n",
    "#     filename = \"frequency_of_sector_breakdown\"\n",
    "#     if diff:\n",
    "#         filename += \"_\" + diff \n",
    "#     key_header = \"sector\"\n",
    "    \n",
    "    \n",
    "#     dir = dir_utils.makesubdir(constants.path_csv, constants.SECTOR)\n",
    "#     wd = csv_utils.make_csv_breakdown(dir, filename, d, key_header)\n",
    "#     print(pd.read_csv(wd).head(2))\n",
    "#     return d \n",
    "\n",
    "# d1 = frequency_of_sector_breakdown(house_input_df, constants.HOUSE)\n",
    "# d2 = frequency_of_sector_breakdown(senate_input_df, constants.SENATE)\n",
    "# d3 = frequency_of_sector_breakdown(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asset Description (asset_description) and Comment (comment) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def number_of_options(group):\n",
    "#     count = total = 0 \n",
    "#     d = {}\n",
    "#     # [this_person_placed_an_option, ...]\n",
    "#     people = set()\n",
    "\n",
    "#     for _,t in group.iterrows():\n",
    "#         if constants.ASSET_DESCRIPTION in t and ptr_utils.isvalid(t[constants.ASSET_DESCRIPTION]) and (\"Put\" in t[constants.ASSET_DESCRIPTION]  or \"put\" in t[constants.ASSET_DESCRIPTION]  or \"Call\" in t[constants.ASSET_DESCRIPTION]  or \"call\" in t[constants.ASSET_DESCRIPTION]  or \"Option\" in t[constants.ASSET_DESCRIPTION] or \"option\" in t[constants.ASSET_DESCRIPTION]): \n",
    "#             count += 1 \n",
    "#             people.add(official.get_name(t))\n",
    "#         total += 1 \n",
    "\n",
    "#     d[\"(No. of Options, %)\"] = (count, round(count/total, 2))\n",
    "\n",
    "#     return d \n",
    "            \n",
    "# d1 = number_of_options(house_input_df)\n",
    "# d2 = number_of_options(senate_input_df)\n",
    "# d3 = number_of_options(input_df)\n",
    "\n",
    "# dir = dir_utils.makesubdir(constants.path_csv, constants.COMMENT)\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"number_of_options\", (d1,d2,d3), [\"\", constants.HOUSE, constants.SENATE, constants.INPUT])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Scanned PDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def number_of_scanned_pdfs(group):\n",
    "#     count = total = 0 \n",
    "#     d = {}\n",
    "\n",
    "#     for _,t in group.iterrows():\n",
    "#         if t[constants.ASSET_DESCRIPTION] == constants.DISCLOSED:\n",
    "#             count += 1 \n",
    "#         total += 1 \n",
    "            \n",
    "#     d[\"(No. of Scanned PDFS, %)\"] = (count, round(count/total, 2))\n",
    "\n",
    "#     return d \n",
    "            \n",
    "# d1 = number_of_scanned_pdfs(house_input_df)\n",
    "# d2 = number_of_scanned_pdfs(senate_input_df)\n",
    "# d3 = number_of_scanned_pdfs(input_df)\n",
    "\n",
    "# dir = dir_utils.makesubdir(constants.path_csv, constants.COMMENT)\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"number_of_scanned_pdfs\", (d1,d2,d3), [\"\", constants.HOUSE, constants.SENATE, constants.INPUT])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asset Type (asset_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Asset Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def frequency_of_asset_type(group):\n",
    "#     d = {}\n",
    "\n",
    "#     for _,t in group.iterrows():\n",
    "#         if constants.ATYPE in t and ptr_utils.isvalid(t[constants.ATYPE]):\n",
    "#             d = dict_utils.increment_dictionary(d, t[constants.ATYPE])\n",
    "      \n",
    "#     return dict_utils.sort_dictionary_by_values(d)\n",
    "\n",
    "# d1 = frequency_of_asset_type(house_input_df)\n",
    "# d2 = frequency_of_asset_type(senate_input_df)\n",
    "# d3 = frequency_of_asset_type(input_df)\n",
    "\n",
    "# dir = dir_utils.makesubdir(constants.path_csv, constants.ATYPE)\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"frequency_of_asset_type\", (d1,d2,d3), [constants.ATYPE, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amount "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Amount by Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def frequency_of_amount_by_persom(group, diff):\n",
    "#     d = {}\n",
    "\n",
    "#     for _,t in group.iterrows():\n",
    "#         amount = ptr_utils.consistency_amount(t)\n",
    "#         d = dict_utils.increment_dictionary_in_dictionary(d, official.get_name(t), amount)\n",
    "    \n",
    "#     d = dict_utils.sort_dictionary_by_keys(d)\n",
    "    \n",
    "#     filename = \"frequency_of_amount_by_person\"\n",
    "#     if diff:\n",
    "#         filename += \"_\" + diff \n",
    "        \n",
    "#     key_header = constants.AMOUNT\n",
    "    \n",
    "#     dir = dir_utils.makesubdir(constants.path_csv, constants.AMOUNT)\n",
    "#     wd = csv_utils.make_csv_breakdown(dir, filename, d, key_header)\n",
    "#     print(pd.read_csv(wd).head(2))\n",
    "    \n",
    "#     return d \n",
    "   \n",
    "    \n",
    "# d1 = frequency_of_amount_by_persom(house_input_df, constants.HOUSE)\n",
    "# d2 = frequency_of_amount_by_persom(senate_input_df, constants.SENATE)\n",
    "# # d3 = frequency_of_amount_by_persom(input_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Transactions by Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random \n",
    "\n",
    "# def frequency_of_amount_total(group):\n",
    "#     d = {}        \n",
    "\n",
    "#     for _,t in group.iterrows():\n",
    "#         amount = ptr_utils.consistency_amount(t)                    \n",
    "#         d = dict_utils.increment_dictionary(d, amount)\n",
    "\n",
    "#     return d\n",
    "    \n",
    "# d1 = frequency_of_amount_total(house_input_df)\n",
    "# d2 = frequency_of_amount_total(senate_input_df)\n",
    "# d3 = frequency_of_amount_total(input_df)\n",
    "\n",
    "\n",
    "# dir = dir_utils.makesubdir(constants.path_csv, constants.AMOUNT)\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"frequency_of_amount_total\", (d1,d2,d3), [constants.AMOUNT, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Amount by Gender "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def frequency_of_amount_by_gender(group, diff, normalized=None):\n",
    "#     d = {}\n",
    "    \n",
    "#     for _,t in group.iterrows():\n",
    "#         name = official.get_name(t)\n",
    "#         link = input_all_officials_name[name]\n",
    "#         amount = ptr_utils.consistency_amount(t)\n",
    "#         d = dict_utils.increment_dictionary_in_dictionary(d, amount, all_officials_gender[link])\n",
    "\n",
    "#     if normalized: \n",
    "#         for amount in d:\n",
    "#             for gender in d[amount]:\n",
    "#                 d[amount][gender] /= normalized[gender]\n",
    "        \n",
    "#     d = dict_utils.add_sort_key_for_amount(d)\n",
    "#     d = dict_utils.sort_dictionary_by_sort_key(d)\n",
    "\n",
    "\n",
    "#     filename = \"frequency_of_amount_by_gender\"\n",
    "#     if diff:\n",
    "#         filename += \"_\" + diff\n",
    "#     if normalized:\n",
    "#         filename += \"_normalized\"\n",
    "    \n",
    "#     dir = dir_utils.makesubdir(constants.path_csv, constants.AMOUNT)\n",
    "#     wd = csv_utils.make_csv_breakdown(dir, filename, d, constants.AMOUNT)\n",
    "#     print(pd.read_csv(wd).head(2))\n",
    "#     return d \n",
    "   \n",
    "# d1 = frequency_of_amount_by_gender(house_input_df, constants.HOUSE, profile_gender(input_house_officials_link))\n",
    "# d2 = frequency_of_amount_by_gender(senate_input_df, constants.SENATE, profile_gender(input_senate_officials_link))\n",
    "# d3 = frequency_of_amount_by_gender(input_df, constants.INPUT, profile_gender(input_all_officials_link))\n",
    "    \n",
    "# d1 = frequency_of_amount_by_gender(house_input_df, constants.HOUSE)\n",
    "# d2 = frequency_of_amount_by_gender(senate_input_df, constants.SENATE)\n",
    "# d3 = frequency_of_amount_by_gender(input_df, constants.INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Transactions by Political Affiliation and Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def frequency_of_amount_by_aff(group, diff):\n",
    "#     d = {}\n",
    "\n",
    "#     for _,t in group.iterrows():\n",
    "#         obj = t_to_obj(t)\n",
    "#         amount = ptr_utils.consistency_amount(t)            \n",
    "#         d = dict_utils.increment_dictionary_in_dictionary(d, amount, obj.party)\n",
    "\n",
    "\n",
    "#     d = dict_utils.add_sort_key_for_amount(d)\n",
    "#     d = dict_utils.sort_dictionary_by_sort_key(d)\n",
    "    \n",
    "        \n",
    "#     filename = \"frequency_of_amount_by_aff\"\n",
    "#     if diff:\n",
    "#         filename += \"_\" + diff\n",
    "    \n",
    "#     dir = dir_utils.makesubdir(constants.path_csv, constants.AMOUNT)\n",
    "#     wd = csv_utils.make_csv_breakdown(dir, filename, d, constants.AMOUNT)\n",
    "#     print(pd.read_csv(wd).head(2))\n",
    "    \n",
    "#     return d \n",
    "   \n",
    "    \n",
    "# d1 = frequency_of_amount_by_aff(house_input_df, constants.HOUSE)\n",
    "# d2 = frequency_of_amount_by_aff(senate_input_df, constants.SENATE)\n",
    "# d3 = frequency_of_amount_by_aff(input_df, constants.INPUT) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def average_activity(group, diff):\n",
    "#     d={}\n",
    "    \n",
    "#     for _,t in group.iterrows():\n",
    "#         if ptr_utils.isvalid(t[constants.AMOUNT]):\n",
    "                        \n",
    "#             mean = ptr_utils.get_gmean(t[constants.AMOUNT])\n",
    "\n",
    "#             d = dict_utils.increment_list_in_dictionary(d, official.get_name(t), mean)\n",
    "\n",
    "\n",
    "#     d = dict_utils.flatten_gmean(d)        \n",
    "            \n",
    "#     filename = \"average_activity\"\n",
    "#     if diff:\n",
    "#         filename += \"_\" + diff\n",
    "\n",
    "#     key_header = constants.OFFICIAL \n",
    "#     value_header = \"average_size_of_transactions\"\n",
    "\n",
    "#     d = dict_utils.sort_dictionary_by_values(d)\n",
    "#     d = dict_utils.commify(d)\n",
    "\n",
    "#     dir = dir_utils.makesubdir(constants.path_csv, constants.AMOUNT)\n",
    "#     wd = csv_utils.make_csv(dir, filename, d, [key_header, value_header])\n",
    "#     df = pd.read_csv(wd)\n",
    "#     print(df.head(5))\n",
    "\n",
    "#     return d \n",
    "\n",
    "# d1 = average_activity(house_input_df, constants.HOUSE)\n",
    "# d2 = average_activity(senate_input_df, constants.SENATE)\n",
    "# d3 = average_activity(input_df, constants.INPUT) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types (type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Actions Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def frequency_of_act(group):\n",
    "#     d = {}\n",
    "\n",
    "#     for _,t in group.iterrows():\n",
    "#         if ptr_utils.isvalid(t[constants.TYPE]):\n",
    "#             d = dict_utils.increment_dictionary(d, t[constants.TYPE])\n",
    "    \n",
    "#     return dict_utils.sort_dictionary_by_values(d)\n",
    "    \n",
    "     \n",
    "# d1 = frequency_of_act(house_input_df)\n",
    "# d2 = frequency_of_act(senate_input_df)\n",
    "# d3 = frequency_of_act(input_df)\n",
    "\n",
    "# dir = dir_utils.makesubdir(constants.path_csv, constants.TYPE)\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"frequency_of_act\", (d1,d2,d3), [constants.TYPE, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Transactions per Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def types_of_transactions_per_person(group, diff, normalized=None):\n",
    "#     d={}\n",
    "    \n",
    "#     for _,t in group.iterrows():\n",
    "#         d = dict_utils.increment_dictionary_in_dictionary(d, official.get_name(t), t[constants.TYPE])\n",
    "#         d = dict_utils.increment_dictionary_in_dictionary(d, official.get_name(t), constants.TOTAL)\n",
    "\n",
    "\n",
    "#     if normalized: \n",
    "#         for k,v in d.items():\n",
    "#             newinner = {}\n",
    "#             for ik, iv in v.items():\n",
    "#                 link = input_all_officials_name[k]\n",
    "#                 _, obj = input_officials_objects[link]\n",
    "#                 newinner[ik] = round(iv/obj.get_seniority(), 2)\n",
    "                \n",
    "#             d[k] = newinner\n",
    "    \n",
    "#     filename = \"types_of_transactions_per_person\"\n",
    "#     if diff:\n",
    "#         filename += \"_\" + diff\n",
    "#     if normalized:\n",
    "#         filename += \"_normalized\"\n",
    "\n",
    "#     d = dict_utils.sort_dictionary_by_keys(d)\n",
    "\n",
    "#     dir = dir_utils.makesubdir(constants.path_csv, constants.TYPE)\n",
    "#     wd = csv_utils.make_csv_breakdown(dir, filename, d, constants.OFFICIAL)\n",
    "#     df = pd.read_csv(wd)\n",
    "#     print(df.head(5))\n",
    "\n",
    "#     return d \n",
    "\n",
    "# d1 = types_of_transactions_per_person(house_input_df, constants.HOUSE)\n",
    "# d2 = types_of_transactions_per_person(senate_input_df, constants.SENATE)\n",
    "# d3 = types_of_transactions_per_person(input_df, constants.INPUT)\n",
    "\n",
    "# d1 = types_of_transactions_per_person(house_input_df, constants.HOUSE, normalized=True)\n",
    "# d2 = types_of_transactions_per_person(senate_input_df, constants.SENATE, normalized=True)\n",
    "# d3 = types_of_transactions_per_person(input_df, constants.INPUT, normalized=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def num_of_trans_per_year(group, normalized=None):\n",
    "#     d={}\n",
    "    \n",
    "#     for _,t in group.iterrows():\n",
    "#         d =  dict_utils.increment_dictionary(d, ptr_utils.get_year(t[constants.TDATE]))\n",
    "\n",
    "#     if normalized:\n",
    "#         d2 = {}\n",
    "#         for k,v in d.items():\n",
    "#             d2[k] = v/normalized\n",
    "            \n",
    "        \n",
    "#     return dict_utils.sort_dictionary_by_values(d), dict_utils.sort_dictionary_by_values(d2)\n",
    "\n",
    "# d1, d4 = num_of_trans_per_year(house_input_df, len(input_house_officials_objects))\n",
    "# d2, d5 = num_of_trans_per_year(senate_input_df, len(input_senate_officials_objects))\n",
    "# d3, d6 = num_of_trans_per_year(input_df, len(input_officials_objects))\n",
    "\n",
    "# dir = dir_utils.makesubdir(constants.path_csv, constants.FREQ)\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_per_year\", (d1,d2,d3), [\"year\", constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_per_year_normalized\", (d4,d5,d6), [\"year\", constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Transactions per Person \n",
    "_Not controlling for number of years in position or size of transaction._ For each official, we want their total number of transactions.  {'Sam': 5, 'Alex': 2424, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def num_of_trans_per_person(group):\n",
    "#     d={}\n",
    "    \n",
    "#     for _,t in group.iterrows():\n",
    "#         d = dict_utils.increment_dictionary(d, official.get_name(t))\n",
    "\n",
    "#     return dict_utils.sort_dictionary_by_values(d)\n",
    "    \n",
    "# d1 = num_of_trans_per_person(house_input_df)\n",
    "# d2 = num_of_trans_per_person(senate_input_df)    \n",
    "# d3 = num_of_trans_per_person(input_df)\n",
    "\n",
    "# dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_per_person\", (d1,d2,d3), [constants.OFFICIAL, constants.HOUSE, constants.SENATE, constants.INPUT])\n",
    "\n",
    "\n",
    "# def num_of_trans_per_person_normalized(group):\n",
    "#     d={}\n",
    "    \n",
    "#     for _,t in group.iterrows():\n",
    "#         d = dict_utils.increment_dictionary(d, official.get_name(t))\n",
    "\n",
    "#     new_d = {}\n",
    "#     for k,v in d.items():\n",
    "#         link = input_all_officials_name[k]\n",
    "#         _, obj = input_officials_objects[link]\n",
    "#         new_d[k] = round(v/obj.get_seniority(), 2) if round(v/obj.get_seniority(), 2) != 0 else 1 \n",
    "        \n",
    "#     return new_d\n",
    "    \n",
    "# d1 = num_of_trans_per_person_normalized(house_input_df)\n",
    "# d2 = num_of_trans_per_person_normalized(senate_input_df)    \n",
    "# d3 = num_of_trans_per_person_normalized(input_df)\n",
    "\n",
    "# dir = dir_utils.makesubdir(constants.path_csv, constants.PROFILE)\n",
    "# csv_utils.make_csv_multiple_dicts(dir, \"num_of_trans_per_person_normalized\", (d1,d2,d3), [constants.OFFICIAL, constants.HOUSE, constants.SENATE, constants.INPUT])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e534e48711db4d1e1c48977d0d14ff85b1f16d41bcc4fdfd88268a329b3c9d66"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
